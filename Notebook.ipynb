{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g50JFo12q7mu",
        "outputId": "c71430fb-dcdf-493b-a17c-4945ecc8eee6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n",
            "ERROR: No matching distribution found for faiss-gpu\n"
          ]
        }
      ],
      "source": [
        "! pip install -qq -U  tiktoken pypdf faiss-gpu\n",
        "! pip install -qq -U transformers InstructorEmbedding\n",
        "! pip install -qq -U accelerate bitsandbytes xformers einops\n",
        "! pip install langchain==0.1.2 sentence_transformers==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikXI46Haqk8T",
        "outputId": "db70a3ab-db79-4033-c310-317e89fd9083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/faiss_index_hp_zip.zip\n",
            "replace /content/faiss_index_hp/content/faiss_index_hp/index.faiss? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/faiss_index_hp_zip.zip -d /content/faiss_index_hp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnEfKdlRrC-z",
        "outputId": "84dd1dd1-45e2-4df8-ef7c-f3e12cfbc41b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import trange\n"
          ]
        }
      ],
      "source": [
        "import langchain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from InstructorEmbedding import INSTRUCTOR\n",
        "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541,
          "referenced_widgets": [
            "74757051b1684c939ad73ab268fd135a",
            "b38ff279188c49afa8298ada33bb2d45",
            "c92989c8bb764ba28778e47f242186ee",
            "4b1577ec50754dbaaef75a250ad96f41",
            "ed635c515e7844e587054c46f8a7293a",
            "427287483c0d4fa0955e64afb31853a8",
            "9cd6ffbe92494e8aa6b5b7fa53bd7fec",
            "49fbbe1ca0c64348abe4047859b5dd5b",
            "d615cfe957a642ce80e2ea6da8656aed",
            "4b479556d1624c04945faa851d9e31b9",
            "66d9e3d5830c488ca4211001475ed84f",
            "a786fbf8a8454ec185964763ca8de96e",
            "7f471d30ec974177816aef2acf2d1468",
            "31e6dc60c55e4c989f2498cb555756b7",
            "e10b4b04a66b43908851895ac0ef391a",
            "c20207bc1e8748ffad80a3eeda12adcd",
            "bf0df769c6b040359d8728c108b9bbe1",
            "b429ee2cda484aa4b83f9c2e734115f7",
            "41bb013c679b4697b508b3d10a236b3f",
            "1927851c41db406c83933bbbefd90739",
            "de4db21c49824949972f6ff47c498ad9",
            "ece4ca531d3045a0bbb1c59465e77cc6",
            "6c05a3fc16a04f67b4a65c7ee90cbefe",
            "612174fd64c442e39aca36f4f904b56f",
            "174853e7a904470792682f90af79cc22",
            "e5bedfddcf224d6698e3c19a56af0d63",
            "8433d0798b8b49409774397d133f97a0",
            "3c1f507882d042b5ba45562b27be9679",
            "182715959efd4d5ead1788d541798b6a",
            "8aa3049ba4dd4d3788c49a3204042123",
            "102d52e569d344d2aaded742f0cfb3a9",
            "a63184bb7a5347ad96b228ba32fd43b5",
            "6a544fd636004abbba74ed30d7e922d7",
            "3e949d6ad24440d8b78cefc19d0897ef",
            "62db16d354fc4e41af4196ec4b4193da",
            "dc550b8d89fc42e190367d0cd6b04886",
            "8c6e1b6fa17040e39b64eb4a6d552bf0",
            "3699239f496242f79da402d86701d97d",
            "75da699ae6994e2491b75c402d3cc48a",
            "20ba8d6240a54973b897d633bcbe8366",
            "a698c05ca3914319a8a8ed8676fd3d32",
            "8965f7137844485386d2c23b69eb6a66",
            "3a8f1fd4ac49493ba27be1b88b4efc10",
            "80f2ce731b1b4b60a674b362052a894a",
            "9f70a22bbb6146a4a0151ae2fbeffdf7",
            "c266ac54bec7423588398b3da9430000",
            "027b7a49ad3d48f3a575ed03c2245e60",
            "e5125b04c82c4753946e289d8457ce5f",
            "f019d0fef7f14dcbb3b217417122233a",
            "1b32cdc0338344898ef00ee08844758b",
            "8d214dff5b76415582a6cca9e17f81e1",
            "a4f556d528d64ce9b3c76d22ac9d344e",
            "8f818c26ad0643c3a3fe9c96a4045f9c",
            "0ed385c3bea340d8972992169b5d100d",
            "3aa484311f1b4c9a81aeec7d877b3fe9",
            "401ae295d4844593afdcacf49a469915",
            "ea13ac8fa51542abb1a6d9be5aa0fec2",
            "b69afe3bc7c24699a638a2777cc41532",
            "26d73cdf39c44477b7e1e066e4b843dd",
            "3270078a406642f69672d71de71cb446",
            "d9706e40a31543b28bd852bc55528059",
            "c487ab2ee27c4007bd82f829d78fe77c",
            "c0e8f72e20c94ea78ca5ad65139dbe09",
            "95b0687fa64d4e9c920c06ca83c9aba3",
            "927312b07c954fe6ac2afc1daa42d78a",
            "f0579994e98144beab765911a8e385ec",
            "7920c1b266ef4d6a8c6bfbcc0b74244c",
            "9feb4d40fa5a45c391aafdda0fde77b6",
            "fc445ac7745f46f4a514761c8d5e90af",
            "691df0a2b2ba414dbe86c51480f7e824",
            "26f70cb48b7940f6a7676233dbeef3d1",
            "feed9be0a0d840058632ab8326063fa9",
            "a3caf8326c304b8fa8e2a56771b1349d",
            "028dc09f782e4e58af108564ee9d2b7d",
            "857c1addd5c7459d833b9ac52453ea75",
            "0b73d3efd96d4229a4a82e63c25f0a17",
            "1b3342e5a9c94d379df8d74d67784de4",
            "3bdedb0152c6464492ab9292ae6982d0",
            "3476eaecfd78486691dbd70c52bf2467",
            "397c41e4536f4f83bddcc8af5882a026",
            "0d4530d33c4e45728ab76235bcced886",
            "418c7414c017437eafde601358bdc5c3",
            "63101aedfece4324939736dfa344abf8",
            "c881d316bea849b9a4db9ef6b4f18599",
            "4754b50a94aa420eb28eb46f4e5faf16",
            "4f15e937eb6f41ebbdd7e9b66bc5309c",
            "8f20a5c8f3f0425bb32aa5a7aae2a90f",
            "586e2c4167b548d2a8ecb8ca2e8f5e4c",
            "64d999ec1d37458b8b75fd1e8fede25b",
            "11cdecc3da334cad8b08c304d9e2906e",
            "2654acfd96794d8588535aa6b0e562ce",
            "321511fc895d489fab1c1167e3801bb2",
            "448f5743d6f743189b6f4fe4b79580ed",
            "7d1c1b5a3067478a832990c3c014e589",
            "bdd3ae8bfbf446309b54f466de0e1af6",
            "5e936149ad5a403498bb59085048fbbd",
            "9a2d985fd93740878573c9d68bd1e780",
            "03c3f550b72d4d5d97c065f21df6373b",
            "48d753276ecf475797379d7161896706"
          ]
        },
        "id": "zdYKHscGrTWu",
        "outputId": "9bb45100-97b9-473d-d8d5-4b126ea03abd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74757051b1684c939ad73ab268fd135a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/739 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a786fbf8a8454ec185964763ca8de96e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/28.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c05a3fc16a04f67b4a65c7ee90cbefe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e949d6ad24440d8b78cefc19d0897ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f70a22bbb6146a4a0151ae2fbeffdf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "401ae295d4844593afdcacf49a469915",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7920c1b266ef4d6a8c6bfbcc0b74244c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bdedb0152c6464492ab9292ae6982d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64d999ec1d37458b8b75fd1e8fede25b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_repo  = 'bigscience/bloom-7b1'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_repo , load_in_4bit=True,\n",
        "            device_map='auto',\n",
        "            torch_dtype=torch.float16,\n",
        "            low_cpu_mem_usage=True,)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
        "\n",
        "max_len = 1024\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj8kHbMOwj0W"
      },
      "outputs": [],
      "source": [
        "temperature = 0,\n",
        "top_p = 0.95,\n",
        "repetition_penalty = 1.15\n",
        "\n",
        "    # splitting\n",
        "split_chunk_size = 800\n",
        "split_overlap = 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMiaKKIMpiTE",
        "outputId": "1a38867f-17cb-4085-e4da-b0beeb754fa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BloomForCausalLM(\n",
              "  (transformer): BloomModel(\n",
              "    (word_embeddings): Embedding(250880, 4096)\n",
              "    (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "    (h): ModuleList(\n",
              "      (0-29): 30 x BloomBlock(\n",
              "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): BloomAttention(\n",
              "          (query_key_value): Linear4bit(in_features=4096, out_features=12288, bias=True)\n",
              "          (dense): Linear4bit(in_features=4096, out_features=4096, bias=True)\n",
              "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): BloomMLP(\n",
              "          (dense_h_to_4h): Linear4bit(in_features=4096, out_features=16384, bias=True)\n",
              "          (gelu_impl): BloomGelu()\n",
              "          (dense_4h_to_h): Linear4bit(in_features=16384, out_features=4096, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laJ82u_hsp16"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    task = \"text-generation\",\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    max_length = max_len,\n",
        "    temperature = 0.3 ,\n",
        "    top_p = top_p,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline = pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcsEoe3gtKJq",
        "outputId": "15334dce-3d48-4362-fb74-9f1cd0bb25b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `(0.95,)` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " going to do it?\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "- I don't know.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"how are you \"\n",
        "print(llm(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAiLBRBTtW2o",
        "outputId": "29b3168f-8ab5-4b55-c00c-f62a3210a0b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [00:39<00:00,  6.65s/it]\n"
          ]
        }
      ],
      "source": [
        "loader = DirectoryLoader(\n",
        "    path=\"/content/\" ,\n",
        "    glob=\"*.pdf\",\n",
        "    loader_cls=PyPDFLoader,\n",
        "    show_progress=True,\n",
        "    use_multithreading=True\n",
        ")\n",
        "\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BuQGysPlaJr",
        "outputId": "f07f3a04-ec44-46a6-839a-723311c0549b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ],
      "source": [
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "hf = HuggingFaceInstructEmbeddings(\n",
        "    model_name=\"hkunlp/instructor-large\",\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVXD-izzGC4h"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = split_chunk_size,\n",
        "    chunk_overlap = split_overlap\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "YLKoPUQhaIiz",
        "outputId": "a6518c55-b17d-43f1-997a-8f76a6f8f580"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e39bd79d1881>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mmetadatas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    911\u001b[0m                 \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \"\"\"\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m         return cls.__from(\n\u001b[1;32m    915\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[1;32m    169\u001b[0m         \u001b[0minstruction_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_instruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'token_embeddings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'context_masks'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mcontext_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context_masks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0moutput_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrans_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0moutput_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1975\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1976\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                 )\n\u001b[1;32m   1109\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1111\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    695\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    599\u001b[0m     ):\n\u001b[1;32m    600\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mpresent_key_value_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "db = FAISS.from_documents(texts, hf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDphBbVACVIW",
        "outputId": "8408e608-aab8-4cbc-9176-8d0add9fccc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"Undergraduate Fundamentals of Machine Learning\\nCitation\\nDeuschle, William J. 2019. Undergraduate Fundamentals of Machine Learning. Bachelor's \\nthesis, Harvard College.\\nPermanent link\\nhttps://nrs.harvard.edu/URN-3:HUL.INSTREPOS:37364585\\nTerms of Use\\nThis article was downloaded from Harvard University’s DASH repository, and is made available \\nunder the terms and conditions applicable to Other Posted Material, as set forth at http://\\nnrs.harvard.edu/urn-3:HUL.InstRepos:dash.current.terms-of-use#LAA\\nShare Your Story\\nThe Harvard community has made this article openly available.\\nPlease share how this access benefits you.  Submit a story .\\nAccessibility\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 0}),\n",
              " Document(page_content='Undergraduate Fundamentals\\nof Machine Learning\\nWilliam J. Deuschle\\nAdviser: Finale Doshi-Velez\\nA thesis presented to Computer Science in partial ful\\x0cllment of the honors requirement for the\\ndegree of Bachelor of Arts\\nHarvard College\\nCambridge, Massachusetts\\nDecember, 2018', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 1}),\n",
              " Document(page_content=\"ii\\nAbstract\\nDrawing on lectures, course materials, existing textbooks, and other resources, we synthesize and\\nconsolidate the content necessary to o\\x0ber a successful \\x0crst exposure to machine learning for stu-\\ndents with an undergraduate-level background in linear algebra and statistics. The \\x0cnal product\\nis a textbook for Harvard's introductory course in machine learning, CS 181.\\nThis work is motivated by a lack of resources for individuals with an undergraduate background in\\nthe areas necessary to succeed in an introductory course in machine learning. Speci\\x0ccally, existing\\ntextbooks are too encyclopedic to be expedient for students seeing the material for the \\x0crst time,\\nor they assume mathematical and statistical maturity beyond that of undergraduates. Like other\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 2}),\n",
              " Document(page_content='professors and students have done for several courses at Harvard, we seek to solve this problem\\nwith a properly-scoped textbook following the trajectory of the course.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 2}),\n",
              " Document(page_content=\"iii\\nAcknowledgements\\nMuch graditude is owed to my thesis adviser, Prof. Finale Doshi-Velez, for patiently guiding me\\nthrough both the technical and teaching-focused aspects of this thesis.\\nI'd also like to thank my family, particularly my parents, for their constant support and encour-\\nagement throughout my life, as well as the many friends who aided me while writing this thesis.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 3}),\n",
              " Document(page_content=\"Contents\\n1 Introduction to Machine Learning 1\\n1.1 What is Machine Learning? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\n1.2 What Will This Book Teach Me? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\n1.3 Our Machine Learning Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.4 This Book's Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nMathematical and Statistical Notation . . . . . . . . . . . . . . . . . . . . . . 3\\nTextbook Speci\\x0cc Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n2 Regression 4\\n2.1 De\\x0cning the Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 4}),\n",
              " Document(page_content='2.2 Solution Options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n2.2.1 K-Nearest-Neighbors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2.2 Neural Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2.3 Random Forests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2.4 Gradient Boosted Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2.5 Turning to Linear Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Introduction to Linear Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n2.4 Basic Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 4}),\n",
              " Document(page_content='2.4.1 Merging of Bias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n2.4.2 Visualization of Linear Regression . . . . . . . . . . . . . . . . . . . . . . . . 7\\n2.5 Finding the Best Fitting Line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n2.5.1 Objective Functions and Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n2.5.2 Least Squares Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n2.6 Linear Regression Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n2.6.1 Optimal Weights via Matrix Di\\x0berentiation . . . . . . . . . . . . . . . . . . . 10\\n2.6.2 Bayesian Solution: Maximum Likelihood Estimation . . . . . . . . . . . . . . 11', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 4}),\n",
              " Document(page_content='2.6.3 Alternate Interpretation: Linear Regression as Projection . . . . . . . . . . . 12\\n2.7 Model Flexibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n2.7.1 Basis Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n2.7.2 Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\niv', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 4}),\n",
              " Document(page_content='CONTENTS v\\n2.7.3 Generalizing Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n2.7.4 Bayesian Regularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n2.8 Choosing Between Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n2.8.1 Bias-Variance Tradeo\\x0b and Decomposition . . . . . . . . . . . . . . . . . . . 21\\n2.8.2 Cross-Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n2.8.3 Making a Model Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n2.8.4 Bayesian Model Averaging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n2.9 Linear Regression Extras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 5}),\n",
              " Document(page_content='2.9.1 Predictive Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n2.10 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n3 Classi\\x0ccation 28\\n3.1 De\\x0cning the Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n3.2 Solution Options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n3.3 Discriminant Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n3.3.1 Basic Setup: Binary Linear Classi\\x0ccation . . . . . . . . . . . . . . . . . . . . 29\\n3.3.2 Multiple Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n3.3.3 Basis Changes in Classi\\x0ccation . . . . . . . . . . . . . . . . . . . . . . . . . . 30', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 5}),\n",
              " Document(page_content='3.4 Numerical Parameter Optimization and Gradient Descent . . . . . . . . . . . . . . . 32\\n3.4.1 Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n3.4.2 Batch Gradient Descent versus Stochastic Gradient Descent . . . . . . . . . . 35\\n3.5 Objectives for Decision Boundaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n3.5.1 0/1 Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n3.5.2 Least Squares Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\n3.5.3 Hinge Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\n3.6 Probabilistic Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 5}),\n",
              " Document(page_content='3.6.1 Probabilistic Discriminative Models . . . . . . . . . . . . . . . . . . . . . . . 38\\nLogistic Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nMulti-Class Logistic Regression and Softmax . . . . . . . . . . . . . . . . . . 41\\n3.6.2 Probabilistic Generative Models . . . . . . . . . . . . . . . . . . . . . . . . . 43\\nClassi\\x0ccation in the Generative Setting . . . . . . . . . . . . . . . . . . . . . 43\\nMLE Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nNaive Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\n3.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\n4 Neural Networks 48', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 5}),\n",
              " Document(page_content='4.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n4.1.1 Comparison to Other Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n4.1.2 Universal Function Approximation . . . . . . . . . . . . . . . . . . . . . . . . 49\\n4.2 Feed-Forward Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 5}),\n",
              " Document(page_content='vi CONTENTS\\n4.3 Neural Network Basics and Terminology . . . . . . . . . . . . . . . . . . . . . . . . . 50\\n4.3.1 Adaptive Basis Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\n4.4 Network Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\n4.4.1 Objective Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\n4.4.2 Optimizing Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\n4.4.3 Backpropagation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\n4.4.4 Computing Derivatives Using Backpropagation . . . . . . . . . . . . . . . . . 55\\n4.5 Choosing a Network Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 6}),\n",
              " Document(page_content='4.5.1 Cross Validation for Neural Networks . . . . . . . . . . . . . . . . . . . . . . 59\\n4.5.2 Preventing Over\\x0ctting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nRegularization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\\nData Augmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\\n4.6 Specialized Forms of Neural Networks . . . . . . . . . . . . . . . . . . . . . . . . . . 60\\n4.6.1 Convolutional Neural Networks (CNNs) . . . . . . . . . . . . . . . . . . . . . 60\\n4.6.2 Recurrent Neural Networks (RNNs) . . . . . . . . . . . . . . . . . . . . . . . 61\\n4.6.3 Bayesian Neural Networks (BNNs) . . . . . . . . . . . . . . . . . . . . . . . . 62\\n5 Support Vector Machines 63', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 6}),\n",
              " Document(page_content='5.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\n5.1.1 Max Margin Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\n5.1.2 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\\n5.2 Hard Margin Classi\\x0cer for Linearly Separable Data . . . . . . . . . . . . . . . . . . . 64\\n5.2.1 Why the Hard Margin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\\n5.2.2 Deriving our Optimization Problem . . . . . . . . . . . . . . . . . . . . . . . 65\\n5.2.3 What is a Support Vector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\\n5.3 Soft Margin Classi\\x0cer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 6}),\n",
              " Document(page_content='5.3.1 Why the Soft Margin? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\\n5.3.2 Updated Optimization Problem for Soft Margins . . . . . . . . . . . . . . . . 68\\n5.3.3 Soft Margin Support Vectors . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\\n5.4 Conversion to Dual Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\\n5.4.1 Lagrange Multipliers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\\n5.4.2 Deriving the Dual Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . 71\\n5.4.3 Making Predictions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\n5.4.4 Why is the Dual Formulation Necessary? . . . . . . . . . . . . . . . . . . . . 73', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 6}),\n",
              " Document(page_content='5.4.5 Kernel Composition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\n6 Clustering 75\\n6.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\n6.1.1 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\n6.2 K-Means Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 6}),\n",
              " Document(page_content=\"CONTENTS vii\\n6.2.1 Lloyd's Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\n6.2.2 Example of Lloyd's . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\n6.2.3 Number of Clusters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\\n6.2.4 Initialization and K-Means++ . . . . . . . . . . . . . . . . . . . . . . . . . . 81\\n6.2.5 K-Medoids Alternative . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\\n6.3 Hierarchical Agglomerative Clustering . . . . . . . . . . . . . . . . . . . . . . . . . . 83\\n6.3.1 HAC Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\n6.3.2 Linkage Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 7}),\n",
              " Document(page_content='Min-Linkage Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nMax-Linkage Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nAverage-Linkage Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nCentroid-Linkage Criterion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nDi\\x0berent Linkage Criteria Produce Di\\x0berent Clusterings . . . . . . . . . . . . 87\\n6.3.3 How HAC Di\\x0bers from K-Means . . . . . . . . . . . . . . . . . . . . . . . . . 88\\n7 Dimensionality Reduction 89\\n7.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\n7.2 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 7}),\n",
              " Document(page_content='7.3 Principle Component Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\\n7.3.1 Reconstruction Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\\n7.3.2 Minimizing Reconstruction Loss . . . . . . . . . . . . . . . . . . . . . . . . . 93\\n7.3.3 Multiple Principle Components . . . . . . . . . . . . . . . . . . . . . . . . . . 94\\n7.3.4 Identifying Directions of Maximal Variance in our Data . . . . . . . . . . . . 94\\n7.3.5 Choosing the Optimal Number of Principal Components . . . . . . . . . . . . 95\\n7.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\\n8 Graphical Models 99\\n8.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 7}),\n",
              " Document(page_content='8.2 Directed Graphical Models (Bayesian Networks) . . . . . . . . . . . . . . . . . . . . 100\\n8.2.1 Joint Probability Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\n8.2.2 Generative Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\n8.2.3 Generative Modeling vs. Discriminative Modeling . . . . . . . . . . . . . . . 104\\n8.2.4 Understanding Complexity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105\\n8.2.5 Independence and D-Separation . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\n8.3 Example: Naive Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\\n8.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\n9 Mixture Models 112', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 7}),\n",
              " Document(page_content='9.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\\n9.2 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 7}),\n",
              " Document(page_content='viii CONTENTS\\n9.3 Fitting a Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\n9.3.1 Maximum Likelihood for Mixture Models . . . . . . . . . . . . . . . . . . . . 114\\n9.3.2 Complete-Data Log Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\n9.4 Expectation-Maximization (EM) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\n9.4.1 Expectation Step . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\n9.4.2 Maximization Step . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\\n9.4.3 Full EM Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\n9.4.4 Connection to K-Means Clustering . . . . . . . . . . . . . . . . . . . . . . . . 119', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 8}),\n",
              " Document(page_content='9.4.5 Dice Example: Mixture of Multinomials . . . . . . . . . . . . . . . . . . . . . 119\\n9.5 Gaussian Mixture Models (GMM) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\\n9.6 Admixture Models: Latent Dirichlet Allocation (LDA) . . . . . . . . . . . . . . . . . 122\\n9.6.1 LDA for Topic Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\n9.6.2 Applying EM to LDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\\n9.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\n10 Hidden Markov Models 125\\n10.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\n10.2 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 8}),\n",
              " Document(page_content=\"10.3 HMM Data, Model, and Parameterization . . . . . . . . . . . . . . . . . . . . . . . . 127\\n10.3.1 HMM Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\n10.3.2 HMM Model Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\n10.3.3 HMM Parameterization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\n10.4 EM for HMMs and the Forward-Backward Algorithm . . . . . . . . . . . . . . . . . 128\\n10.4.1 Forward-Backward Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 129\\n10.4.2 Using \\x0b's and\\x0c's for Training and Inference . . . . . . . . . . . . . . . . . . 131\\nJoint Distribution Over Emissions . . . . . . . . . . . . . . . . . . . . . . . . 132\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 8}),\n",
              " Document(page_content='Smoothing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\\nPrediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\\nTransition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\\n10.4.3 E-Step . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\n10.4.4 M-Step . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134\\n10.4.5 From HMM Training to Inference . . . . . . . . . . . . . . . . . . . . . . . . . 134\\n10.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 8}),\n",
              " Document(page_content=\"Chapter 1\\nIntroduction to Machine Learning\\n1.1 What is Machine Learning?\\nThere is a great deal of misunderstanding about what machine learning is, fueled by recent success\\nand at times sensationalist media coverage. While its applications have been and will continue\\nto be extraordinarily powerful under the right circumstances, it's important to gain some sense\\nof where and why the tools presented in this book will be applicable. Broadly, machine learning\\nis the application of statistical, mathematical, and numerical techniques to derive some form of\\nknowledge from data. This `knowledge' may a\\x0bord us some sort of summarization, visualization,\\ngrouping, or even predictive power over data sets.\\nWith all that said, it's important to emphasize the limitations of machine learning. It is not nor\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 9}),\n",
              " Document(page_content='will it ever be a replacement for critical thought and methodical, procedural work in data science.\\nIndeed, machine learning can be reasonably characterized a loose collection of disciplines and tools.\\nWhere the lines begin that separate machine learning from statistics or mathematics or probability\\ntheory or any other handful of \\x0celds that it draws on are not clear. So while this book is a synopsis\\nof the basics of machine learning, it might be better understood as a collection of tools that can be\\napplied to a speci\\x0cc subset of problems.\\n1.2 What Will This Book Teach Me?\\nThe purpose of this book is to provide you the reader with the following: a framework with which\\nto approach problems that machine learning learning might help solve. You will hopefully come', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 9}),\n",
              " Document(page_content='away with a sense of the strengths and weaknesses of the tools presented within and, even more\\nimportantly, gain an understanding of how these tools are situated among problems of interest. To\\nthat end, we will aim to develop systems for thinking about the structure of the problems we work\\non. That way, as we continue to add new tools and techniques to our repertoire, we will always\\nhave a clear view of the context in which we can expect to use them. This will not only create\\na nice categorization of the di\\x0berent practices in machine learning, it will also help motivate why\\nthese techniques exist in the \\x0crst place.\\nYou will not be an expert in any individual ML concept after reading this text. Rather, you', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 9}),\n",
              " Document(page_content='should come away with three di\\x0berent levels of understanding. First, you should gain a general\\ncontextual awareness of the di\\x0berent problem types that ML techniques may be used to solve.\\nSecond, you should come away with a practical awareness of how di\\x0berent ML techniques operate.\\nThis means that after you have successfully identi\\x0ced an appropriate ML technique for a given\\nproblem, you will also know how that method actually accomplishes the goal at hand. If you only\\n1', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 9}),\n",
              " Document(page_content=\"2 CHAPTER 1. INTRODUCTION TO MACHINE LEARNING\\ncome away with these two levels of understanding, you will be o\\x0b to a good start. The third level\\nof understanding relates to having a derivational awareness of the algorithms and methods we will\\nmake use of. This level of understanding is not strictly necessary to successfully interact with\\nexisting machine learning capabilities, but it will be required if you desire to go further and deepen\\nexisting knowledge. Thus, we will be presenting derivations, but it will be secondary to a high level\\nunderstanding of problem types and the practical intuition behind available solutions.\\n1.3 Our Machine Learning Framework\\nLet's consider for the \\x0crst time what we will call the Machine Learning Cube . The purpose of\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 10}),\n",
              " Document(page_content=\"this cube is to describe the domain of problems we will encounter, and it will be a useful way to\\ndelineate the techniques we will apply to di\\x0berent types of problems. Understanding the di\\x0berent\\nfacets of the cube will aid you in understanding machine learning as a whole, and can even give you\\nintuition about techniques that you have never encountered before. Let's now describe the features\\nof the cube.\\nOur cube has three axes. On the \\x0crst axis we will put the domain of our data. The domain of\\nour data can take on one of two forms: discrete orcontinuous . Discrete, or categorical data, is\\ndata that can only fall into one of nspeci\\x0cc classes. For example: male or female, integer values\\nbetween 1 and 10, or di\\x0berent states in the U.S. are all examples of categorical data. Continuous\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 10}),\n",
              " Document(page_content='data is that which falls on the real number line.\\nThe second axis of the cube is reserved for the statistical nature of the machine learning tech-\\nnique in question. Speci\\x0ccally, it will fall into one of two broad categories: probabilistic or\\nnon-probabilistic techniques. Probabilistic techniques are those for which we incorporate our\\ndata using some form of statistical distribution or summary. In general, we are then able to dis-\\ncard some or all of our data once we have \\x0cnished tuning our probabilistic model. In contrast,\\nnon-probabilistic techniques are those that use the data directly to perform some action. A very\\ncommon and general example of this is comparing how close a new data point is to other points', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 10}),\n",
              " Document(page_content='in your existing data set. Non-probabilistic techniques potentially make fewer assumptions, but\\nthey do require that you keep around some or all of your data. They are also potentially slower\\ntechniques at runtime because they may require touching all of the data in your dataset to perform\\nsome action. These are a very broad set of guidelines for the distinction between probabilistic and\\nnon-probabilistic techniques - you should expect to see some exceptions and even some techniques\\nthat \\x0ct into both of these categories to some degree. Having a sense for their general bene\\x0cts and\\ndrawbacks is useful, and you will gain more intuition about the distinction as we begin to explore\\ndi\\x0berent techniques.\\nThe third and \\x0cnal axis of the cube describes the type of training we will use. There are', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 10}),\n",
              " Document(page_content='two major classes of machine learning techniques: supervised andunsupervised . In fact, these\\ntwo classes of techniques are so important to describing the \\x0celd of machine learning that we will\\nroughly divide this textbook into two halves dedicated to techniques found within each of these\\ncategories. A supervised technique is one for which we get to observe a data set of both the inputs\\nand the outputs ahead of time, to be used for training. For example, we might be given a data\\nset about weather conditions and crop production over the years. Then, we could train a machine\\nlearning model that learns a relationship between the input data (weather) and output data (crop\\nproduction). The implication here is that given new input data, we will be able to predict the', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 10}),\n",
              " Document(page_content=\"unseen output data. An unsupervised technique is one for which we only get a data set of `inputs'\\nahead of time. In fact, we don't even need to consider these as inputs anymore: we can just consider\\nthem to be a set of data points that we wish to summarize or describe. Unsupervised techniques\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 10}),\n",
              " Document(page_content=\"1.4. THIS BOOK'S NOTATION 3\\nrevolve around clustering or otherwise describing our data.\\nWe will see examples of all of these as we progress throughout the book, and you will gain an\\nintuition for where di\\x0berent types of data and techniques fall in our cube. Eventually, given just\\nthe information in the cube for a new technique, you will have a solid idea of how that technique\\noperates.\\n1.4 This Book's Notation\\nThe machine learning community uses a number of di\\x0berent conventions, and learning to decipher\\nthe di\\x0berent versions of those conventions is important to understanding work done in the \\x0celd.\\nFor this book, we will try to stick to a standard notation that we de\\x0cne here in part. In addition\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 11}),\n",
              " Document(page_content='to mathematical and statistical notation, we will also describe the conventions used in this book\\nfor explaining and breaking up di\\x0berent concepts.\\nMathematical and Statistical Notation\\nWe will describe the dimensionality of variables when necessary, but generic variables will often be\\nsu\\x0ecient when explaining new techniques. Boldface variables ( x) represent vectors, capital boldface\\ncharacters ( X) represent matrices, and standard typeface variables ( x) describe scalars.\\nStatistical distributions will sometimes be described in terms of their probability density func-\\ntion (PDF), e.g. Y\\x181\\n\\x1bp\\n2\\x19e\\x00(x\\x00\\x16)2/2\\x1b2. Alternatively, in the case of a well known probability\\ndistribution, we will describe those in terms of their standard notation, e.g. Y\\x18N(\\x16;\\x1b2)\\nTextbook Speci\\x0cc Notation', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 11}),\n",
              " Document(page_content='We have also introduced a few conventions to make consumption of this material easier. We have\\nboxes dedicated to de\\x0cnitions, explaining techniques in the context of the ML Framework Cube,\\nand for explaining common misconceptions:\\nDe\\x0cnition 1.4.1 (De\\x0cnition Explanation): You will \\x0cnd de\\x0cnitions in these dark gray boxes.\\nDerivation 1.4.1 (Derivation Explanation): You will \\x0cnd derivations in these light gray boxes.\\nML Framework Cube: ML Framework Cube\\nYou will \\x0cnd ML Framework Cube explanations in these blue wrapped boxes.\\n?You will \\x0cnd explanations for subtle or confusing concepts in these red wrapped boxes.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 11}),\n",
              " Document(page_content=\"Chapter 2\\nRegression\\nA major component of machine learning, the one that most people associate with ML, is dedicated\\nto making predictions about a target given some inputs, such as predicting how much money an\\nindividual will earn in their lifetime given their demographic information. In this chapter, we're\\ngoing to focus on the case where our prediction is a continuous, real number. When the target is\\na real number, we call this prediction procedure regression .\\n2.1 De\\x0cning the Problem\\nIn order to understand regression, let's start in a more natural place: what types of problems are\\nwe trying to solve? What exactly does it mean to make a prediction that is a continuous, real\\nnumber ? To build some intuition, here are a few examples of problems that regression could be\\nused for:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 12}),\n",
              " Document(page_content=\"1. Predicting a person's height given the height of their parents.\\n2. Predicting the amount of time someone will take to pay back a loan given their credit history.\\n3. Predicting what time a package will arrive given current weather and tra\\x0ec conditions.\\nHopefully you are starting to see the pattern emerging here. Given some inputs, we need to\\nproduce a prediction for a continuous output. That is exactly the purpose of regression . Notice\\nthat regression isn't any one technique in particular. It's just a class of methods that helps us\\nachieve our overall goal of predicting a continuous output.\\nDe\\x0cnition 2.1.1 (Regression): A class of techniques that seeks to make predictions about un-\\nknown continuous target variables given observed input variables.\\n2.2 Solution Options\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 12}),\n",
              " Document(page_content='Now that you understand the type of problems we are trying to solve with regression, we can\\nstart to think at a high level of the di\\x0berent ways we might arrive at a solution. Here is a short,\\nnonexhaustive list of regression techniques with brief explanations:\\n4', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 12}),\n",
              " Document(page_content=\"2.2. SOLUTION OPTIONS 5\\n2.2.1 K-Nearest-Neighbors\\nK-Nearest-Neighbors is an extremely intuitive, non-parametric technique for regression or classi\\x0c-\\ncation. It works as follows in the regression case:\\n1. Identify the Kpoints in our data set that are closest to the new data point. `Closest' is some\\nmeasure of distance, usually Euclidean.\\n2. Average the value of interest for those Kdata points.\\n3. Return that averaged value of interest: it is the prediction for our new data point.\\n?Anon-parametric model simply means we don't make any assumptions about the form of our data. We only need\\nto use the data itself to make predictions.\\n2.2.2 Neural Networks\\nA neural network works by scaling and combining input variables many times. Furthermore, at\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 13}),\n",
              " Document(page_content=\"each step of scaling and combining inputs, we typically apply some form of nonlinearity over our\\ndata values. The proof is beyond the scope of this textbook, but neural networks are known to be\\nuniversal function approximators . This means that given enough scaling and combining steps, we\\ncan approximate any function to an arbitrarily high degree of accuracy using a neural network.\\n2.2.3 Random Forests\\nRandom forests are what's known as an ensemble method . This means we average the results of\\nmany smaller regressors known as decision trees to produce a prediction. These decision trees\\nindividually operate by partitioning our original data set with respect to the value of predictive\\ninterest using a subset of the features present in that data set. Each decision tree individually may\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 13}),\n",
              " Document(page_content=\"not be a reliable regressor; by combining many of them we achieve a model with better performance.\\n2.2.4 Gradient Boosted Trees\\nGradient boosted trees are another technique built on decision trees. Assume we start with a set\\nof decision trees that together achieve a certain level of performance. Then, we iteratively add new\\ntrees to improve performance on the hardest examples in our data set, and reweight our new set of\\ndecision trees to produce the best level of performance possible.\\n2.2.5 Turning to Linear Regression\\nYou've likely never even heard of some of these preceding techniques - that's okay. The point is\\nthat we have a number of existing methods that take di\\x0berent approaches to solving regression\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 13}),\n",
              " Document(page_content=\"problems. Each of these will have their own strengths and weaknesses that contribute to a decision\\nabout whether or not you might use them for a given regression problem. We obviously do not\\ncover these methods in great detail here; what's more important is the understanding that there\\nare a variety of ways to go about solving regression problems. From here on out, we will take a\\ndeeper dive into linear regression. There are several reasons for which we are exploring this speci\\x0cc\\ntechnique in greater detail. The two main reasons are that it has been around for a long time\\nand thus is very well understood, and it also will introduce many concepts and terms that will be\\nutilized extensively in other machine learning topics.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 13}),\n",
              " Document(page_content=\"6 CHAPTER 2. REGRESSION\\n2.3 Introduction to Linear Regression\\nIn this chapter, we're speci\\x0ccally going to focus on linear regression , which means that our goal\\nis to \\x0cnd some linear combination of the x1;:::;xDinput values that predict our target y.\\nDe\\x0cnition 2.3.1 (Linear Regression): Suppose we have an input x2RDand a continuous\\ntargety2R. Linear regression determines weights wi2Rthat combine the values of xito\\nproducey:\\ny=w0+w1x1+:::+wDxD (2.1)\\n?Noticew0in the expression above, which doesn't have a corresponding x0value. This is known as the bias term.\\nIf you consider the de\\x0cnition of a line y=mx+b, the bias term is corresponds to the intercept b. It accounts for\\ndata that has a non-zero mean.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 14}),\n",
              " Document(page_content=\"Let's illustrate how linear regression works using an example, considering the case of 10 year old\\nSam. She is curious about how tall she will be when she grows up. She has a data set of parents'\\nheights and the \\x0cnal heights of their children. The inputs xare:\\nx1= height of mother (cm)\\nx2= height of father (cm)\\nUsing linear regression, she determines the weights wto be:\\nw= [34;0:39;0:33]\\nSam's mother is 165 cm tall and her father is 185 cm tall. Using the results of the linear regression\\nsolution, Sam solves for her expected height:\\nSam's height = 34 + 0 :39(165) + 0 :33(185) = 159.4 cm\\nML Framework Cube: Linear Regression\\nLet's inspect the categories linear regression falls into for our ML framework cube. First, as we've\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 14}),\n",
              " Document(page_content='already stated, linear regression deals with a continuous output domain. Second, our goal is\\nto make predictions on future data points, and to construct something capable of making those\\npredictions we \\x0crst need a labeled data set of inputs and outputs. This makes linear regression a\\nsupervised technique. Third and \\x0cnally, linear regression is non-probabilistic . Note that there\\nalso exist probabilistic interpretations of linear regression which we will discuss later in the chapter.\\nDomain Training Probabilistic\\nContinuous Supervised No\\n2.4 Basic Setup\\nThe most basic form of linear regression is a simple weighted combination of the input variables x,\\nwhich you will often see written as:\\nf(x;w) =w0+w1x1+:::+wDxD (2.2)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 14}),\n",
              " Document(page_content=\"2.4. BASIC SETUP 7\\nFigure 2.1: Data set with clear trend.\\n2.4.1 Merging of Bias\\nWe're going to introduce a common notational trick here for making the bias term, w0, easier to\\nhandle. At the moment w0is unwieldly because it is not being multiplied by an xivalue. A simple\\nway to make our bias term easier to handle is to simply introduce another variable, x0, that is\\nalways 1 for every data point. For example, considering the case of Sam's height from above, we\\nhave the height of her parents, x:\\nx= (165;185)\\nWe now add a 1 in the \\x0crst position of the data point to make it:\\nx'= (1;165;185)\\nWe do this for every point in our data set. This bias trick lets us write:\\nf(x;w) =wTx=w0x0+w1x1+:::+wDxD (2.3)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 15}),\n",
              " Document(page_content=\"This is more compact, easier to reason about, and makes properties of linear algebra nicer for the\\ncalculations we will be performing.\\n2.4.2 Visualization of Linear Regression\\nLet's try to build some intuition about how linear regression works. Our algorithm is given a\\ncollection of data points: inputs xand corresponding targets y. Our goal is to \\x0cnd the best set of\\nweights wsuch that given a new data point x, we can accurately predict the true target value y.\\nThis is visualizable in the simple case where xis a 1-dimensional input variable, as in Figure 2.1.\\nOur eyes are naturally able to detect a very clear trend in this data. If we were given a new\\nx\\x03data point, how would be predict its target value y? We would \\x0crst \\x0ct a line to our data, as in\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 15}),\n",
              " Document(page_content=\"Figure 2.2, and then \\x0cnd where on that line the new x\\x03value sits.\\nThat is the entirety of linear regression! It \\x0cts the `best' line to our data, and then uses that\\nline to make predictions. In 1-D input space, this manifests itself as the simple problem seen above,\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 15}),\n",
              " Document(page_content=\"8 CHAPTER 2. REGRESSION\\nFigure 2.2: Data set with clear trend, best \\x0ctting line included.\\nwhere we need only \\x0cnd a single bias term w0(which acts as the intercept of the line) and single\\nweightw1(which acts as the slope of the line). However, the same principle applies to higher\\ndimensional data as well. We're always \\x0ctting the hyperplane that best predicts the data.\\n?Although our input data points xcan take on multiple dimensions, our output data yis always a 1-dimensional\\nreal number when dealing with regression problems.\\nNow that we have some intuition for what linear regression is, a natural question arises: how\\ndo we \\x0cnd the optimal values for w? That is the remaining focus of this chapter.\\n2.5 Finding the Best Fitting Line\\n2.5.1 Objective Functions and Loss\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 16}),\n",
              " Document(page_content=\"Now that we've de\\x0cned our model as a weighted combination of our input variables, we need some\\nway to choose our value of w. To do this, we need an objective function .\\nDe\\x0cnition 2.5.1 (Objective Function): A function that measures the `goodness' of a model.\\nWe can optimize this function to identify the best possible model for our data.\\nAs the de\\x0cnition explains, the purpose of an objective function is to measure how good a speci\\x0cc\\nmodel is. We can therefore optimize this function to \\x0cnd a good model. Note that in the case of\\nlinear regression, our `model' is just a setting of our parameters w.\\nAn objective function will sometimes be referred to as loss. Loss actually measures how bad a\\nmodel is, and then our goal is to minimize it. It is common to think in terms of loss when discussing\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 16}),\n",
              " Document(page_content='linear regression, and we incur loss when the hyperplane we \\x0ct is far away from our data.\\nSo how do we compute the loss for a speci\\x0cc setting of w? To do this, we often use residuals .', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 16}),\n",
              " Document(page_content='2.5. FINDING THE BEST FITTING LINE 9\\nDe\\x0cnition 2.5.2 (Residual): The residual is the di\\x0berence between the target ( y) and predicted\\n(y(x;w)) value that a model produces:\\nresidual = target \\x00prediction = y\\x00f(x;w) =y\\x00wTx\\nCommonly, loss is a function of the residuals produced by a model. For example, you can imagine\\ntaking the absolute value of all of the residuals and adding those up to produce a measurement of\\nloss. This is sometimes referred to as L1 Loss . Or, you might square all of the residuals and then\\nadd those up to produce loss, which is called L2 loss orleast squares loss . You might also use some\\ncombination of L1 and L2 loss. For the most part, these are the two most common forms of loss\\nyou will see when discussing linear regression.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 17}),\n",
              " Document(page_content=\"When minimized, these distinct measurements of loss will produce solutions for wthat have\\ndi\\x0berent properties. For example, L2 loss is not robust to outliers due to the fact that we are\\nsquaring residuals. Furthermore, L2 loss will produce only a single solution while L1 loss can\\npotentially have many equivalent solutions. Finally, L1 loss produces unstable solutions, meaning\\nthat for small changes in our data set, we may see large changes in our solution w.\\nLoss is a concept that we will come back to very frequently in the context of supervised machine\\nlearning methods. Before exploring exactly how we use loss to \\x0ct a line, let's consider least squares\\nloss in greater depth.\\n2.5.2 Least Squares Loss\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 17}),\n",
              " Document(page_content='As we mentioned above, there are di\\x0berent methods for computing loss. One of the most commonly\\nused measurements is known as least squares or L2 loss . Least squares, as it is often abbreviated,\\nsays that the loss for a given data point is the square of the di\\x0berence between the target and\\npredicted values:\\nLn(w) = (y\\x00wTxn)2(2.4)\\n?The notationLn(w) is used to indicate the loss incurred by a model wfor a single data point ( xn, y).L(w) indicates\\nthe loss incurred for an entire data set by the model w. Be aware that this notation is sometimes inconsistent between\\ndi\\x0berent sources.\\nThere is a satisfying statistical interpretation for using this loss function which we will explain\\nlater in this chapter, but for now it will su\\x0ece to discuss some of the properties of this loss function', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 17}),\n",
              " Document(page_content='that make it desirable.\\nFirst, notice that it will always take on positive values. This is convenient because we can focus\\nexclusively on minimizing our loss, and it also allows us to combine the loss incurred from di\\x0berent\\ndata points without worrying about them cancelling out.\\nA more subtle but enormously important property of this loss function is that we know a lot\\nabout how to e\\x0eciently optimize quadratic functions. This is not a textbook about optimization,\\nbut some quick and dirty intuition that we will take advantage of throughout this book is that\\nwe can easily and reliably take the derivative of quadratic functions because they are continuously\\ndi\\x0berentiable. We also know that optima of a quadrative function will be located at points where', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 17}),\n",
              " Document(page_content='the derivative of the function is equal to 0, as seen in Figure 2.3. In contrast, L1 loss is not\\ncontinuously di\\x0berentiable over the entirety of its domain.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 17}),\n",
              " Document(page_content=\"10 CHAPTER 2. REGRESSION\\nFigure 2.3: Quadratic function with clear optimum at x= 2, where the derivative of the function\\nis 0.\\n2.6 Linear Regression Algorithms\\nNow that we have our least squares loss function, we can \\x0cnally begin to \\x0ct a line to our data. We\\nwill walk through the derivation of how this is done, in the process revealing the algorithm used\\nfor linear regression.\\n2.6.1 Optimal Weights via Matrix Di\\x0berentiation\\nFirst, we can de\\x0cne the loss incurred by parameters wover our entire data set Xas follows:\\nL(w) =1\\n2NX\\nn=1(yn\\x00wTxn)2(2.5)\\n?Note that we added a constant1\\n2to the beginning of our loss expression. This scales the loss, which will not change\\nour \\x0cnal result for the optimal parameters. It has the bene\\x0ct of making our calculations cleaner once we've taken\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 18}),\n",
              " Document(page_content='the gradient of the loss.\\nWe now want to solve for the values of wthat minimize this expression.\\nDerivation 2.6.1 (Least Squares Optimal Weights Derivation): We \\x0cnd the optimal\\nweights w\\x03as follows:\\nStart by taking the gradient of the loss with respect to our parameter w:\\nrL(w) =NX\\nn=1(yn\\x00wTxn)xT\\nn', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 18}),\n",
              " Document(page_content=\"2.6. LINEAR REGRESSION ALGORITHMS 11\\nSetting this gradient to 0, we have:\\n0 =NX\\nn=1ynxT\\nn\\x00wTNX\\nn=1xnxT\\nn (2.6)\\nAt this point, it is convenient to rewrite these summations as matrix operations in terms of w\\ninstead of wT. Note that ( wTPN\\nn=1xnxT\\nn)T=XTXwand (PN\\nn=1ynxT\\nn)T=XTY. Rewriting:\\n0 =XTY\\x00XTXw\\nSolving for w\\x03:\\nw\\x03= (XTX)\\x001XTY (2.7)\\nThe quantity ( XTX)\\x001XTin Derivation 2.6.1 has a special name: the Moore-Penrose pseudo\\ninverse . You can think of it as a generalization of a matrix inversion operation to a non-square\\nmatrix.\\n2.6.2 Bayesian Solution: Maximum Likelihood Estimation\\nWe've thus far been discussing linear regression exclusively in terms of a loss function that helps\\nus \\x0ct a set of weights to our data. In particular, we have been working with least squares, which\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 19}),\n",
              " Document(page_content=\"has nice properties that make it a reasonable loss function.\\nIn a very satisfying fashion, least squares also has a statistical foundation. In fact, you can\\nrecover the least squares loss function purely from a statistical derivation that we present here.\\nConsider our data set D=f(xi;yi)gN\\ni=1,xi2Rm,y2R. Let's imagine that our data was\\ngenerated according to the following process:\\nyi\\x18N(wTxi;\\x0c\\x001)\\nWhich can be written equivalently as:\\np(yijxi;w;\\x0c) =N(wTxi;\\x0c\\x001) (2.8)\\nThe interpretation of this is that our target value yis generated according to a linear combination\\nof our inputs x, but there is also some noise in the data generating process described by the variance\\nparameter\\x0c\\x001. It's an acknowledgement that some noise exists naturally in our data.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 19}),\n",
              " Document(page_content=\"?It's common to write variance as an inverse term, such as \\x0c\\x001. The parameter \\x0cis then known as the precision ,\\nwhich is sometimes easier to work with than the variance.\\nAs before, we now ask the question: how do we solve for the optimal weights w? One approach\\nwe can take is to maximize the probability of observing our target data Y. This technique is known\\nasmaximum likelihood estimation .\\nDerivation 2.6.2 (Maximum Likelihood Estimation for Bayesian Linear Regression):\\nThe likelihood of our data set is given by:\\np(YjX;w;\\x0c) =NY\\nn=1N(wTxn;\\x0c\\x001)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 19}),\n",
              " Document(page_content='12 CHAPTER 2. REGRESSION\\nWe then take the logarithm of the likelihood, and since the logarithm is a strictly increasing,\\ncontinuous function, this will not change our optimal weights w:\\nlnp(YjX;w;\\x0c) =NX\\nn=1lnN(wTxn;\\x0c\\x001)\\nUsing the density function of a univariate Gaussian:\\nlnp(YjX;w;\\x0c) =NX\\nn=1ln1p\\n2\\x19\\x0c\\x001e\\x00(yn\\x00wTxn)2=2\\x0c\\x001\\n=N\\n2ln\\x0c\\x00N\\n2ln (2\\x19)\\x00\\x0c\\n2NX\\nn=1(yn\\x00wTxn)2\\nNotice that this is a quadratic function in w, which means that we can solve for it by taking the\\nderivative with respect to w, setting that expression to 0, and solving for w:\\n@lnp(YjX;w;\\x0c)\\n@w=\\x0cNX\\nn=1(yn\\x00wTxn)xT\\nn\\n0 =\\x0cNX\\nn=1(yn\\x00wTxn)xT\\nn\\n0 =NX\\nn=1ynxT\\nn\\x00wTNX\\nn=1xnxT\\nn\\nNotice that this is exactly the same form as Equation 2.6. Solving for was before:\\nw\\x03= (XTX)\\x001XTY (2.9)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 20}),\n",
              " Document(page_content=\"Notice that our \\x0cnal solution is exactly the same form as the solution in Equation 2.7, which\\nwe solved for by minimizing the least squares loss! The takeaway here is that minimizing\\na least squares loss function is equivalent to maximizing the probability under the\\nassumption of a linear model with Gaussian noise .\\n2.6.3 Alternate Interpretation: Linear Regression as Projection\\nAnother common interpretation of linear regression is that of a projection of our targets, Y, onto\\nthe column space of our inputs X. This can be useful for building intuition.\\nWe showed above that the quantity ( XTX)\\x001XTcan be thought of as the pseudoinverse for\\nour inputs X. Let's now consider the case where Xis square and the pseudoinverse is equal to the\\ntrue inverse: X\\x001= (XTX)\\x001XT. We have for our optimal w\\x03:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 20}),\n",
              " Document(page_content='w\\x03= (XTX)\\x001XTY', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 20}),\n",
              " Document(page_content='2.7. MODEL FLEXIBILITY 13\\nwhich simpli\\x0ces as\\nw\\x03=X\\x001Y\\nWe can recover our target values Yby multiplying either side by X:\\nXw\\x03=XX\\x001Y\\nXw\\x03=Y\\nWe were able to recover our targets Yexactly because Xis an invertible tranformation. How-\\never, in the general case where Xis not invertible and we have to use the approximate pseudoinverse\\n(XTX)\\x001XT, we instead recover ^Y:\\nXw\\x03=X(XTX)\\x001XTY\\nXw\\x03=^Y\\nwhere ^Ycan be thought of as the closest projection of Yonto the column space of X.\\nFurthermore, this motivates the intuition that w\\x03is the set of coe\\x0ecients that best transforms\\nour input space Xinto our target values Y.\\n2.7 Model Flexibility\\nOccasionally, linear regression will fail to recover a good solution for a data set. While this may', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 21}),\n",
              " Document(page_content=\"be because our data doesn't actually have predictive power, it might also just indicate that our\\ndata is provided in a format unsuitable for linear regression. This section explores that problem, in\\nparticular focusing on how we can manipulate the \\rexibility of our models to make them perform\\nbetter.\\n2.7.1 Basis Functions\\nThere are some situations where linear regression is not the best choice of model for our input data\\nX. Because linear regression only scales and combines input variables, it is unable to apply more\\ncomplex transformations to our data such as a sinor square root function. In those situations where\\nwe need to transform our input variable somehow prior to performing linear regression (which is\\nknown as moving our data into a new basis ), we can apply a basis function .\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 21}),\n",
              " Document(page_content='De\\x0cnition 2.7.1 (Basis Function): Typically denoted by the symbol \\x1e(\\x01), a basis function is\\na transformation applied to an input data point xto move our data into a di\\x0berent input basis ,\\nwhich is another phrase for input domain .\\nFor example, consider our original data point:\\nx= (x(1);x(2))0\\nWe may choose our basis function \\x1e(x) such that our transformed data point in its new basis is:\\n\\x1e(x) = (x(1);x(1)2;x(2);sin(x(2)))0\\nUsing a basis function is so common that we will sometimes describe our input data points as\\n\\x1e= (\\x1e(1);\\x1e(2);:::;\\x1e(D))0.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 21}),\n",
              " Document(page_content=\"14 CHAPTER 2. REGRESSION\\nFigure 2.4: Data with no basis function applied.\\n?The notation x= (x(1);x(2))0is a way to describe the dimensions of a single data point x. The term x(1)is the\\n\\x0crst dimension of a data point x, while x1is the \\x0crst data point in a data set.\\nBasis functions are very general - they could specify that we just keep our input data the same.\\nAs a result, it's common to rewrite the least squares loss function from Equation 2.4 for linear\\nregression in terms of the basis function applied to our input data:\\nL(w) =1\\n2NX\\nn=1(yn\\x00wT\\x1en)2(2.10)\\nTo motivate why we might need basis functions for performing linear regression, let's consider\\nthis graph of 1-dimensional inputs Xalong with their target outputs Y, presented in Figure 2.4.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 22}),\n",
              " Document(page_content=\"As we can see, we're not going to be able to \\x0ct a good line to this data. The best we can hope\\nto do is something like that of Figure 2.5.\\nHowever, if we just apply a simple basis function to our data, in this case the square root\\nfunction,\\x1e(x) = (px1)0, we then have the red line in Figure 2.6. We now see that we can \\x0ct a very\\ngood line to our data, thanks to basis functions.\\nStill, the logical question remains: how can I choose the appropriate basis function? This toy\\nexample had a very obviously good basis function, but in general with high-dimensional, messy\\ninput data, how do we choose the basis function we need?\\nThe answer is that this is not an easy problem to solve. Often, you may have some domain\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 22}),\n",
              " Document(page_content=\"speci\\x0cc knowledge that tells you to try a certain basis, such as if you're working with chemical data\\nand know that an important equation involves a certain function of one of your inputs. However,\\nmore often than not we won't have this expert knowledge either. Later, in the chapter on neural\\nnetworks, we will discuss methods for discovering the best basis functions for our data automatically.\\n2.7.2 Regularization\\nWhen we introduced the idea of basis functions above, you might have wondered why we didn't\\njust try adding many basis transformations to our input data to \\x0cnd a good transformation. For\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 22}),\n",
              " Document(page_content='2.7. MODEL FLEXIBILITY 15\\nFigure 2.5: Data with no basis function applied, attempt to \\x0ct a line.\\nFigure 2.6: Data with square root basis function applied.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 23}),\n",
              " Document(page_content=\"16 CHAPTER 2. REGRESSION\\nFigure 2.7: Data set with a clear trend and Gaussian noise.\\nexample, we might use this large basis function on a D-dimensional data point z:\\n\\x1e(z) = (z(1);z(1)2;:::;z(1)100;z(2);z(2)2;:::;z(2)100;:::;z(D);z(D)2;:::;z(D)100)0\\nwhere you can see that we expand the dimensions of the data point to be 100 times its original\\nsize.\\nLet's say we have an input data point xthat is 1-dimensional, and we apply the basis function\\ndescribed above, so that after the transformation each data point is represented by 100 values. Say\\nwe have 100 data points on which to perform linear regression, and because our transformed input\\nspace has 100 values, we have 100 parameters to \\x0ct. In this case, with one parameter per data\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 24}),\n",
              " Document(page_content=\"point, it's possible for us to \\x0ct our regression line perfectly to our data so that we have no loss!\\nBut is this a desirable outcome? The answer is no, and we'll provide a visual example to illustrate\\nthat.\\nImagine Figure 2.7 is our data set. There is a very clear trend in this data, and you would likely\\ndraw a line that looks something like that of Figure 2.8 to \\x0ct it.\\nHowever, imagine we performed a large basis transformation like the one described above. If we\\ndo that, it's possible for us to \\x0ct our line perfectly, threading every data point, like that in Figure\\n2.9.\\nLet's see how both of these would perform on new data points. With our \\x0crst regression line,\\nif we have a new data point x= (10)0, we would predict a target value of 14.1, which most people\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 24}),\n",
              " Document(page_content=\"would agree is a pretty good measurement. However, with the second regression line, we would\\npredict a value of 9.5, which most people would agree does not describe the general trend in the\\ndata. So how can we handle this problem elegantly?\\nExamining our loss function, we see that right now we're only penalizing predictions that are\\nnot correct in training. However, what we ultimately care about is doing well on new data points,\\nnot just our training set. This leads us to the idea of generalization .\\nDe\\x0cnition 2.7.2 (Generalization): Generalization is the ability of a model to perform well on\\nnew data points outside of the training set.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 24}),\n",
              " Document(page_content='2.7. MODEL FLEXIBILITY 17\\nFigure 2.8: Natural \\x0ct for this data set.\\nFigure 2.9: Unnatural \\x0ct for this data set.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 25}),\n",
              " Document(page_content=\"18 CHAPTER 2. REGRESSION\\nA convoluted line that matches the noise of our training set exactly isn't going to generalize\\nwell to new data points that don't look exactly like those found in our training set. If wish to avoid\\nrecovering a convoluted line as our solution, we should also penalize the total size of our weights\\nw. The e\\x0bect of this is to discourage many complex weight values that produce a messy regression\\nline. By penalizing large weights, we favor simple regression lines like the one in Figure 2.8 that\\ntake advantage of only the most important basis functions.\\nThe concept that we are introducing, penalizing large weights, is an example of what's known as\\nregularization , and it's one that we will see come up often in di\\x0berent machine learning methods.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 26}),\n",
              " Document(page_content=\"De\\x0cnition 2.7.3 (Regularization): Applying penalties to parameters of a model.\\nThere is obviously a tradeo\\x0b between how aggressively we regularize our weights and how tightly\\nour solution \\x0cts to our data, and we will formalize this tradeo\\x0b in the next section. However, for\\nnow, we will simply introduce a regularization parameter \\x15to our least squares loss function:\\nL(w) =1\\n2NX\\nn=1(yn\\x00wT\\x1en)2+\\x15\\n2w2(2.11)\\nThe e\\x0bect of \\x15is to penalize large weight parameters. The larger \\x15is, the more we will favor\\nsimple solutions. In the limit lim \\x15!1L(w), we will drive all weights to 0, while with a nonexistant\\n\\x15= 0 we will apply no regularization at all. Notice that we're squaring our weight parameters -\\nthis is known as L2 norm regularization orridge regression . While L2 norm regularization is\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 26}),\n",
              " Document(page_content=\"very common, it is just one example of many ways we can perform regularization.\\nTo build some intuition about the e\\x0bect of this regularization parameter, examine Figure 2.10.\\nNotice how larger values of \\x15produce less complex lines, which is the result of applying more\\nregularization. This is very nice for the problem we started with - needing a way to choose which\\nbasis functions we wanted to use. With regularization, we can select many basis functions, and then\\nallow regularization to `prune' the ones that aren't meaningful (by driving their weight parameters\\nto 0). While this doesn't mean that we should use as many basis transformations as possible (there\\nwill be computational overhead for doing this), it does allow us to create a much more \\rexible\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 26}),\n",
              " Document(page_content=\"linear regression model without creating a convoluted regression line.\\n2.7.3 Generalizing Regularization\\nWe've thus far only discussed one form of regularization: ridge regression. Remember that under\\nridge regression, the loss function takes the form:\\nL(w) =1\\n2NX\\nn=1(yn\\x00wT\\x1en)2+\\x15\\n2w2\\nWhere the\\x15\\n2w2term is for the regularization. We can generalize our type of regularization by\\nwriting it as:\\nL(w) =1\\n2NX\\nn=1(yn\\x00wT\\x1en)2+\\x15\\n2\\x0c\\x0cw\\x0c\\x0ch\\nwherehdetermines the type of regularization we are using and thus the form of the optimal solu-\\ntion that we recover. The three most commonly used forms of regularization are lasso, ridge, and\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 26}),\n",
              " Document(page_content=\"2.7. MODEL FLEXIBILITY 19\\nFigure 2.10: E\\x0bect of di\\x0berent regularization parameter values on \\x0cnal regression solution.\\nelastic net.\\nRidge Regression\\nThis is the case of h= 2, which we've already discussed, but what type of solutions does it tend\\nto recover? Ridge regression prevents any individual weight from growing too large, providing us\\nwith solutions that are generally moderate.\\nLasso Regression\\nLasso regression is the case of h= 1. Unlike ridge regression, lasso regression will drive some\\nparameters wito zero if they aren't informative for our \\x0cnal solution. Thus, lasso regression is\\ngood if you wish to recover a sparse solution that will allow you to throw out some of your basis\\nfunctions. You can see the forms of ridge and lasso regression functions in Figure 2.11.\\nElastic Net\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 27}),\n",
              " Document(page_content=\"Elastic net is a middle ground between ridge and lasso regression, which it achieves by using a linear\\ncombination of the previous two regularization terms. Depending on how heavily each regulariza-\\ntion term is weighted, this can produce results on a spectrum between lasso and ridge regression.\\n2.7.4 Bayesian Regularization\\nWe've seen regularization in the context of loss functions, where the goal is to penalize large weight\\nvalues. How does the concept of regularization apply to Bayesian linear regression?\\nThe answer is that we can interpret regularizing our weight parameters as adding a prior\\ndistribution over w. Note that this is a di\\x0berent conception of regularization than we saw in the\\nprevious section. In the Bayesian framework, we are averaging over di\\x0berent models speci\\x0ced by\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 27}),\n",
              " Document(page_content='di\\x0berent values of w. Therefore, in this context regularization entails weighting models with smaller\\nvalues of wmore heavily.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 27}),\n",
              " Document(page_content=\"20 CHAPTER 2. REGRESSION\\nFigure 2.11: Form of the ridge (blue) and lasso (red) regression functions.\\nDerivation 2.7.1 (Bayesian Regularization Derivation): Because we wish to shrink our\\nweight values toward 0 (which is exactly what regularization does), we will select a Normal prior\\nwith mean 0 and variance S\\x001\\n0:\\nw\\x18N(0;S\\x001\\n0I)\\nRemember from Equation 2.8 that the distribution over our observed data is Normal as well, written\\nhere in terms of our entire data set:\\np(YjX;w;\\x0c) =N(Xw;\\x0c\\x001I)\\nWe want to combine the likelihood and the prior to recover the posterior distribution of w, which\\nfollows directly from Bayes' Theorem:\\np(wjX;Y;\\x0c)|{z}\\nposterior/p(YjX;w;\\x0c)|{z}\\nlikelihoodp(w)|{z}\\nprior\\nWe now wish to \\x0cnd the value of wthat maximizes the posterior distribution. We can maximize\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 28}),\n",
              " Document(page_content=\"the log of the posterior with respect to w, which simpli\\x0ces the problem slightly:\\nlnp(wjX;Y;\\x0c)/lnp(YjX;w;\\x0c) + lnp(w)\\nLet's handle ln p(YjX;w;\\x0c) \\x0crst:\\nlnp(YjX;w;\\x0c) = lnNY\\nn=1N(ynjwTxn;\\x0c\\x001)\\n= lnNY\\nn=11p\\n2\\x19\\x0c\\x001exp\\x1a\\n\\x00\\x0c\\n2(yn\\x00wTxn)2\\x1b\\n=C\\x00\\x0c\\n2NX\\nn=1(yn\\x00wTxn)2+1p\\n2\\x19\\x0c\\x001\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 28}),\n",
              " Document(page_content=\"2.8. CHOOSING BETWEEN MODELS 21\\nwhere Ccollects the constant terms that don't depend on w. Let's now handle ln p(w):\\nlnp(w) = lnN(0;S\\x001\\n0I)\\n= ln1\\n(j2\\x19S\\x001\\n0Ij)1\\n2exp\\x1a\\n\\x00S0\\n2wTw\\x1b\\n=C\\x00S0\\n2wTw\\ncombining the terms for ln p(YjX;w;\\x0c) and lnp(w):\\nlnp(wjX;Y;\\x0c) =\\x00\\x0c\\n2NX\\nn=1(yn\\x00wTxn)2\\x00S0\\n2wTw\\ndividing by a positive constant \\x0c:\\nlnp(wjX;Y;\\x0c) =\\x001\\n2NX\\nn=1(yn\\x00wTxn)2\\x00S0\\n\\x0c1\\n2wTw\\nNotice that maximizing the posterior probability is equivalent to minimizing the sum of squared\\nerrors (yn\\x00wTxn)2and the regularization term wTw.\\nThe interpretation of this is that adding a prior over the distribution of our weight\\nparameters w and then maximizing the resulting posterior distribution is equivalent\\nto adding a regularization term where \\x15=S0\\n\\x0c\\n2.8 Choosing Between Models\\n2.8.1 Bias-Variance Tradeo\\x0b and Decomposition\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 29}),\n",
              " Document(page_content=\"Now that you know about regularization, you might have some intuition for why we need to \\x0cnd\\na balance between complex and simple regression solutions. A complex solution, while it might \\x0ct\\nall of our training data, may not generalize well to future data points. On the other hand, a line\\nthat is too simple might not vary enough to provide good predictions at all. This phenomenon is\\nnot unique to linear regression- it's actually a very fundamental concept in machine learning that's\\nknown as the bias-variance tradeo\\x0b .\\nDe\\x0cnition 2.8.1 (Bias-Variance Tradeo\\x0b): When constructing machine learning models, we\\nhave a choice somewhere on a spectrum between two extremes: \\x0ctting exactly to our training data\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 29}),\n",
              " Document(page_content=\"or not varying in response to our training data at all. The \\x0crst extreme, \\x0ctting all of our training\\ndata, is a situation of high variance , because our output changes heavily in reponse to our input\\ndata (see the red line in Figure 2.10). At the other extreme, a solution that doesn't change in\\nresponse to our training data at all is a situation of high bias (see the yellow line in Figure 2.10).\\nThis means our model heavily favors a speci\\x0cc form regardless of the training data, so our target\\noutputs don't \\ructuate between distinct training sets.\\nObviously a good solution will fall somewhere in between these two extremes of high variance\\nand high bias. Indeed, we have techniques like regularization to help us balance the two extremes\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 29}),\n",
              " Document(page_content=\"22 CHAPTER 2. REGRESSION\\n(improving generalization), and we have other techniques like cross-validation that help us deter-\\nmine when we have found a good balance (measuring generalization).\\n?In case you are not familiar with the terms bias andvariance , we provide their statistical de\\x0cnitions here:\\nbias(\\x12) = E[\\x12]\\x00\\x12\\nvariance(\\x12) = E[(\\x12\\x00E[\\x12])2]\\nBefore we discuss how to e\\x0bectively mediate between these opposing forces of error in our models,\\nwe will \\x0crst show that the bias-variance tradeo\\x0b is not only conceptual but also has probabilistic\\nunderpinnings. Speci\\x0ccally, any loss that we incur over our training set using a given model can\\nbe described in terms of bias and variance, as we will demonstrate now.\\nDerivation 2.8.1 (Bias-Variance Decomposition): Let's begin by asserting that we have a\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 30}),\n",
              " Document(page_content='modelf(\\x01) that makes a prediction of our target ygiven input data point x. We wish to break\\ndown the squared error of finto terms involving bias and variance.\\nStart with the expected squared error (MSE), where the expectation is taken with respect to both\\nour data set D, which is a random variable of ( x,y) pairs sample from a distribution F, and our\\nconditional distribution yjx:\\nMSE = E[(y\\x00f(x))2]\\nFor reasons that will become clear in a few steps, add and subtract our target mean \\x16 y, which is the\\ntrue conditional mean given by \\x16 y= Eyjx[y], inside of the squared term:\\nMSE = E[(y\\x00\\x16y+ \\x16y\\x00f(x))2]\\nGroup together the \\x0crst two terms and the last two terms:\\nMSE = E[((y\\x00\\x16y) + (\\x16y\\x00f(x)))2]\\nExpanding this expression and using linearity of expectation:', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 30}),\n",
              " Document(page_content=\"MSE = E[(y\\x00\\x16y)2] + E[(\\x16y\\x00f(x))2] + 2E[(y\\x00\\x16y)(\\x16y\\x00f(x))] (2.12)\\nLet's examine the last term, 2E[( y\\x00\\x16y)(\\x16y\\x00f(x))]. Notice that (\\x16 y\\x00f(x)) does not depend on the\\nconditional distribution yjxat all. Thus, we are able to move one of those expecations in, which\\nmakes this term:\\n2E[(y\\x00\\x16y)(\\x16y\\x00f(x))] = 2ED[Eyjx[(y\\x00\\x16y)](\\x16y\\x00f(x))]\\nAnd note that:\\nEyjx[(y\\x00\\x16y)] = 0\\nWhich eliminates this last term entirely:\\n2E[(y\\x00\\x16y)(\\x16y\\x00f(x))] = 2ED[0\\x01(\\x16y\\x00f(x))] = 0\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 30}),\n",
              " Document(page_content=\"2.8. CHOOSING BETWEEN MODELS 23\\nWe can now write Equation 2.12 as:\\nMSE = E[(y\\x00\\x16y)2] + E[(\\x16y\\x00f(x))2] (2.13)\\nWe now have two terms contributing to our squared error. We will ignore the \\x0crst term E[( y\\x00\\x16y)2],\\nas this is unidenti\\x0cable noise in our data set. In other words, our data will randomly deviate\\nfrom the mean in ways we cannot predict. On the other hand, we can work with the second term\\nE[(\\x16y\\x00f(x))2] as it involves our model function f(\\x01)\\nAs before, for reasons that will become clear in a few steps, let's add and subtract our prediction\\nmean \\x16f(\\x01) = ED[f(x)], which is the expectation of our model function taken with respect to our\\nrandom data set.\\nE[(\\x16y\\x00f(x))2] = E[(\\x16y\\x00\\x16f(x) +\\x16f(x)\\x00f(x))2]\\nExpanding this squared term, we have:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 31}),\n",
              " Document(page_content='E[(\\x16y\\x00f(x))2] = (\\x16y\\x00\\x16f(x))2+ E[( \\x16f(x)\\x00f(x))2] + 2E[(\\x16y\\x00\\x16f(x))(\\x16f(x)\\x00f(x))]\\nAs before, the third term here is 0:\\n2E[(\\x16y\\x00\\x16f(x))(\\x16f(x)\\x00f(x))] = 2(\\x16y\\x00\\x16f(x))E[( \\x16f(x)\\x00f(x))] = 2(\\x16y\\x00\\x16f(x))(0) = 0\\nLeaving us with these two terms:\\nE[(\\x16y\\x00f(x))2] = (\\x16y\\x00\\x16f(x))2+ E[( \\x16f(x)\\x00f(x))2]\\nNotice the form of these two terms. The \\x0crst one, (\\x16 y\\x00\\x16f(x))2, is the squared bias of our model,\\nsince it is the square of the average di\\x0berence between our prediction and the true target value.\\nThe second one, E[( \\x16f(x)\\x00f(x))2], is the variance of our model, since it is the expected squared\\ndi\\x0berence between our model and its average value. Thus:\\nE[(y\\x00f(x))2] =bias(f(x))2+variance (f(x))\\nThus, our total squared error, plugging in to Equation 2.13 can be written as:\\nMSE =noise (x) +bias(f(x))2+variance (f(x))', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 31}),\n",
              " Document(page_content=\"24 CHAPTER 2. REGRESSION\\nFigure 2.12: Bias and variance both contribute to the overall error of our model.\\nThe key takeaway of the bias-variance decomposition is that the controllable error in our model\\nis given by the squared bias and variance. Holding our error constant, to decrease bias requires\\nincreasing the variance in our model, and vice-versa. In general, a graph of the source of error in\\nour model might look something like Figure 2.12.\\nFor a moment, consider what happens on the far left side of this graph. Our variance is very\\nhigh, and our bias is very low. In e\\x0bect, we're \\x0ctting perfectly to all of the data in our data set.\\nThis is exactly why we introduced the idea of regularization from before - we're \\x0ctting a very\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 32}),\n",
              " Document(page_content=\"convoluted line that is able to pass through all of our data but which doesn't generalize well to new\\ndata points. There is a name for this: over\\x0ctting .\\nDe\\x0cnition 2.8.2 (Over\\x0ctting): A phenomenon where we construct a convoluted model that is\\nable to predict every point in our data set perfectly but which doesn't generalize well to new data\\npoints.\\nThe opposite idea, under\\x0ctting , is what happens at the far right of the graph: we have high\\nbias and aren't responding to the variation in our data set at all.\\nDe\\x0cnition 2.8.3 (Under\\x0ctting): A phenomenon where we construct a model that doesn't re-\\nspond to variation in our data.\\nSo you can hopefully now see that the bias-variance tradeo\\x0b is important to managing the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 32}),\n",
              " Document(page_content=\"problem of over\\x0ctting and under\\x0ctting. Too much variance in our model and we'll over\\x0ct to our\\ndata set. Too much bias and we won't account for the trends in our data set at all.\\nIn general, we would like to \\x0cnd a sweet spot of moderate bias and variance that produces\\nminimal error. In the next section, we will explore how we \\x0cnd this sweet spot.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 32}),\n",
              " Document(page_content=\"2.8. CHOOSING BETWEEN MODELS 25\\n2.8.2 Cross-Validation\\nWe've seen that in choosing a model, we incur error that can be described in terms of bias and\\nvariance. We've also seen that we can regulate the source of error through regularization, where\\nheavier regularization increases the bias of our model. A natural question then is how do we know\\nhow much regularization to apply to achieve a good balance of bias and variance?\\nAnother way to look at this is that we've traded the question of \\x0cnding the optimal number of\\nbasis functions for \\x0cnding the optimal value of the regularization parameter \\x15, which is often an\\neasier problem in most contexts.\\nOne very general technique for \\x0cnding the sweet spot of our regularization parameter, other hy-\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 33}),\n",
              " Document(page_content='perparameters, or even for choosing among entirely di\\x0berent models is known as cross-validation .\\nDe\\x0cnition 2.8.4 (Cross-Validation): A subsampling procedure used over a data set to tune\\nhyperparameters and avoid over-\\x0ctting. Some portion of a data set (10-20% is common) is set aside,\\nand training is performed on the remaining, larger portion of data. When training is complete,\\nthe smaller portion of data left out of training is used for testing. The larger portion of data is\\nsometimes referred to as the training set , and the smaller portion is sometimes referred to as the\\nvalidation set .\\nCross-validation is often performed more than once for a given setting of hyperparameters to\\navoid a skewed set of validation data being selected by chance. In K-Folds cross-validation , you', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 33}),\n",
              " Document(page_content=\"perform cross-validation Ktimes, allocating1\\nKof your data for the validation set at each iteration.\\nLet's tie this back into \\x0cnding a good regularization parameter. For a given value of \\x15, we will\\nincur a certain amount of error in our model. We can measure this error using cross-validation,\\nwhere we train our model on the training set and compute the \\x0cnal error using the validation set.\\nTo \\x0cnd the optimal value for \\x15, we perform cross-validation using di\\x0berent values of \\x15, eventually\\nsettling on the value that produces the lowest \\x0cnal error. This will e\\x0bectively trade o\\x0b bias and\\nvariance, \\x0cnding the value of \\x15that minimizes the total error.\\nYou might wonder why we need to perform cross-validation at all - why can't we train on the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 33}),\n",
              " Document(page_content=\"entire data set and then compute the error over the entire data set as well?\\nThe answer is again over\\x0ctting. If we train over the entire data set and then validate our results\\non the exact same data set, we are likely to choose a regularization parameter that encourages our\\nmodel to conform to the exact variation in our data set instead of \\x0cnding the generalizable trends.\\nBy training on one set of data, and then validating on a completely di\\x0berent set of data, we\\nforce our model to \\x0cnd good generalizations in our data set. This ultimately allows us to pick\\nthe regularization term \\x15that \\x0cnds the sweet spot between bias and variance, over\\x0ctting and\\nunder\\x0ctting.\\n2.8.3 Making a Model Choice\\nNow that we're aware of over\\x0ctting, under\\x0ctting, and how those concepts relate to the bias-variance\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 33}),\n",
              " Document(page_content=\"tradeo\\x0b, we still need to come back to the question of how we actually select a model. Intuitively,\\nwe are trying to \\x0cnd the middle ground between bias and variance: picking a model that \\x0cts our\\ndata but that is also general enough to perform well on yet unseen data. Furthermore, there is\\nno such thing as the `right' model choice. Instead, there are only model options that are either\\nbetter or worse than others. To that end, it can be best to rely on the techniques presented above,\\nspeci\\x0ccally cross-validation, to make your model selection. Then, although you will not be able to\\nmake any sort of guarantee about your selection being the `best' of all possible models, you can at\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 33}),\n",
              " Document(page_content=\"26 CHAPTER 2. REGRESSION\\nleast have con\\x0cdence your model achieved the best generalizability that could be proven through\\ncross-validation.\\n2.8.4 Bayesian Model Averaging\\nWe can also handle model selection using a Bayesian approach. This means we account for our\\nuncertainty about the true model by averaging over the possible candidate models, weighting each\\nmodel by our prior certainty that it is the one producing our data. If we have Mmodels indexed\\nbym= 1;:::;M , we can write the likelihood of observing our data set Xas follows:\\np(X) =MX\\nm=1p(Xjm)p(m)\\nwherep(m) is our prior certainty for a given model and p(Xjm) is the likelihood of our data set\\ngiven that model. The elegance of this approach is that we don't have to pick any particular model,\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 34}),\n",
              " Document(page_content=\"instead choosing to marginalize out our uncertainty.\\n2.9 Linear Regression Extras\\nWith most of linear regression under our belt at this point, it's useful to drill down on a few concepts\\nto come to a deeper understanding of how we can use them in the context of linear regression and\\nbeyond.\\n2.9.1 Predictive Distribution\\nRemaining in the setting of Bayesian Linear Regression, we may wish to get a distribution over\\nour weights winstead of a point estimator for it using maximum likelihood. As we saw in Section\\n2.7.4, we can introduce a prior distribution over w, then together with our observed data, we can\\nproduce a posterior distribution over was desired.\\nDerivation 2.9.1 (Posterior Predictive Derivation): For the sake of simplicity and ease of\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 34}),\n",
              " Document(page_content=\"use, we will select our prior over wto be a Normal distribution with mean \\x160and variance S\\x001\\n0:\\np(w) =N(\\x160;S\\x001\\n0)\\nRemembering that the observed data is normally distributed, and accounting for Normal-Normal\\nconjugacy, our posterior distribution will be Normal as well:\\np(wjX;Y;\\x0c) =N(\\x16N;S\\x001\\nN)\\nwhere\\nSN= (S\\x001\\n0+\\x0cXTX)\\x001\\n\\x16N=SN(S\\x001\\n0\\x160+\\x0cXY)\\nWe now have a posterior distribution over w. However, usually this distribution is not what we\\ncare about. We're actually interested in making a point prediction for the target y\\x03given a new\\ninput x\\x03. How do we go from a posterior distribution over wto this prediction?\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 34}),\n",
              " Document(page_content=\"2.10. CONCLUSION 27\\nThe answer is using what's known as the posterior predictive overy\\x03given by:\\np(y\\x03jx\\x03;X;Y) =Z\\nwp(y\\x03jx\\x03;w)p(wjX;Y)dw\\n=N(y\\x03jwTx\\x03;\\x0c\\x001)N(wj\\x16N;S\\x001\\nN)dw(2.14)\\nThe idea here is to average the probability of y\\x03over all the possible setting of w,\\nweighting the probabilities by how likely each setting of w is according to its posterior\\ndistribution.\\n2.10 Conclusion\\nIn this chapter, we looked at a speci\\x0cc tool for handling regression problems known as linear regres-\\nsion. We've seen linear regression described in terms of loss functions, probabilistic expressions,\\nand geometric projections, which re\\rects the deep body of knowledge that we have around this\\nvery common technique.\\nWe've also discussed many concepts in this chapter that will prove useful in other areas of\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 35}),\n",
              " Document(page_content='machine learning, particularly for other supervised techniques: loss functions, regularization, bias\\nand variance, over and under\\x0ctting, posterior distributions, maximum likelihood estimation, and\\ncross-validation among others. Spending time to develop an understanding of these concepts now\\nwill pay o\\x0b going forward.\\nIt may or may not be obvious at this point that we are missing a technique for a very large class\\nof problems: those where the solution is not just a continuous, real number. How do we handle\\nsituations where we need to make a choice between di\\x0berent discrete options? This is the question\\nwe will turn to in the next chapter.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 35}),\n",
              " Document(page_content=\"Chapter 3\\nClassi\\x0ccation\\nIn the last chapter we explored ways of predicting a continuous, real-number target. In this chapter,\\nwe're going to think about a di\\x0berent problem- one where our target output is discrete-valued. This\\ntype of problem, one where we make a prediction by choosing between \\x0cnite class options, is known\\nasclassi\\x0ccation .\\n3.1 De\\x0cning the Problem\\nAs we did when studying regression, let's begin by thinking about the type of problems we are\\ntrying to solve. Here are a few examples of classi\\x0ccation tasks:\\n1. Predicting whether a given email is spam.\\n2. Predicting the type of object in an image.\\n3. Predicting whether a manufactured good is defective.\\nThe point of classi\\x0ccation is hopefully clear: we're trying to identify the most appropriate class for\\nan input data point.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 36}),\n",
              " Document(page_content=\"De\\x0cnition 3.1.1 (Classi\\x0ccation): A set of problems that seeks to make predictions about un-\\nobserved target classes given observed input variables.\\n3.2 Solution Options\\nThere are several di\\x0berent means by which we can solve classi\\x0ccation problems. We're going\\nto discuss three in this chapter: discriminant functions, probabilistic discriminative models (e.g.\\nlogistic regression), and probabilistic generative models. Note that these are not the only methods\\nfor performing classi\\x0ccation tasks, but they are similar enough that it makes sense to present\\nand explore them together. Speci\\x0ccally, these techniques all use some linear combination of input\\nvariables to produce a class prediction. For that reason, we will refer to these techniques as\\ngeneralized linear models .\\n28\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 36}),\n",
              " Document(page_content='3.3. DISCRIMINANT FUNCTIONS 29\\nML Framework Cube: Generalized Linear Models\\nSince we are using these techniques to perform classi\\x0ccation, generalized linear models deal with\\nadiscrete output domain. Second, as with linear regression, our goal is to make predictions on\\nfuture data points given an initial set of data to learn from. Thus, generalized linear models are\\nsupervised techniques. Finally, depending on the type of generalized linear model, they can be\\neither probabilistic or non-probabilistic .\\nDomain Training Probabilistic\\nDiscrete Supervised Yes / No\\n3.3 Discriminant Functions\\nGeneralized linear models for classi\\x0ccation come in several di\\x0berent \\ravors. The most straightfor-\\nward method carries over very easily from linear regression: discriminant functions . As we will', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 37}),\n",
              " Document(page_content=\"see, with discriminant functions we are linearly separating the input space into sections belonging\\nto di\\x0berent target classes. We will explore this method \\x0crst. One thing to keep in mind is that\\nit's generally easiest to initially learn these techniques in the case where we have only two target\\nclasses, but there is typically a generalization that allows us to handle the multi-class case as well.\\nAs with linear regression, discriminant functions h(x;w) seek to \\x0cnd a weighted combination of\\nour input variables to make a prediction about the target class:\\nh(x;w) =w(0)x(0)+w(1)x(1)+:::+w(D)x(D)(3.1)\\nwhere we are using the bias trick of appending x(0)= 1 to all of our data points.\\n3.3.1 Basic Setup: Binary Linear Classi\\x0ccation\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 37}),\n",
              " Document(page_content=\"The simplest use case for a discriminant function is when we only have two classes that we are\\ntrying to decide between. Let's denote these two classes 1and-1. Our discriminant function in\\nEquation 3.1 will then predict class 1ifh(x;w)\\x150 and class -1ifh(x;w)<0:\\n(\\n1 ifh(x;w)\\x150\\n\\x001 ifh(x;w)<0\\nGeometrically, the linear separation between these two classes then looks like that of Figure 3.1.\\nNotice the line where our prediction switches from class 1 to class -1. This is precisely where\\nh(x;w) = 0, and it is known as the decision boundary .\\nDe\\x0cnition 3.3.1 (Decision Boundary): The decision boundary is the line that divides the input\\nspace into di\\x0berent target classes. It is learned from an initial data set, and then the target class\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 37}),\n",
              " Document(page_content='of new data points can be predicted based on where they fall relative to the decision boundary. At\\nthe decision boundary, the discriminant function takes on a value of 0.\\n?You will sometimes see the term decision surface in place of decision boundary, particularly if the input space is\\nlarger than two dimensions.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 37}),\n",
              " Document(page_content=\"30 CHAPTER 3. CLASSIFICATION\\nFigure 3.1: Clear separation between classes.\\n3.3.2 Multiple Classes\\nNow consider the case that we have K > 2 classesC1;C2;:::;CKto choose between. One obvious\\napproach we might try is to use Kdi\\x0berent discriminant functions that each determine whether or\\nnot a given input is in that class Ck. This is known as a one-versus-all approach, and it doesn't work\\nproperly because we end up with ambiguous regions as demonstrated in Figure 3.2. Intuitively,\\nseveral of the discriminator functions could claim that a data point is a part of their class, which\\nis an undesirable result.\\nAnother obvious approach we might employ is to use\\x00K\\n2\\x01\\ndiscriminant functions that each\\ndetermine whether a given point is more likely to be in class Cjor classCk. This is known as a\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 38}),\n",
              " Document(page_content=\"one-versus-one approach, and it also doesn't work because we again end up with ambiguous regions\\nas demonstrated in Figure 3.3.\\nInstead, we can avoid these ambiguities in the multi-class case by using Kdi\\x0berent linear\\nclassi\\x0cershk(x;wk), and then assigning new data points to the class Ckfor whichhk(x;wk)>\\nhj(x;wj) for allj6=k. Then, similar to the two-class case, the decision boundaries are described\\nby the surface along which hk(x;wk) =hj(x;wj).\\nNow that we've explored the multi-class generalization, we can consider how to learn the weights\\nwthat de\\x0cne the optimal discriminant functions. However, prior to solving for w, we need to discuss\\nhow basis transformations apply to classi\\x0ccation problems.\\n3.3.3 Basis Changes in Classi\\x0ccation\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 38}),\n",
              " Document(page_content=\"We initially discussed basis changes in the context of linear regression, and they are equally impor-\\ntant for classi\\x0ccation tasks. For example, consider the data set in Figure 3.4.\\nIt's obviously not possible for us to use a linear classi\\x0cer to separate this data set. However, if\\nwe apply a basis change by squaring one of the data points, we instead have Figure 3.5, which is\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 38}),\n",
              " Document(page_content='3.3. DISCRIMINANT FUNCTIONS 31\\nFigure 3.2: Ambiguities arise from one-versus-all method.\\nFigure 3.3: Ambiguities arise from one-versus-one method.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 39}),\n",
              " Document(page_content='32 CHAPTER 3. CLASSIFICATION\\nFigure 3.4: Data set without any basis functions applied, not linearly separable.\\nnow linearly separable by a plane between the two classes. Applying a generic basis change \\x1e(\\x01),\\nwe can write our generalized linear model as:\\nhk(x;wk) =wT\\nk\\x1e(x) =wT\\nk\\x1e (3.2)\\nFor the sake of simplicity in the rest of this chapter, we will leave out any basis changes in our\\nderivations, but you should recognize that they could be applied to any of our input data to make\\nthe problems more tractable.\\n?For an input matrix X, there is a matrix generalization of our basis transformed inputs: \\x08=\\x1e(X), where \\x08is\\nknown as the design matrix .\\n3.4 Numerical Parameter Optimization and Gradient Descent', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 40}),\n",
              " Document(page_content=\"Recall from the previous chapter on linear regression that when it comes to optimizing our model's\\nweight parameters w, the goal is to minimize our loss function L(w) (also called the objective\\nfunction). We did this by taking the derivative of our objective function with respect to w, setting\\nthat expression equal to 0, and solving for w. We were previously able to perform that procedure\\nwith con\\x0cdence because the least squares loss function was convex with respect to the weight\\nparameters, which meant it had a global solution we could solve for directly. Thus, the point of\\nminimization for the objective function would occur where rL(w) = 0.\\nUnfortunately, it's not always the case that our objective function will be convex with respect\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 40}),\n",
              " Document(page_content='to our weight parameters. In fact, in the next section, we will consider an objective function that\\nis not convex, and as a result we will need a new way to optimize our parameters. Typically, when\\nfacing a non-convex objective function, we will need to resort to a numerical procedure.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 40}),\n",
              " Document(page_content='3.4. NUMERICAL PARAMETER OPTIMIZATION AND GRADIENT DESCENT 33\\nFigure 3.5: Data set with basis functions applied, now linearly separable.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 41}),\n",
              " Document(page_content=\"34 CHAPTER 3. CLASSIFICATION\\nFigure 3.6: Step Size in Gradient Descent.\\n?The terms numerical andanalytical procedures come up very frequently in machine learning literature. An analytical\\nsolution typically utilizes a closed form equation that accepts your model and input data and returns a solution in\\nthe form of optimized model parameters. On the other hand, numerical solutions are those that require some\\nsort of iteration to move toward an ever better solution, eventually stopping once the solution is deemed `good\\nenough'. Analytical solutions are typically more desirable than numerical solutions due to computational e\\x0eciency\\nand performance guarantees, but they often are not possible for complex problems due to non-convexity.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 42}),\n",
              " Document(page_content='Gradient descent is one such numerical optimization technique.\\n3.4.1 Gradient Descent\\nDe\\x0cnition 3.4.1 (Gradient Descent): Gradient descent is a numerical, iterative optimization\\ntechnique for \\x0cnding the minimum of a function. It is often used to \\x0ct complex model parameters.\\nThe high level idea behind gradient descent is as follows: to update our parameters, we take\\na small step in the opposite direction of the gradient of our objective function with respect to the\\nweight parameters w(t). Notationally, this looks like the following:\\nw(t+1)=w(t)\\x00\\x11rL(w(t)) (3.3)\\nwhere w(t)corresponds to the state of the parameters wat timet,L(w(t)) is the gradient of our\\nobjective function, and \\x11 > 0 is known as the learning rate . Note that the parameter values at', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 42}),\n",
              " Document(page_content='timet= 0 given by w(0)are often initialized randomly.\\n?In general, we want a learning rate that is large enough so that we make progress toward reaching a better solution,\\nbut not so large that we take a step that puts us in a worse place in the parameter space than we were at the previous\\nstep. Notice in Figure 3.6 that an appropriately small step size improves our objective function, while a large step\\nsize overshoots the update and leaves us in a worse position.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 42}),\n",
              " Document(page_content=\"3.5. OBJECTIVES FOR DECISION BOUNDARIES 35\\nWhy take a step in the opposite direction of the gradient of the objective function? You can\\nthink of the objective function as a hill, and the current state of our parameters w(t)is our position\\non that hill. The gradient tells us the steepest direction of increase in the objective function (i.e.\\nit speci\\x0ces the direction that will make our model worse). Since we want to minimize the objective\\nfunction, we choose to move away from the direction of the gradient, sending our model down the\\nhill towards an area of lower error. We typically cease optimization when our updates become\\nsu\\x0eciently small, indicating that we've reached a local minimum. Note that it's a good idea to run\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 43}),\n",
              " Document(page_content='gradient descent multiple times to settle on a \\x0cnal value for w, ideally initializing w(0)to a di\\x0berent\\nstarting value each time, because we are optimizing a function with multiple local minima.\\n3.4.2 Batch Gradient Descent versus Stochastic Gradient Descent\\nThere are di\\x0berent means by which we can compute the gradient of our objective function at each\\nstep. The \\x0crst way, often called batch gradient descent , computes the gradient for our objective\\nfunction at each step using the entire data set. In contrast, the technique known as stochastic\\ngradient descent (also known as SGD) utilizes a subset of the data points at each step to compute\\nthe gradient, sometimes just a single data point. Stochastic gradient descent is typically a more', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 43}),\n",
              " Document(page_content=\"popular technique for several reasons. First, the computation time is often signi\\x0ccantly smaller as\\nyou don't need to pass over the entire data set at each iteration. Furthermore, it's less likely that\\nyou will get stuck in local minima while running SGD because a point in the parameter space that\\nis a local minima for the entire data set combined is much less likely to be a local minima for each\\ndata point individually. Finally, SGD lends itself to being used for training online models (meaning\\nmodels built on data points that are arriving at regular intervals) as the entirety of the data does\\nnot need to be present in order to train.\\n3.5 Objectives for Decision Boundaries\\nNow that we have a high-level understanding of what we're trying to accomplish with discriminant\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 43}),\n",
              " Document(page_content='functions as well as a grasp on gradient descent, we can consider how to solve for the decision\\nboundaries that will dictate our classi\\x0ccation decisions. Similar to linear regression, we \\x0crst need\\nto establish an objective function to optimize. We begin with a very simple objective function\\nknown as 0/1 loss .\\n3.5.1 0/1 Loss\\nRecall that a loss function penalizes mistakes made by our model. The idea behind the 0/1 loss\\nfunction is very simple: if our model misclassi\\x0ces a point, we incur a loss of 1, and if our model\\nclassi\\x0ces it correctly, we incur no loss.\\nWhile this is a very intuitive loss function, it does not have a closed form solution like least\\nsquares does, and it is non-convex so it is not easily optimized. Intuitively, because we incur a loss', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 43}),\n",
              " Document(page_content=\"of 0 or 1 for every prediction, we have no sense of `how good' a given prediction was. For example,\\none prediction could be very close to correct, while another could be way o\\x0b, but they would both\\nreceive an equivalent loss of 1. Formally, because this loss function is not di\\x0berentiable, we cannot\\nget gradient information with which to optimize our model parameters w. We will \\x0cnd a way\\naround this in a moment when we discuss hinge loss , but before we get to that, let's consider\\nusing least squares loss as we did for linear regression.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 43}),\n",
              " Document(page_content=\"36 CHAPTER 3. CLASSIFICATION\\n3.5.2 Least Squares Loss\\nWe are already familiar with the least squares loss function from linear regression, and we can\\napply it again in this context to \\x0cnd the set of weights wthat form the optimal decision boundary\\nbetween target classes.\\nWe \\x0crst need to introduce the idea of one-hot encoding , which simply means that the class\\nof a given data point is described by a vector with Koptions that has a 1 in the position that\\ncorresponds to class Ckand 0s everywhere else (note that these classes aren't usually 0-indexed).\\nFor example, class C1of 4 classes would be represented by the vector:\\n2\\n6641\\n0\\n0\\n03\\n775(3.4)\\nWhile class C2would be represented by the vector:\\n2\\n6640\\n1\\n0\\n03\\n775(3.5)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 44}),\n",
              " Document(page_content='and so on. Now that we have the idea of one-hot encoding, we can describe our target classes\\nfor each data point in terms of a one-hot encoded vector, which can then be used in our training\\nprocess for least squares.\\nEach classCkgets its own linear function with a di\\x0berent set of weights wk:\\nhk(x;wk) =wT\\nkx\\nWe can combine the set of weights for each class into a matrix W, which gives us our linear classi\\x0cer:\\nh(x;W) =WTx (3.6)\\nwhere each row in the weight matrix Wcorresponds to the linear function of an individual class.\\nWe can use the results derived in the last chapter to \\x0cnd the solution for Wthat minimizes the\\nleast squares loss function. Assuming a data set of input data points Xand one-hot encoded target', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 44}),\n",
              " Document(page_content=\"vectors Y(where every row is a single target vector), the optimal solution for Wis given by:\\nW\\x03= (XTX)\\x001XTY\\nwhich we can then use in our discriminant function h(x;W\\x03) to make predictions on new data\\npoints.\\nWhile least squares gives us an analytic solution for our discriminant function, it also has some\\nsigni\\x0ccant limitations. For one, least squares penalizes data points that are `too good', meaning\\nthey fall too far on the correct side of the decision boundary. Furthermore, it is not robust to\\noutliers, meaning the decision boundary signi\\x0ccantly changes with the addition of just a few outlier\\ndata points, as seen in Figure 3.7.\\nWe can help remedy the problems with least squares by using an alternative loss function for\\ndetermining our weight parameters.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 44}),\n",
              " Document(page_content=\"3.5. OBJECTIVES FOR DECISION BOUNDARIES 37\\nFigure 3.7: Outliers signi\\x0ccantly impact our decision boundary.\\nFigure 3.8: Form of the ReLU function.\\n3.5.3 Hinge Loss\\nRecall that the problem with 0/1 loss was that we couldn't use it optimize our model parameters\\nw. It didn't produce a closed form solution like least squares loss, and it wasn't di\\x0berentiable so\\nwe couldn't take gradients.\\nThe hinge loss function is a modi\\x0ccation of the 0/1 loss function that both provides more \\x0cne-\\ngrained information about the `goodness' of a prediction and makes the loss function di\\x0berentiable.\\nTo understand the hinge loss function, it's \\x0crst necessary to introduce the recti\\x0ced linear activation\\nunit, known as ReLU, seen in Figure 3.8.\\nReLU(z) = maxf0;zg (3.7)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 45}),\n",
              " Document(page_content=\"We can use the form of this function to our advantage in constructing the hinge loss by recognizing\\nthat we wish to incur error when we're wrong (which corresponds to z > 0, the right side of\\nthe graph that is continuously increasing), and we wish to incur 0 error if we are correct (which\\ncorresponds to the left side of the graph where z<0).\\nRemember from the previous section on least squares that in the two-class case, we classify a\\ndata point x\\x03as being from class 1ifh(x\\x03;w)\\x150, and class -1otherwise. We can combine this\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 45}),\n",
              " Document(page_content='38 CHAPTER 3. CLASSIFICATION\\nlogic with ReLU by recognizing that \\x00h(x\\x03;w)y\\x03\\x150 when there is a classi\\x0ccation error, where\\ny\\x03is the true class of data point x\\x03. This has exactly the properties we described above: we incur\\nerror when we misclassify, and otherwise we do not incur error.\\nWe can then write the entirety of the hinge loss function:\\nL(w) =NX\\ni=1ReLU(\\x00h(xi;w)yi) (3.8)\\n=\\x00NX\\nyi6=^yih(xi;w)yi (3.9)\\n=\\x00NX\\nyi6=^yiwTxiyi (3.10)\\nwhere ^yiis our class prediction and yiis the true class value. Notice that misclassi\\x0ced examples\\ncontribute positive loss, as desired. We can take the gradient of this loss function, which will allow\\nus to optimize it using stochastic gradient descent. The gradient of the loss with respect to our\\nparameters wis as follows:\\n@L(w)\\n@w=\\x00NX\\nyi6=^yixiyi', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 46}),\n",
              " Document(page_content=\"and then our update equation from time tto timet+ 1 for a single misclassi\\x0ced example and with\\nlearning rate \\x11is given by:\\nw(t+1)=w(t)\\x00\\x11@L(w)\\n@w=w(t)+\\x11xiyi\\nTo sum up, the bene\\x0cts of the hinge loss function are its di\\x0berentiability (which allows us to\\noptimize our weight parameters), the fact that it doesn't penalize any correctly classi\\x0ced data\\npoints (unlike basic linear classi\\x0ccation), and that it penalizes more heavily data points that are\\nmore poorly misclassi\\x0ced.\\nUsing hinge loss with discriminant functions to solve classi\\x0ccation tasks (and applying stochastic\\ngradient descent to optimize the model parameters) is known as the perceptron algorithm . The\\nperceptron algorithm guarantees that if there is separability between all of our data points and we\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 46}),\n",
              " Document(page_content='run the algorithm for long enough, we will \\x0cnd a setting of parameters that perfectly separates our\\ndata set. The proof for this is beyond the scope of this textbook.\\n3.6 Probabilistic Methods\\nUnsurprisingly, we can also cast the problem of classi\\x0ccation into a probabilistic context, which\\nwe now turn our attention to. Within this setting, we have a secondary choice to make between\\ntwo distinct probabilistic approaches: discriminative or generative. We will explore both of these\\noptions.\\n3.6.1 Probabilistic Discriminative Models\\nUltimately, our classi\\x0ccation task can be summarized as follows: given a new data point x\\x03, can\\nwe accurately predict the target class y\\x03?', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 46}),\n",
              " Document(page_content=\"3.6. PROBABILISTIC METHODS 39\\nGiven this problem statement, it makes sense that we might try to model p(y\\x03jx\\x03). In fact,\\nmodeling this conditional distribution directly is what's known as probabilistic discriminative\\nmodeling .\\nDe\\x0cnition 3.6.1 (Probabilistic Discriminative Modeling): Probabilistic modeling is a clas-\\nsi\\x0ccation technique whereby we choose to directly model the conditional class distribution in order\\nto make classi\\x0ccation predictions.\\nThis means that we will start with the functional form of the generalized linear model described\\nby Equation 3.2, convert this to a conditional distribution, and then optimize the parameters of\\nthe conditional distribution directly using a maximum likelihood procedure. From here, we will be\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 47}),\n",
              " Document(page_content='able to make predictions on new data points x\\x03. The key feature of this procedure, which is known\\nasdiscriminative training , is that it optimizes the parameters of a conditional distribution directly.\\nWe describe a speci\\x0cc, common example of this type of procedure called logistic regression in\\nthe next section.\\nLogistic Regression\\nOne problem we need to face in our discriminative modeling paradigm is that the results of our\\ngeneralized linear model are not probabilities; they are simply real numbers. This is why in the\\nprevious paragraph we mentioned needing to convert our generalized linear model to a conditional\\ndistribution. That step boils down to somehow squashing the outputs of our generalized linear', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 47}),\n",
              " Document(page_content='model onto the real numbers between 0 and 1, which will then correspond to probabilities. To do\\nthis, we will apply what is known as the logistic sigmoid function ,\\x1b(\\x01).\\nDe\\x0cnition 3.6.2 (Logistic Sigmoid Function, \\x1b(\\x01)):The logistic sigmoid function is commonly\\nused to compress the real number line down to values between 0 and 1. It is de\\x0cned functionally\\nas:\\n\\x1b(z) =1\\n1 + exp (\\x00z)\\nAs you can see in Figure 3.9 where the logistic sigmoid function is graphed, it squashes our output\\ndomain between 0 and 1 as desired for a probability.\\n?There is a more satisfying derivation for our use of the logistic sigmoid function in logistic regression, but under-\\nstanding its squashing properties as motivation is su\\x0ecient for the purposes of this book.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 47}),\n",
              " Document(page_content=\"Using the logistic sigmoid function, we now have a means of generating a probability that a new\\ndata point x\\x03is part of class y\\x03. Because we are currently operating in the two-class case, which\\nin this context will be denoted C1andC2, we'll write the probability for each of these classes as:\\np(y\\x03=C1jx\\x03) =\\x1b(wTx\\x03)\\np(y\\x03=C2jx\\x03) = 1\\x00p(y\\x03=C1jx\\x03)\\nNow that we have such functions, we can apply the maximum likelihood procedure to determine\\nthe optimal parameters for our logistic regression model.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 47}),\n",
              " Document(page_content=\"40 CHAPTER 3. CLASSIFICATION\\nFigure 3.9: Logistic Sigmoid Function.\\nFor a data setfxi;yigwherei= 1::Nandyi2f0;1g, the likelihood for our setting of parameters\\nwcan be written as:\\np(fyigN\\ni=1jw) =NY\\ni=1^yyi\\nif1\\x00^yig1\\x00yi(3.11)\\nwhere ^yi=p(yi=C1jxi) =\\x1b(wTxi).\\nIn general, we would like to maximize this probability to \\x0cnd the optimal setting of our param-\\neters. This is exactly what we intend to do, but with two further simpli\\x0ccations. First, we're going\\nto maximize the probability of the logarithm of the likelihood, as in Equation 3.12.\\nln(p(fyigN\\ni=1jw)) =NX\\ni=1fyiln ^yi+ (1\\x00yi) ln (1\\x00^yi)g (3.12)\\nAs a monotonically increasing function, maximizing the logarithm of the likelihood (called the\\nlog likelihood ) will result in the same optimal setting of parameters as if we had just optimized\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 48}),\n",
              " Document(page_content=\"the likelihood directly. Furthermore, using the log likelihood has the nice e\\x0bect of turning what\\nis currently a product of terms from 1 ::Nto a sum of terms from 1 ::N, which will make our\\ncalculations nicer.\\nSecond, we will turn our log likelihood into an error function by taking the negative of our log\\nlikelihood expression. Now, instead of maximizing the log likelihood, we will be minimizing the\\nerror function, which will again \\x0cnd us the same setting of parameters.\\n?It's worth rereading the above paragraph again to understand the pattern presented there, which we will see several\\ntimes throughout this book. Instead of maximizing a likelihood function directly, it is often easier to de\\x0cne an error\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 48}),\n",
              " Document(page_content='function using the negative log likelihood, which we can then minimize to \\x0cnd the optimal setting of parameters for\\nour model.\\nAfter taking the negative logarithm of the likelihood function de\\x0cned by Equation 3.11, we\\nare left with the following term, known as the cross-entropy error function , which we will seek to', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 48}),\n",
              " Document(page_content=\"3.6. PROBABILISTIC METHODS 41\\nminimize:\\nE(w) =\\x00lnp(fyigjw) =\\x00NX\\ni=1fyiln ^yi+ (1\\x00yi) ln (1\\x00^yi)g (3.13)\\nwhere as before ^ yi=p(yi=C1jxi) =\\x1b(wTxi). Now, to solve for the optimal setting of parameters\\nusing a maximum likelihood approach as we've done previously, we start by taking the gradient of\\nthe cross-entropy error function with respect to w:\\nrE(w) =NX\\ni=1(^yi\\x00yi)xi (3.14)\\nwhich we arrive at by recognizing that the derivative of the logistic sigmoid function can be written\\nin terms of itself as:\\n@\\x1b(z)\\n@z=\\x1b(z)(1\\x00\\x1b(z))\\nLet's inspect the form of Equation 3.14 for a moment to understand its implications. First, it's\\na summation over all of our data points, as we would expect. Then, for each data point, we are\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 49}),\n",
              " Document(page_content='taking the di\\x0berence between our predicted value ^ yiand the actual value yi, and multiplying that\\ndi\\x0berence by the input vector xi.\\nWhile a closed form solution does not present itself here as it did in the case of linear regression\\ndue to the nonlinearity of the logistic sigmoid function, we can still optimize the parameters wof\\nour model using an iterative procedure like gradient descent, where the objective function is de\\x0cned\\nby Equation 3.13.\\nMulti-Class Logistic Regression and Softmax\\nAs we saw when working with discriminant functions, we also need to account for multi-class\\nproblems, which are practically speaking more common than the simple two-class scenario.\\nIn the logistic regression setting (which is a form of discriminative modeling , not to be confused', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 49}),\n",
              " Document(page_content=\"with discriminant functions ), we are now working with probabilities, which is why we introduced the\\n`probability squashing' sigmoidal function \\x1b(\\x01). Note that the sigmoidal function is also sometimes\\nknown as the sigmoidal activation function.\\nSimilarly, in the multi-class logistic regression setting, we would like to also have a probabil-\\nity squashing function that generalizes beyond two classes. This generalization of the sigmoidal\\nfunction is known as softmax .\\nDe\\x0cnition 3.6.3 (Softmax): Softmax is the multi-class generalization of the sigmoidal activa-\\ntion function. It accepts a vector of activations (inputs) and returns a vector of probabilities\\ncorresponding to those activations. It is de\\x0cned as follows:\\nsoftmaxk(z) =exp (zk)PK\\ni=1exp (zi), for allk\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 49}),\n",
              " Document(page_content='Multi-class logistic regression uses softmax over a vector of activations to select the most likely\\ntarget class for a new data point. It does this by applying softmax and then assigning the new data\\npoint to the class with the highest probability.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 49}),\n",
              " Document(page_content=\"42 CHAPTER 3. CLASSIFICATION\\nExample 3.1 (Softmax Example): Consider an example that has three classes: C1;C2;C3. Let's\\nsay we have an activation vector zfor our new data point xthat we wish to classify, given by:\\nz=WTx=2\\n44\\n1\\n73\\n5\\nwhere\\nzj=wT\\njx\\nThen, using our de\\x0cnition of softmax, we have:\\nsoftmax( z) =2\\n40:047\\n0:002\\n0:9503\\n5\\nAnd therefore, we would assign our new data point xto classC3, which has the largest activation.\\nAs in the two-class logistic regression case, we now need to solve for the parameters Wof our\\nmodel, also written as fwjg. Assume we have an observed data set fxi;yigfori= 1::Nwhere yi\\nare one-hot encoded target vectors. We begin this process by writing the likelihood for our data,\\nwhich is only slightly modi\\x0ced here to account for multiple classes:\\np(fyigN\\ni=1jW) =NY\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 50}),\n",
              " Document(page_content='i=1KY\\nj=1p(yi=Ckjxi)yij=NY\\ni=1KY\\nj=1^yyij\\nij (3.15)\\nwhere ^yij= softmax j(Wxi)\\nWe can now take the negative logarithm to get the cross-entropy error function for the multi-\\nclass classi\\x0ccation problem:\\nE(W) =\\x00lnp(fyigN\\ni=1jW) =\\x00NX\\ni=1KX\\nj=1yijln ^yij (3.16)\\nAs in the two-class case, we now take the gradient with respect to one of our weight parameter\\nvectors wj:\\nrwjE(W) =NX\\ni=1(^yij\\x00yij)xi (3.17)\\nwhich we arrived at by recognizing that the derivative of the softmax function with respect to the\\ninput activations zjcan be written in terms of itself:\\n@softmaxk(z)\\n@zj= softmax k(z)(Ikj\\x00softmaxj(z))\\nwhere I is the identity matrix.\\nAs in the two-class case, now that we have this gradient expression, we can use an iterative\\nprocedure like gradient descent to optimize our parameters W.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 50}),\n",
              " Document(page_content=\"3.6. PROBABILISTIC METHODS 43\\n3.6.2 Probabilistic Generative Models\\nWith the probabilistic discriminative modeling approach, we elected to directly model the class-\\nconditional probability p(y\\x03jx\\x03). However, there was an alternative option: we could have instead\\nmodeled the joint distribution of the class y\\x03and the input data point x\\x03together as p(y\\x03;x\\x03). This\\napproach is what's known as probabilistic generative modeling because we actually model the\\nprocess by which the data was generated.\\nTo model the data generating process in classi\\x0ccation tasks generally acknowledges that a data\\npoint is produced by \\x0crst selecting a class y\\x03from a categorical class prior p(y\\x03) and then generating\\nthe data point x\\x03itself from the class-conditional distribution p(y\\x03jx\\x03), the form of which is problem\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 51}),\n",
              " Document(page_content='speci\\x0cc. This generative approach is a particularly good idea if we want to create more data (by\\nsampling from the joint distribution) or if we have some sort of expert knowledge about how the\\ndata was generated, which can make our model more powerful than the discriminative approach.\\n?Notice that with probabilistic generative modeling, we choose a speci\\x0cc distribution for our class-conditional\\ndensities instead of simply using a generalized linear model combined with a sigmoid/softmax function as we did\\nin the logistic regression setting. This highlights the di\\x0berence between discriminative and generative modeling: in\\nthe generative setting, we are modeling the production of the data itself instead of simply optimizing the parameters', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 51}),\n",
              " Document(page_content=\"of a more general model that predicts class membership directly.\\nClassi\\x0ccation in the Generative Setting\\nNow that we're situated in the generative setting, we turn our attention to the actual problem of\\nusing our model to predict class membership of new data points x\\x03.\\nTo perform classi\\x0ccation, we will pick the class Ckthat maximizes the probability of x\\x03being\\nfrom that class as de\\x0cned by p(y\\x03=Ckjx\\x03). We can relate this conditional density to the joint\\ndensityp(y\\x03;x\\x03) through Bayes' Rule:\\np(y\\x03=Ckjx\\x03) =p(y\\x03;x\\x03)\\np(x\\x03)=p(x\\x03jy\\x03=Ck)p(y\\x03=Ck)\\np(x\\x03)/p(x\\x03jy\\x03=Ck)p(y\\x03=Ck)\\nwherep(x\\x03) is a constant that can be ignored as it will be the same for every conditional probability\\np(y\\x03=Ckjx\\x03).\\nRecall that the class prior p(y) will always be a categorical distribution (the multi-class general-\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 51}),\n",
              " Document(page_content=\"ization of the Bernoulli distribution), while the class-conditional distribution can be speci\\x0ced using\\nprior knowledge of the problem domain. Once we have speci\\x0ced this class conditional distribution,\\nwe can solve for the parameters of both that model and the categorical distribution by optimizing\\nthe likelihood function. Let's now derive that likelihood function.\\nDerivation 3.6.1 (Probabilistic Generative Model Likelihood Function):\\nWe're going to derive the likelihood function for the parameters of our probabilistic generative\\nmodel in the two-class setting, allowing that the multi-class generalization will be a straightforward\\nexercise.\\nLet's start by assuming a Gaussian conditional distribution for our data p(xjy=Ck). Given a data\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 51}),\n",
              " Document(page_content=\"setfxi;yigfori= 1::N, whereyi= 1 corresponds to class C1andyi= 0 corresponds to class C2,\\nwe can construct our maximum likelihood solution. Let's \\x0crst specify our class priors:\\np(C1) =\\x19\\np(C2) = 1\\x00\\x19\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 51}),\n",
              " Document(page_content=\"44 CHAPTER 3. CLASSIFICATION\\nFor simplicity, we'll assume a shared covariance matrix \\x06between our two classes. Then, for data\\npoints xifrom classC1, we have:\\np(xi;C1) =p(C1)p(xijC1) =\\x19N(xij\\x161;\\x06)\\nAnd for data points xifrom classC2, we have:\\np(xi;C2) =p(C2)p(xijC2) = (1\\x00\\x19)N(xij\\x162;\\x06)\\nUsing these two densities, we can construct our likelihood function:\\np(\\x19;\\x161;\\x162;\\x06) =NY\\ni=1\\x12\\n\\x19N(xij\\x161;\\x06)\\x13yi\\x12\\n(1\\x00\\x19)N(xij\\x162;\\x06)\\x131\\x00yi\\nAs usual, we will take the logarithm which is easier to work with:\\nlnp(\\x19;\\x161;\\x162;\\x06) =NX\\ni=1yiln\\x12\\n\\x19N(xij\\x161;\\x06)\\x13\\n+ (1\\x00yi) ln\\x12\\n(1\\x00\\x19)N(xij\\x162;\\x06)\\x13\\nNow that we have speci\\x0ced the log-likelihood function for our model, we can go about optimizing\\nour model by maximizing this likelihood. One way to do this is with a straightforward maximimum\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 52}),\n",
              " Document(page_content=\"likelihood estimation approach. We will optimize our parameters \\x19;\\x161;\\x162;and;\\x06separately, using\\nthe usual procedure of taking the derivative, setting equal to 0, and then solving for the parameter\\nof interest. We write down this MLE solution in the following section.\\nMLE Solution\\nSolving for \\x19\\nBeginning with \\x19, we'll concern ourselves only with the terms that depend on \\x19which are:\\nNX\\ni=1yiln\\x19+ (1\\x00yi) ln (1\\x00\\x19)\\nTaking the derivative with respect to \\x19, setting equal to 0, rearranging, we get:\\n\\x19=1\\nNNX\\ni=1yi=N1\\nN=N1\\nN1+N2\\nwhereN1is the number of data points in our data set from class C1,N2is the number of data\\npoints from class C2, andNis just the total number of data points. This means that the maximum\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 52}),\n",
              " Document(page_content=\"likelihood solution for \\x19is the fraction of points that are assigned to class C1, a fairly intuitive\\nsolution and one that will be commonly seen when working with maximum likelihood calculations.\\nSolving for \\x16\\nLet's now perform the maximization for \\x161. Start by considering the terms from our log likelihood\\ninvolving\\x161:\\nNX\\ni=1yilnN(xij\\x161;\\x06) =\\x001\\n2NX\\ni=1yi(xi\\x00\\x161)T\\x06\\x001(xi\\x00\\x161) +c\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 52}),\n",
              " Document(page_content='3.6. PROBABILISTIC METHODS 45\\nwherecare constants not involving the \\x161term. Taking the derivative with respect to \\x161, setting\\nequal to 0, and rearranging:\\n\\x161=1\\nN1NX\\ni=1yixi\\nwhich is simply the average of all the data points xiassigned to class C1, a very intuitive result.\\nBy the same derivation, the maximum likelihood solution for \\x162is:\\n\\x162=1\\nN2NX\\ni=1(1\\x00yi)xi\\nSolving for \\x06\\nAnd \\x0cnally, we can derive the maximum likelihood solution for the shared covariance matrix \\x06.\\nStart by considering the terms in our log likelihood expression involving \\x06:\\n\\x001\\n2NX\\ni=1yilnj\\x06j\\x001\\n2NX\\ni=1yi(xi\\x00\\x161)T\\x06\\x001(xi\\x00\\x161)\\x001\\n2NX\\ni=1(1\\x00yi) lnj\\x06j\\x001\\n2NX\\ni=1(1\\x00yi)(xi\\x00\\x162)T\\x06\\x001(xi\\x00\\x162)\\nTaking the derivative with respect to \\x06:\\nN\\x06\\x00T\\x001\\n2NX\\ni=1yi\\x06\\x00T(xi\\x00\\x161)(xi\\x00\\x161)T\\x06\\x00T\\x001\\n2NX\\ni=1(1\\x00yi)\\x06\\x00T(xi\\x00\\x162)(xi\\x00\\x162)T\\x06\\x00T', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 53}),\n",
              " Document(page_content='Setting equal to 0 and rearranging to solve for \\x06:\\n\\x06=1\\nNNX\\ni=1\\x12\\nyi(xi\\x00\\x161)(xi\\x00\\x161)T+ (1\\x00yi)(xi\\x00\\x162)(xi\\x00\\x162)T\\x13\\nwhich has the intuitive interpretation that the maximum likelihood solution for the shared covari-\\nance matrix is the weighted average of the two individual covariance matrices.\\nIt is relatively straightforward to extend these maximum likelihood derivations from their two-\\nclass form to their more general, multi-class form.\\nNaive Bayes\\nThere exists a further simpli\\x0ccation to probabilistic generative modeling in the context of classi\\x0c-\\ncation known as Naive Bayes .\\nDe\\x0cnition 3.6.4 (Naive Bayes): Naive Bayes is a type of generative model for classi\\x0ccation\\ntasks. It imposes the simplifying rule that for a given class Ck, we assume that each feature of', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 53}),\n",
              " Document(page_content=\"the data points xgenerated within that class are independent (hence the descriptor `naive'). This\\nmeans that the conditional distribution p(xjy=Ck) can be written as:\\np(xjy=Ck) =DY\\ni=1p(xjjy=Ck)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 53}),\n",
              " Document(page_content='46 CHAPTER 3. CLASSIFICATION\\nwhereDis the number of features in our data point xandCkis the class. Note that Naive Bayes\\ndoes not specify the form of the model p(xjjy=Ck), this decision is left up to us.\\nThis is obviously not a realistic simpli\\x0ccation for all scenarios, but it can make our calculations\\neasier and may actually hold true in certain cases. We can build more intuition for how Naive\\nBayes works through an example.\\nExample 3.2 (Naive Bayes Example): Suppose you are given a biased two-sided coin and two\\nbiased dice. The coin has probabilities as follows:\\nHeads : 30%\\nTails : 70%\\nThe dice have the numbers 1 through 6 on them, but they are biased di\\x0berently. Die 1 has\\nprobabilities as follows:\\n1: 40%\\n2: 20%\\n3: 10%\\n4: 10%\\n5: 10%\\n6: 10%\\nDie 2 has probabilities as follows:\\n1: 20%', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 54}),\n",
              " Document(page_content='2: 20%\\n3: 10%\\n4: 30%\\n5: 10%\\n6: 10%\\nYour friend is tasked with doing the following. First, they \\rip the coin. If it lands Heads, they\\nselect Die 1, otherwise they select Die 2. Then, they roll that die 10 times in a row, recording the\\nresults of the die rolls. After they have completed this, you get to observe the aggregated results\\nfrom the die rolls. Using this information (and assuming you know the biases associated with the\\ncoin and dice), you must then classify which die the rolls came from. Assume your friend went\\nthrough this procedure and produced the following counts:\\n1: 3\\n2: 1\\n3: 2\\n4: 2\\n5: 1\\n6: 1', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 54}),\n",
              " Document(page_content=\"3.7. CONCLUSION 47\\nDetermine which die this roll count most likely came from.\\nSolution:\\nThis problem is situated in the Naive Bayes framework: for a given class (dictated by the coin\\n\\rip), the outcomes within that class (each die roll) are independent. Making a classi\\x0ccation in this\\nsituation is as simple as computing the probability that the selected die produced the given roll\\ncounts. Let's start by computing the probability for Die 1:\\np(Die 1) =p(Coin Flip = Heads) \\x03p(Roll Count = [3 ;1;2;2;1;1])\\n/0:3\\x03(0:4)3\\x03(0:2)1\\x03(0:1)2\\x03(0:1)2\\x03(0:1)1\\x03(0:1)1\\n/3:84\\x0310\\x009\\nNotice that we don't concern ourselves with the normalization constant for the probability of the\\nroll count - this will not di\\x0ber between the choice of dice and we can thus ignore it for simplicity.\\nNow the probability for Die 2:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 55}),\n",
              " Document(page_content='p(Die 2) =p(Coin Flip = Tails) \\x03p(Roll Count = [3 ;1;2;2;1;1])\\n/0:7\\x03(0:2)3\\x03(0:2)1\\x03(0:1)2\\x03(0:3)2\\x03(0:1)1\\x03(0:1)1\\n/1:008\\x0310\\x008\\nTherefore, we would classify this roll count as having come from Die 2.\\nNote that this problem asked us only to make a classi\\x0ccation prediction after we already\\nknew the parameters governing the coin \\rip and dice rolls. However, given a data set, we could\\nhave also used a maximum likelihood procedure under the Naive Bayes assumption to estimate\\nthe values of the parameters governing the probability of the coin \\rip and die rolls.\\n3.7 Conclusion\\nIn this chapter, we looked at di\\x0berent objectives and techniques for solving classi\\x0ccation problems,\\nincluding discriminant functions, probabilistic discriminative models, and probabilistic generative', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 55}),\n",
              " Document(page_content='models. In particular, we emphasized the distinction between two-class and multi-class problems\\nas well as the philosophical di\\x0berences between generative and discriminative modeling.\\nWe also covered several topics that we will make use of in subsequent chapters, including sigmoid\\nfunctions and softmax, maximum likelihood solutions, and further use of basis changes.\\nBy now, you have a sound understanding of generative modeling and how it can be applied to\\nclassi\\x0ccation tasks. In the next chapter, we will explore how generative modeling is applied to a\\nstill broader class of problems.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 55}),\n",
              " Document(page_content=\"Chapter 4\\nNeural Networks\\nDespite how seemingly popular neural networks have become recently, they aren't actually a novel\\ntechnique. The \\x0crst neural networks were described in the early 1940s, and the only reason they\\nweren't put into practice shortly thereafter was the fact that we didn't yet have access to the large\\namounts of storage and compute that complex neural network require. Over the last two decades,\\nand particularly with the advent of cloud computing, we now have more and more access to the\\ncheap processing power and memory required to make neural networks a viable option for model\\nbuilding.\\nAs we will come to see in this chapter, neural networks are an extraordinarily \\rexible class of\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 56}),\n",
              " Document(page_content=\"models used to solve a variety of di\\x0berent problem types. In fact, this \\rexibility is both what makes\\nthem so widely applicable and yet so di\\x0ecult to use properly. We will explore the applications,\\nunderlying theory, and training schemes behind neural networks.\\n4.1 Motivation\\nFor problems that fall into the category of regression or classi\\x0ccation, we've already discussed the\\nutility of basis functions. Sometimes, a problem that is intractable with our raw input data will\\nbe readily solvable with basis-transformed data. We often select these basis changes using expert\\nknowledge. For example, if we were working with a data set that related to chemical information,\\nand there were certain equations that a chemist told us to be important for the particular problem\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 56}),\n",
              " Document(page_content=\"we were trying to solve, we might include a variety of the transformations that are present in those\\nequations.\\nHowever, imagine now that we have a data set with no accompanying expert information. More\\noften than not, complex problem domains don't come with a useful set of suggested transformations.\\nHow do we \\x0cnd useful basis functions in these situations? This is exactly the strength of neural\\nnetworks - they identify the best basis for a data set!\\nNeural networks simultaneously solve for our model parameters and the best basis transforma-\\ntions. This makes them exceedingly \\rexible. Unfortunately, this \\rexibility is also the weakness of\\nneural nets: while it enables us to solve di\\x0ecult problems, it also creates a host of other complica-\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 56}),\n",
              " Document(page_content='tions. Chief among these complications is the fact that neural networks require a lot of computation\\nto train. This is a result of the e\\x0bective model space being so large - to explore it all takes time\\nand resources. Furthermore, this \\rexibilty can cause rather severe over\\x0ctting if we are not careful.\\nIn summary, neural networks identify good basis transformations for our data, and the strengths\\nand weaknesses of neural networks stem from the same root cause: model \\rexibility. It will be our\\ngoal then to appropriately harness these properties to create useful models.\\n48', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 56}),\n",
              " Document(page_content=\"4.1. MOTIVATION 49\\n4.1.1 Comparison to Other Methods\\nIn the previous two chapters, we explored two broad problem types: classi\\x0ccation and regression,\\nand it's natural to wonder where neural networks \\x0ct in. The answer is that they are applicable to\\nboth. The \\rexibility of neural networks even extends to the types of problems they can be made to\\nhandle. Thus, the tasks that we've explored over the last two chapters, such as predicting heights\\nin the regression case or object category in the classi\\x0ccation case, can be performed by neural\\nnetworks.\\nGiven that neural networks are \\rexible enough to be used as models for either regression or\\nclassi\\x0ccation tasks, this means that every time you're faced with a problem that falls into one of\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 57}),\n",
              " Document(page_content=\"these categories, you have a choice to make between the methods we've already covered or using\\na neural network. Before we've explored the speci\\x0ccs of neural networks, how can we discern at a\\nhigh level when they will be a good choice for a speci\\x0cc problem?\\nOne simple way to think about this is that if we never needed to use neural networks, we probably\\nwouldn't. In other words, if a problem can be solved e\\x0bectively by one of the techniques we've\\nalready described for regression or classi\\x0ccation (such as linear regression, discriminant functions,\\netc.), we would prefer to use those. The reason is that neural networks are often more memory\\nand processor intensive than these other techniques, and they are much more complex to train and\\ndebug.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 57}),\n",
              " Document(page_content=\"The \\rip side of this is that hard problems are often too complex or too hard to engineer features\\nfor to use a simple regression or classi\\x0ccation technique. Indeed, even if you eventually think you\\nwill need to use a neural network to solve a given problem, it makes sense to try a simple technique\\n\\x0crst both to get a baseline of performance and because it may just happen to be good enough.\\nWhat is so special about neural networks that they can solve problems that the other techniques\\nwe've explored may not be able to? And why are they so expensive to train? These questions will\\nbe explored over the course of the chapter, and a good place to start is with the status of neural\\nnetworks as universal function approximators.\\n4.1.2 Universal Function Approximation\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 57}),\n",
              " Document(page_content='The \\rexibility of neural networks is a well-established phenomenon. In fact, neural networks are\\nwhat are known as universal function approximators . This means that with a large enough network,\\nit is possible to approximate any function. The proof of this is beyond the scope of this textbook,\\nbut it provides some context for why \\rexibility is one of the key attributes of neural networks.\\nML Framework Cube: Neural Networks\\nAs universal function approximators, neural networks can operate over discrete or continuous out-\\nputs. We primarily use neural networks to solve regression or classi\\x0ccation problems, which involve\\ntraining on data sets with example inputs and outputs, making this a supervised technique. Fi-', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 57}),\n",
              " Document(page_content='nally, while there exist probabilistic extensions for neural networks, they primarily operate in the\\nnon-probabilistic setting.\\nDomain Training Probabilistic\\nContinuous/Discrete Supervised No', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 57}),\n",
              " Document(page_content='50 CHAPTER 4. NEURAL NETWORKS\\nFigure 4.1: Simple Neural Network.\\n4.2 Feed-Forward Networks\\nThe feed-forward neural network is the most basic setup for a neural network. Most of the logic\\nbehind neural networks can be explained using a feed-forward network, with additional bells and\\nwhistles typically added to form more complex networks. We will explore this basic neural network\\nstructure \\x0crst.\\n4.3 Neural Network Basics and Terminology\\nLooking at Figure 4.1, we see that a feed-forward neural network is a series of connected layers\\nthat transform an input data point xinto an output data point y. Each layer is composed of\\nnodes , the small black circles. Each node in the input layer corresponds to one dimension of a', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 58}),\n",
              " Document(page_content=\"single data point x(meaning the \\x0crst node is x1, the second node x2, etc.). The same is true of the\\nnodes in the output layer, which represent each dimension of y. The nodes in the hidden layers\\nare referred to as activations . Let's zoom in on the \\x0crst node in hidden layer 1, shown in Figure\\n4.2, to describe what happens at each node as we transform an input.\\nLooking at Figure 4.2, notice that every node in the input layer is connected to this \\x0crst node\\nin hidden layer 1. Each of the lines is a connection , that has a weight wdassociated with it.\\nWe multiply all the nodes in the input layer by their corresponding weight, and then add them all\\ntogether to produce the activation aat this \\x0crst node:\\na=x1w1+x2w2+x3w3 (4.1)\\n?Every node in every layer has distinct weights associated with it.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 58}),\n",
              " Document(page_content=\"This gives us the activation for the \\x0crst node in the \\x0crst hidden layer. Once we've done this\\nfor every node in the \\x0crst hidden layer, we can then move on to computing the activations for the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 58}),\n",
              " Document(page_content=\"4.3. NEURAL NETWORK BASICS AND TERMINOLOGY 51\\nFigure 4.2: Zooming in on the inputs and the \\x0crst node of the \\x0crst layer.\\nsecond hidden layer (which require the activations of the \\x0crst hidden layer, as indicated by the\\nnetwork of connections). We keep pushing activation values through the network in this manner\\nuntil we have our complete output layer, at which point we are \\x0cnished.\\nWe've skipped over some important details in this high-level overview, but with this general\\ninformation about what a neural network looks like and the terminology associated with it, we can\\nnow dig into the details a little deeper.\\n4.3.1 Adaptive Basis Functions\\nAs we mentioned in the introduction, the strength of neural networks is that we can learn an\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 59}),\n",
              " Document(page_content=\"e\\x0bective basis for our problem domain at the same time as we train the parameters of our model.\\nIn fact, learning this basis becomes just another part of our parameter training. Let's make this\\nnotion of learning a basis more concrete.\\nThinking back to our chapter on linear regression, we were training a model that made predic-\\ntions using a functional form that looked like:\\ny(x;w) =w\\x1eT=DX\\nd=1wd\\x1ed\\nwhere\\x1e=\\x1e(x),\\x1eis the basis transformation function, and Dis the dimensionality of our data\\npoint.\\nTypically with this linear regression setup, we are training our model to optimize the parameters\\nw. With neural networks this is no di\\x0berent - we still train to learn those parameters. However,\\nthe di\\x0berence in the neural network setting is that the basis transformation function \\x1eis no longer\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 59}),\n",
              " Document(page_content=\"52 CHAPTER 4. NEURAL NETWORKS\\n\\x0cxed. Instead, the transformations are incorporated into the model parameters, and thus learned\\nat the same time.\\nThis leads to a di\\x0berent functional form for neural networks. A neural network \\x0crst performs\\nMlinear combinations of an input data point x:\\naj=DX\\nd=1w(1)\\njdxd+w(1)\\nj08j21::M (4.2)\\nNote that Equation 4.2 describes what we've already seen in Figure 4.2. The only di\\x0berence is that\\nwe index each node in the hidden layer (along with its weights) by j. Therefore, there are Mnodes\\nin this \\x0crst hidden layer, corresponding to the Mlinear combinations of the input data point x.\\nThe notation w(1)indicates that these weights are part of the \\x0crst hidden layer of our network.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 60}),\n",
              " Document(page_content=\"Notice also that we haven't applied the `bias trick' of appending a 1 to our data point x. We\\nwill still apply this trick in general, but we've left it out here to illustrate that the terms w(1)\\njdare\\ntypically referred to as weights while the term w(1)\\nj0is known as the bias.\\nAs is explained above, the Mdi\\x0berent values ajthat we compute using this equation are what\\nis known as activations . We then transform these activations with a non-linear activation function\\nh(\\x01) to give:\\nzj=h(aj) (4.3)\\n?Note that we didn't mention activation functions in the previous section only for the sake of simplicity. These\\nnon-linearities are crucial to the performance of neural networks because they allow for modeling of outcomes that\\nvary non-linearly with their input variables.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 60}),\n",
              " Document(page_content='These values zjare what is known as hidden units . The activation function is often the logistic\\nsigmoid function discussed in the previous chapter, but may also be something like a tanh function\\nor recti\\x0ced linear unit (ReLU). These output units zjbecome the inputs to the next layer in our\\nnetwork:\\naj+1=DX\\nd=1w(2)\\n(j+1)dzd+w(2)\\n(j+1)0(4.4)\\nNote we can connect many rounds of basis transformation and linear combination, and the number\\nof rounds we choose to include will be the number of layers in our network. Eventually, we will reach\\nthe nodes in the output layer of our network, which after being transformed by their activation\\nfunction, are typically known as output activations denotedyk. This \\x0cnal activation function may', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 60}),\n",
              " Document(page_content=\"be the logistic sigmoid function, softmax function, or even just a linear activation (which means\\nnot transforming them at all).\\nWith this additional detail, we can now examine a more complete diagram of a feed-forward\\nneural network, shown in Figure 4.3. It may be helpful to reread the previous paragraphs and use\\nthe diagram to visualize how a neural network transforms its inputs.\\n?Di\\x0berent resources choose to count the number of layers in a neural net in di\\x0berent manners. We've elected to\\ncount each layer of non-input nodes, thus the two-layer network in Figure 4.3. However, some resources will choose\\nto count every layer of nodes (three in this case) and still others count only the number of hidden layers (making this\\na one hidden layer network).\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 60}),\n",
              " Document(page_content='Combining Figure 4.3 and our preceeding functional description, we can describe the operation', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 60}),\n",
              " Document(page_content=\"4.3. NEURAL NETWORK BASICS AND TERMINOLOGY 53\\nFigure 4.3: Feed-Forward Neural Network.\\nperformed by a two-layer neural network using a single functional transformation:\\nyk(x;w) =\\x1b\\x12MX\\nm=1w(2)\\nkmh\\x12DX\\nd=1w(1)\\nmdxd+w(1)\\nm0\\x13\\n+w(2)\\nk0\\x13\\n(4.5)\\nwhere we've elected to make the \\x0cnal activation function the sigmoidal function \\x1b(\\x01) as we have a\\nbinary output activation layer.\\nNotice that when written like this, a neural network is simply a non-linear function that trans-\\nforms an input xinto an output ythat is controlled by our set of parameters w.\\nFurthermore, it may be clear by now why this basic variety of neural networks is referred to as\\nafeed-forward neural network . If you examine Figure 4.3 or Equation 4.5, you'll notice that we're\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 61}),\n",
              " Document(page_content=\"simply feeding our input xforward through the network from the \\x0crst layer to the last layer, hence\\nthe name. Assuming we have a fully trained network, we can make predictions on new input data\\npoints by propagating them through the network to generate output predictions.\\nNote that we can also simplify this equation by utilizing the bias trick and appending an x0= 1\\nvalue to each of our data points such that:\\nyk(x;w) =\\x1b\\x12MX\\nm=1w(2)\\nkmh\\x12DX\\nd=1w(1)\\nmdxd\\x13\\x13\\nFinally, it's worth considering that while a neural network is a series of linear combinations, it\\nis special because of the di\\x0berentiable non-linearities applied at each of the hidden layers. Without\\nthese non-linearities, the successive application of di\\x0berent network weights would be equivalent to\\na single large linear combination.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 61}),\n",
              " Document(page_content='Now that we understand the basic structure of a neural network, the important question of how\\nto train our network remains. This is the topic we turn to next.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 61}),\n",
              " Document(page_content=\"54 CHAPTER 4. NEURAL NETWORKS\\n4.4 Network Training\\nNow that we understand the structure of a basic feed-forward neural network and how they can be\\nused to make predictions, we turn our attention to the training process.\\n4.4.1 Objective Function\\nTo train our network, it's \\x0crst necessary to establish a logical objective function for our parameters\\nwthat we will seek to minimize. Remember that neural networks can be used to solve both\\nregression and classi\\x0ccation problems, which means that our choice of objective will be very much\\ndependent on the type of problem we are working on as well as the properties we desire from that\\nfunction.\\nAs we've already discussed, for the case of linear regression, a common objective function (but\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 62}),\n",
              " Document(page_content=\"certainly not the only possible one) is the least squares loss function:\\nL(w) =1\\n2NX\\nn=1\\x12\\ny(xn;w)\\x00tn\\x132\\n(4.6)\\nFor a binary classi\\x0ccation problem, which we can model using a sigmoidal nonlinearity in our\\noutput activation unit, we'll often use the cross-entropy loss function given by:\\nL(w) =\\x00NX\\nn=1\\x12\\nynln ^yn+ (1\\x00yn)(ln (1\\x00^yn)\\x13\\n(4.7)\\nAnd \\x0cnally, in the multiclass classi\\x0ccation setting produced by a softmax function in our output\\nactivation layer, we use the following generalizaton to the cross entropy loss function:\\nL(w) =\\x00NX\\nn=1KX\\nk=1yknln\\x12exp(ak(x;w))PK\\nj=1exp(aj(x;w))\\x13\\n(4.8)\\n?Loss function, objective function, and cost function all refer to the same concept: the function we optimize to train\\nour model.\\n4.4.2 Optimizing Parameters\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 62}),\n",
              " Document(page_content=\"Ultimately, as we've seen in the preceding two chapters, it is our goal to select a value for our\\nmodel's weight parameters wthat minimizes our objective function. The highly non-linear nature\\nof neural networks means that this objective function will be non-convex with respect to our weight\\nparameters, and as a result, we will need to use gradient descent for optimization (refer to the\\nprevious chapter for a refresher on gradient descent).\\nIn order to use gradient descent, we \\x0crst need to \\x0cgure out how to compute the gradient of our\\nobjective function with respect to our weights. That is the topic of the next section.\\n4.4.3 Backpropagation\\nConsidering how our feed-forward neural network works, by propagating activations through our\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 62}),\n",
              " Document(page_content=\"network to produce a \\x0cnal output, it's not immediately clear how we can compute gradients for\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 62}),\n",
              " Document(page_content=\"4.4. NETWORK TRAINING 55\\nthe weights that lie in the middle of our network, as we don't actually have expected results for\\nthose intermediate values. The solution to this problem is to send errors backwards through our\\nnetwork in a process known as backpropagation .\\nDe\\x0cnition 4.4.1 (Backpropagation): Backpropagation is the procedure by which we pass errors\\nbackwards through a feed-forward neural network in order to compute gradients for the weight\\nparameters of the network.\\nBackpropagation refers speci\\x0ccally to the portion of neural network training during which we\\ncompute the derivative of the objective function with respect to the weight parameters. This is\\ndone by propagating errors backwards through the network, hence the name.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 63}),\n",
              " Document(page_content='?Note that we still need to update the value of the weight parameters after computing their derivatives. This is\\ntypically done using gradient descent or some variant of it.\\nWe now explore the details of backpropagation in greater depth.\\n4.4.4 Computing Derivatives Using Backpropagation\\nRecall that the activation ajfor an arbitrary node in a neural network can be described by the\\nequation:\\naj=MX\\nm=1wjmzm (4.9)\\nwhere there are Mincoming nodes z1;:::;zMconnected to the node of interest and weighted by\\nwj1;:::;wjMas we see in Equation 4.4 and Figure 4.3. Recall also that this sum is then transformed\\nby an arbitrary activation function h(\\x01) (which is typically nonlinear) to give the activation zj:\\nzj=h(aj) (4.10)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 63}),\n",
              " Document(page_content=\"computing these values as we \\row through the network constitutes the forward pass through our\\nnetwork.\\nWe now wish to begin the process of computing derivatives of the objective function with respect\\nto our weights. For the sake of simplicity, we'll assume that the current setting of our parameters\\nwgenerates a loss of Lfor a single data point, as though we were performing stochastic gradient\\ndescent.\\nLet's consider how we could compute the derivative of Lwith respect to an individual weight\\nin our network, wjm:\\n@L\\n@wjm(4.11)\\nWe \\x0crst need to \\x0cgure out what the dependence of Lis on this single weight wjm. This weight\\ncontributes to the \\x0cnal result only via its contribution to the activation aj. This allows us to use\\nthe chain rule to simplify Equation 4.11 as:\\n@L\\n@wjm=@L\\n@aj\\x01@aj\\n@wjm(4.12)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 63}),\n",
              " Document(page_content='Using Equation 4.9, we have that:\\n@aj\\n@wjm=zm', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 63}),\n",
              " Document(page_content='56 CHAPTER 4. NEURAL NETWORKS\\nFigure 4.4: Gradient of the objective function with respect to a weight.\\nWe now introduce the following notation for the sake of simplicity:\\n\\x0ej=@L\\n@aj(4.13)\\nwhere the values of \\x0ejare referred to as errors . Now, we are able to rewrite Equation 4.12 as:\\n@L\\n@wjm=\\x0ejzm (4.14)\\nThe implications of Equation 4.14 are signi\\x0ccant for understanding backpropagation. It indi-\\ncates that the derivative of the objective function with respect to an arbitrary weight in the network\\nis equal to the product of the error \\x0eat the output end of that weight and the value zat the input\\nend of the weight. We can visualize this property in Figure 4.4.\\nThus, to compute all the derivatives of the network, we need only to compute the values of \\x0ej', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 64}),\n",
              " Document(page_content=\"for each of the nodes in the network. The values of zmshould be saved during the forward pass\\nthrough the network to be multiplied by the values of \\x0ej.\\n?We will only have errors \\x0ejfor the hidden and output units of our network. This is logical because there is no\\nnotion of applying an error to our input data, which we have no control over.\\nWe now need only to consider how we should compute the values of \\x0ej, given by Equation 4.13.\\nFor the \\x0cnal layer, also called the output layer, if we're using least squares loss then the error is\\ngiven by:\\n\\x0ej=@L\\n@aj=@\\x001\\n2(^yk\\x00yk)2\\x01\\n@^yk= ^yk\\x00yk\\nwhich is simply the di\\x0berence between the output of the network and the known result. We've seen\\nthis term, the di\\x0berence between the expected and actual results, arise in the gradient of our error\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 64}),\n",
              " Document(page_content='expressions for both linear regression and classi\\x0ccation in the previous two chapters.\\nTo compute the errors \\x0ejfor the hidden units, we again make use of the chain rule to decompose\\nthe errors\\x0ejas follows:\\n\\x0ej=@E\\n@aj=MX\\nm=1@E\\n@am@am\\n@aj(4.15)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 64}),\n",
              " Document(page_content='4.4. NETWORK TRAINING 57\\nFigure 4.5: Summation over the nodes (blue) to which node j (gold) sends connections (green).\\nwhere the summation runs over all of the Mnodes to which the node jsends connections as seen\\nin Figure 4.5.\\nWe can rewrite this expression using Equations 4.13, 4.9, and 4.10:\\n\\x0ej=h0(aj)MX\\nm=1wmj\\x0em (4.16)\\nwhich means that the value of \\x0efor a given node can be computed by passing back (backpropagating)\\nthe errors\\x0efrom nodes farther up in the network!\\nSince we know the values of \\x0efor the \\x0cnal layer of output node, we can recursively apply\\nEquation 4.16 to compute the values of \\x0efor all the nodes in the network.\\nRemember that all of these calculations were done for a single input data point that generated', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 65}),\n",
              " Document(page_content=\"the errorE. If we were using stochastic gradient descent, we would perform the same calculation\\nfor each data point in our mini-batch, and then sum the gradients as follows:\\n@E\\n@wjm=NX\\nn=1@En\\n@wjm(4.17)\\nTo solidify our understanding of the backpropagation algorithm, it can be useful to try a concrete\\nexample.\\nExample 4.1 (Backpropagation Example): Imagine the case of a simple two layer neural net-\\nwork as in Figure 4.3. We'll use the standard quadratic loss function on our output layer:\\nE=1\\n2MX\\nm=1(^ym\\x00ym)2\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 65}),\n",
              " Document(page_content=\"58 CHAPTER 4. NEURAL NETWORKS\\nWhereMis the number of units in the output layer. To the hidden units, we'll apply a nonlinear\\nsigmoidal activation function given by:\\n\\x1b(z) =1\\n1 + exp (\\x00z)\\nwhose derivative is given by:\\n@\\x1b(z)\\n@z=\\x1b(z)(1\\x00\\x1b(z))\\nFor our input data point x, we forward propagate through our network to get the activations of\\nthe hidden layer:\\naj=DX\\nd=0w(1)\\njdxd\\nWe then transform this value using our sigmoidal nonlinearity:\\nzj=\\x1b(aj)\\nWe then propagate these transformed activations forward once more to get our output activations:\\n^ym=JX\\nj=0w(2)\\nmjzj\\nNow that we've propagated forward, we can begin to propagate our errors backwards! We start by\\ncomputing the errors for the output layer as follows:\\n\\x0em= ^ym\\x00ym\\nWe then backpropagate these errors back to the hidden units as follows:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 66}),\n",
              " Document(page_content='\\x0ej= (\\x1b(zj)(1\\x00\\x1b(zj)))MX\\nm=1wmj\\x0em\\nAnd now that we have our errors for the hidden and output layers, we can compute the derivative\\nof the loss with respect to our weights as follows:\\n@E\\n@w(1)\\njd=\\x0ejxd;@E\\n@w(2)\\nmj=\\x0emzj\\nWe then use these derivatives along wtih an optimization technique such as gradient descent to\\nimprove our model weights.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 66}),\n",
              " Document(page_content=\"4.5. CHOOSING A NETWORK STRUCTURE 59\\nFigure 4.6: Networks with di\\x0berent structures and numbers of internal nodes.\\n4.5 Choosing a Network Structure\\nNow that we know the general form of a neural network and how the training process works, we\\nmust step back and consider the question of how we actually arrive at an optimal network structure.\\nWe'll begin with an idea we've already seen before: cross validation.\\n4.5.1 Cross Validation for Neural Networks\\nWe've previously discussed cross validation in the chapter on linear regression. We used it then\\nto compare the performance of di\\x0berent models, attempting to identify the best model while also\\navoiding over\\x0ctting. We can use a similar process to identify a reasonable network structure.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 67}),\n",
              " Document(page_content=\"First of all, the input and output parameters of a neural network are generally decided for us:\\nthe dimensionality of our input data dictates the number of input units and the dimensionality of\\nthe required output dictates the number of output units. For example, if we have an 8-by-8 pixel\\nimage and need to predict whether it is a `0' or a `1', our input dimensions are \\x0cxed at 64 and our\\noutput dimensions are \\x0cxed at 2. Depending on whether you wish to perform some sort of pre or\\npost-processing on the inputs/outputs of your network, this might not actually be the case, but\\nin general when choosing a network structure we don't consider the \\x0crst or last layer of nodes as\\nbeing a relevant knob that we can tune.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 67}),\n",
              " Document(page_content=\"That leaves us to choose the structure of the hidden layers in our network. Unsurprisingly, the\\nmore hidden layers we have and the more nodes we have in each of those layers, the more variation\\nwe will produce in our results and the closer we will come to over\\x0ctting.\\nThus, we can use cross validation in the same way we've done before: train our model with\\ndi\\x0bering numbers of internal units and structures (as in Figure 4.6) and then select the model that\\nperforms best on the validation set.\\n?There are other considerations at play beyond performance when choosing a network structure. For example, the\\nmore internal units you have in your network, the more storage and compute time you will need to train them. If\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 67}),\n",
              " Document(page_content='either training time or response time after training a model is critical, you may need to consider consolidating your\\nnetwork at the expense of some performace.\\n4.5.2 Preventing Over\\x0ctting\\nBesides keeping your neural network small, there are other means of preventing it from over\\x0ctting.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 67}),\n",
              " Document(page_content='60 CHAPTER 4. NEURAL NETWORKS\\nRegularization\\nYou can also apply regularization to the weights in your network to help prevent over\\x0ctting. For\\nexample, we could introduce a simple quadratic regularizer of the form\\x15\\n2wTwto our objective\\nfunction. There are other considerations to be made here, for example we would like our regularizer\\nto be invariant to scaling, meaning that multiplying our input data by a constant would produce\\na proportionally equivalent network after training. The quadratic regularizer is not invariant to\\nscaling, but the basic concept of avoiding extreme weights is the same nonetheless.\\nData Augmentation\\nWe can use transformations to augment our data sets, which helps prevent over\\x0ctting. This tech-', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 68}),\n",
              " Document(page_content='nique is not speci\\x0cc to neural networks, but often the types of unstructured data for which we use\\nneural networks can bene\\x0ct greatly from it.\\nDe\\x0cnition 4.5.1 (Data Augmentation): Data augmentation refers to the practice of increasing\\nthe size and diversity of your training data by applying transformations to the initial data set.\\nFor example, if we are working with image data, we might choose to rotate or re\\rect the image,\\ndepending on the type of network we are trying to build and whether or not this would preserve\\nthe integrity of the image. We might also change something like the brightness or density of the\\nimage data. In this way, we can produce more and more varied training points, thus reducing the\\nlikelihood of over\\x0ctting.\\n4.6 Specialized Forms of Neural Networks', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 68}),\n",
              " Document(page_content=\"Simple neural networks are useful for a general set of tasks, and as universal function approxima-\\ntors, they could be useful for any task. However, there are certain data types and use cases for\\nwhich we've developed more specialized forms of neural networks that perform even better in their\\nrespective domains. We will take a high level view of these di\\x0berent \\ravors of neural networks.\\n4.6.1 Convolutional Neural Networks (CNNs)\\nConvolutional neural networks (abbreviated CNNs) are most often used for image data, but their\\nunderlying principles apply in other domains as well.\\nTo understand why a CNN is useful, consider this speci\\x0cc problem: you are trying to determine\\nwhether or not there is a dog in an image. There are two general di\\x0eculties we have to deal with\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 68}),\n",
              " Document(page_content=\"in solving this problem. First, while dogs have a lot of similar features (ears, tails, paws, etc.), we\\nneed some means of breaking an image down into smaller pieces that we can identify as being ears\\nor tails or paws. Second, what happens if we train on images of dogs that are all in the center of\\nthe photo, and then we try to test our network on an image where the dog is in the upper left hand\\ncorner? It's going to fail miserably.\\nCNNs overcome these problems by extracting smaller local features from images via what's\\nknown as a sliding window . You can imagine this sliding window as a matrix kernel that moves\\nover every subsection of an image, producing a summary of those subsections that feed into the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 68}),\n",
              " Document(page_content='next layer in our network. We do this over the entire image, and with several di\\x0berent sliding\\nwindows. Without going into too many details, this solves the two general problems we had above:\\nour small sliding window can summarize a feature of interest (such as a dog ear) and it is also\\nlocation invariant, meaning that we can identify that dog ear anywhere in an image.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 68}),\n",
              " Document(page_content='4.6. SPECIALIZED FORMS OF NEURAL NETWORKS 61\\nFigure 4.7: Excellent diagram of the structure of a CNN. source:\\nhttps://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-\\nneural-networks{1489512765771.html\\nFigure 4.8: Simple example of an RNN.\\n4.6.2 Recurrent Neural Networks (RNNs)\\nAs with CNNs, recurrent neural networks (abbreviated RNNs) are used to more e\\x0eciently solve\\na speci\\x0cc problem type. To motivate the structure of an RNN, we will turn again to a speci\\x0cc\\nexample.\\nImagine we were building a tool with the goal of predicting what word comes next in a newspaper\\narticle. Obviously, the words that came before the word that we are currently trying to predict\\nare crucial to predicting the next word. Imagine we propagate the preceding ten words through', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 69}),\n",
              " Document(page_content=\"our network to predict which word we think will come next. It would also be useful if we could\\nsend some of the information at each layer backwards through the network to help with the next\\nprediction - since we know the sequence of words matters. In this sense, our network is `stateful'\\nbecause it's remembering what came before. We don't have this ability with a feed-forward network,\\nwhich by design only propagates information forward through the network. RNNs add backward\\npassing of activations into their network structure to improve predictions on data where there is\\nsome temporal dependence on what came previously.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 69}),\n",
              " Document(page_content='62 CHAPTER 4. NEURAL NETWORKS\\n4.6.3 Bayesian Neural Networks (BNNs)\\nUp until now, our training process has been one of maximum likelihood estimation, or a maximum\\nposterior approach if we utilize a regularizer that can be interpreted as introducing a prior.\\nA Bayesian neural network, or BNN, does exactly what you might imagine: it introduces\\na distribution over the parameters of our model, which then requires marginalizing over those\\ndistributions in order to make a prediction. The speci\\x0ccs of how exactly a BNN is constructed\\nare beyond the scope of this textbook, but the idea behind why we would utilize a BNN is the\\nsame as the reason we utilize Bayesian techniques in other domains, particularly the use of prior\\ninformation to aid model performance.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 70}),\n",
              " Document(page_content='Chapter 5\\nSupport Vector Machines\\nIn this chapter, we will explore what are known as a support vector machines, or SVMs for short.\\nSVMs are broadly useful for problems in classi\\x0ccation and regression, and they are part of a\\nfamily of techniques known as margin methods . The de\\x0cning goal of margin methods, and SVMs\\nspeci\\x0ccally, is to put as much distance as possible between data points and decision boundaries.\\nWe will dig deeper into what exactly this means over the course of the chapter. One of the most\\nappealing aspects of SVMs is that they decompose into convex optimization problems, for which\\nwe can \\x0cnd a global optimum with relative ease. We will explore the mathematical underpinnings\\nof SVMs, which can be slightly more challenging than our previous topics, as well as their typical', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 71}),\n",
              " Document(page_content='use cases.\\n5.1 Motivation\\nWhile SVMs can be used for classi\\x0ccation or regression, we will reason about them in the classi\\x0c-\\ncation case as it is more straightforward.\\nThe grand idea behind SVMs is that we should construct a linear hyperplane in our feature\\nspace that maximally separates our classes, which means that the di\\x0berent classes should be as\\nfar from that hyperplane as possible. The distance of our data from the hyperplane is known as\\nmargin .\\nDe\\x0cnition 5.1.1 (Margin): Margin is the distance of the nearest data point from the separating\\nhyperplane of an SVM model, as seen in Figure 5.1. Larger margins often lead to more generalizable\\nmodels.\\nA larger margin tends to mean that our model will generalize better, since it provides more\\nwiggle room to correctly classify unseen data.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 71}),\n",
              " Document(page_content='This idea of margin is quite intuitive for humans. If you were presented with Figure 5.1 and\\nwere asked to separate the two classes, you would likely draw the line that keeps data points as\\nfar from it as possible. SVMs and other margin-based methods will attempt to algorithmically\\nrecreate this intuition.\\n5.1.1 Max Margin Methods\\nSVMs are a speci\\x0cc instance of a broader class of model known as max margin methods . Their\\nname describes them well: they deal with creating a maximum margin between training data and\\ndecision boundary, with the idea that this leads to model generalizability.\\n63', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 71}),\n",
              " Document(page_content='64 CHAPTER 5. SUPPORT VECTOR MACHINES\\nFigure 5.1: Hyperplane with margin between di\\x0berent classes.\\nOther max margin methods are outside the scope of this textbook. Note that these alternative\\nmethods typically di\\x0ber from SVMs in some non-trivial manner. For example, SVMs do not produce\\nposterior probability distributions but rather decision rules for handling new data points. If you\\nneeded posterior probabilities for your model, there are other max margin methods better suited\\nto that task.\\nML Framework Cube: Support Vector Machines\\nSVMs are typically used in settings with discrete outputs. We need labeled training data to identify\\nthe relevant hyperplane in an SVM model. Finally, SVMs operate in a non-probabilistic setting.\\nDomain Training Probabilistic\\nDiscrete Supervised No', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 72}),\n",
              " Document(page_content='5.1.2 Applications\\nThe theory behind SVMs has been around for quite some time (since 1963), and prior to the rise\\nof neural networks and other more computationally intensive techniques, SVMs were used quite\\nextensively for image recognition, object categorization, and other typical machine learning tasks.\\nIn particular, SVMs were and still are widely used for a subset of classi\\x0ccation problems known\\nas anomaly detection.\\n?The purpose of anomaly detection is to identify unusual data points. For example, if we are manufacturing widgets,\\nwe may wish to inspect and \\rag any widget that seems atypical with respect to the rest of the widgets we produce.\\nAnomaly detection can be as simple as a binary classi\\x0ccation problem where the data set is', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 72}),\n",
              " Document(page_content=\"comprised of anomalous and non-anomalous data points. As we will see, an SVM can be con-\\nstructed from this data set to identify future anomalous points very e\\x0eciently. SVMs continue to\\nbe competitive in many real-world situations where we can de\\x0cne good features for our data.\\n5.2 Hard Margin Classi\\x0cer for Linearly Separable Data\\nWe will learn the theory behind SVMs by starting with a simple two-class classi\\x0ccation problem,\\nas we've seen several times in previous chapters. We will constrain the problem even further\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 72}),\n",
              " Document(page_content=\"5.2. HARD MARGIN CLASSIFIER FOR LINEARLY SEPARABLE DATA 65\\nby assuming that the two classes are linearly separable, which is the basis of the hard margin\\nformulation for SVMs.\\n?The expression `hard margin' simply means that we don't allow any data to be classi\\x0ced incorrectly. If it's not\\npossible to \\x0cnd a hyperplane that perfectly separates the data based on class, then the hard margin classi\\x0cer will\\nreturn no solution.\\n5.2.1 Why the Hard Margin\\nThe hard margin constraint, which assumes that our data is linearly separable, is not actually\\na requirement for constructing an SVM, but it simpli\\x0ces the problem initially and makes our\\nderivations signi\\x0ccantly easier. After we've established the hard margin formulation, we will extend\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 73}),\n",
              " Document(page_content='the technique to work in situations where our data is not linearly separable.\\n5.2.2 Deriving our Optimization Problem\\nRecall that our goal is to de\\x0cne a hyperplane that separates our data points and maintains the\\nmaximum possible distance between the hyperplane and nearest data points on either side of it. To\\nuncover this hyperplane, we start with a simple linear model for a two-class classi\\x0ccation problem:\\nf(x) =wT\\x1e(x) +w0 (5.1)\\nwhere we have Nmultidimensional data points x1;:::;xN,\\x1e(\\x01) is a standard basis transformation\\nfunction, and there is a bias term w0. Each of our data point has a class y1;:::;yNwhich is either\\n1 or\\x001, and we assign new data points to class 1 or \\x001 according to the sign produced by our\\ntrained model f(x).', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 73}),\n",
              " Document(page_content=\"By specifying our model this way, we have implicity de\\x0cned a hyperplane separating our two\\nclasses given by:\\nwT\\x1e(x) +w0= 0 (5.2)\\nFurthermore, we have that wis orthogonal to the hyperplane, which we demonstrate now:\\nDerivation 5.2.1 (Hyperplane Orthogonal to w): Imagine two data points x1andx2on the\\nhyperplane de\\x0cned by wT\\x1e(x) +w0= 0. When we project their di\\x0berence onto our model w, we\\n\\x0cnd:\\nwT(x1\\x00x2) =wTx1\\x00wTx2=\\x00w0\\x00(\\x00w0) = 0 (5.3)\\nwhich means that wis orthogonal to our hyperplane. We can visualize this in Figure 5.2.\\nRemember that we're trying to maximize the margin between our training data and the hyper-\\nplane. The fact that wis orthogonal to our hyperplane will help with this.\\nTo determine the distance between a data point xand the hyperplane, which we denote d, we\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 73}),\n",
              " Document(page_content='need the distance in the direction of wbetween the point and the hyperplane. We denote x?to\\nbe the projection of xonto the hyperplane, which allows us to decompose xas the following:\\nx=x?+dw\\njjwjj(5.4)\\nwhich is simply the sum of the portion of xperpendicular to wand the portion of xthat is parallel\\ntow. From here we can solve for d:', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 73}),\n",
              " Document(page_content='66 CHAPTER 5. SUPPORT VECTOR MACHINES\\nFigure 5.2: Our weight vector wis orthogonal to the separating hyperplane.\\nDerivation 5.2.2 (Distance from Hyperplane Derivation): We start by left multiplying\\nEquation 5.4 with wT.\\nwTx=wTx?+dwTw\\njjwjj\\nSimplifying (note that wTx?=\\x00w0from Equation 5.3):\\nwTx=\\x00w0+djjwjj\\nRearranging:\\nd=wTx+w0\\njjwjj\\nwhich means that for each data point x, we now have the signed distance of that data point\\nfrom the hyperplane.\\nTo classify a data point correctly, the distance dshould be positive for class y= 1, anddshould\\nbe negative for class y=\\x001. For training purposes, we can make the margin positive whenever we\\ncorrectly classify data by multiplying yandd. Then, the margin for an individual data point xnis\\ngiven by:\\nyn(wTxn+w0)\\njjwjj(5.5)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 74}),\n",
              " Document(page_content='The margin for an entire data set is given by the margin to the closest point in the data set, given\\nby:\\nmin\\nnyn(wTxn+w0)\\njjwjj(5.6)\\nThen, it is our goal to maximize this margin with respect to our model parameters wandw0. This\\nis given by:\\narg max\\nw;w0\\x081\\njjwjjmin\\nnyn(wTxn+w0)\\t\\n(5.7)\\nThis is a hard problem to optimize, but we can make it more tractable by recognizing some im-\\nportant features of Equation 5.7. First, rescaling w!\\x0bwandw0!\\x0cw0has no impact on the', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 74}),\n",
              " Document(page_content='5.3. SOFT MARGIN CLASSIFIER 67\\nrelative distance of any data point xnfrom the hyperplane. We can use this rescaling liberty to\\nenforce\\nyn(wTxn+w0) = 1n;closest (5.8)\\nfor the data point closest to the hyperplane. Thus, all of our data points have a margin that is\\ngreater than or equal to 1:\\n8nyn(wTxn+w0)\\x151n;farther (5.9)\\nwhich is used as a constraint in the optimization problem of Equation 5.7. Thus our optimization\\nproblem now looks like:\\narg max\\nw;w01\\njjwjjs.t.8nyn(wTxn+w0)\\x151 (5.10)\\nNotice that maximizing1\\njjwjjis equivalent to minimizing jjwjj2. We will also add a constant term\\n1\\n2for convenience, leaving our \\x0cnal optimization problem:\\narg min\\nw;w01\\n2jjwjj2s.t.8nyn(wTxn+w0)\\x151 (5.11)\\nNote that Equation 5.11 is now a quadratic programming problem, which means we wish to optimize', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 75}),\n",
              " Document(page_content='a quadratic function subject to a set of linear constraints on our parameters. Arriving at this form\\nwas the motivation for the preceding mathematic manipulations. We will discuss shortly how we\\nactually optimize this function.\\n5.2.3 What is a Support Vector\\nUp until now, we have discussed Support Vector Machines without identifying what a support\\nvector is. We now have enough information from the previous section to de\\x0cne them.\\nDe\\x0cnition 5.2.1 (Support Vector): The support vectors in an SVM are the data points closest\\nto the hyperplane.\\nIn the hard margin case we have constrained the closest data points to being a distance of 1\\nfrom the hyperplane, so the support vectors are all d= 1 from the hyperplane. Figure 5.3 shows a\\nhard margin SVM solution with the corresponding support vectors.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 75}),\n",
              " Document(page_content=\"?After we have optimized an SVM in the hard margin case, we must have at least two support vectors with a distance\\nof 1 from the hyperplane.\\n5.3 Soft Margin Classi\\x0cer\\nThus far, we've been operating under the assumption that our data is linearly separable in feature\\nspace, which a\\x0borded us several convenient guarantees in the derivations of the previous section.\\nFor example, given that our data was linearly separable, we could guarantee that every data point\\nwould be on the correct side of the hyperplane, which was part of what allowed us to enforce the\\nconstraint that d= 1 for the points closest to the hyperplane. We now seek to generalize the work\\nof the previous section to situations where our data is not so nice.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 75}),\n",
              " Document(page_content=\"68 CHAPTER 5. SUPPORT VECTOR MACHINES\\nHard Margin SVM Example\\nFigure 5.3: Example of the resulting hyperplane for a hard margin SVM. The \\x0clled in data points\\nare support vectors.\\n5.3.1 Why the Soft Margin?\\nWhat if our data is not linearly separable in transformed feature space? For a real, complex\\nproblem domain, it's highly unlikely that it would be. Unfortunately, our current hard margin\\nSVM formulation would be useless with non-linearly separable data. That is why we need the soft\\nmargin SVM.\\nAt a high level, the soft margin SVM allows for some of our data points to be closer to or even\\non the incorrect side of the hyperplane. This is desirable if our data set is not linearly separable or\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 76}),\n",
              " Document(page_content='contains outliers, and it is also quite intuitive. Examining Figure 5.4, we see that we have a single\\noutlier data point. We can still create a good model by just allowing this single data point to be\\nclose to the hyperplane. That is what the soft margin formulation will allow for.\\n5.3.2 Updated Optimization Problem for Soft Margins\\nTo enable the soft margin formulation, we introduce what are known as slack variables denoted\\n\\x18n\\x150, which simply relax the constraint from Equation 5.9 that we imposed in the hard margin\\nformulation. There is a slack variable \\x18n\\x150 for every data point xn, and they take the following\\nvalues according to how we classify xn:\\n\\x18n=8\\n><\\n>:= 0 if correctly classi\\x0ced\\n2(0;1] if correctly classi\\x0ced but inside margin\\n>1 if incorrectly classi\\x0ced(5.12)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 76}),\n",
              " Document(page_content=\"These slack variable penalize data points on the wrong side of the margin de\\x0cned by the hyperplane,\\nbut they don't forbid us from allowing data points to be on the wrong side if it produces the best\\nmodel. We now reformulate our optimization problem as:\\narg min\\nw;w01\\n2jjwjj2+CNX\\nn=1\\x18ns.t.8nyn(wTxn+w0)\\x151\\x00\\x18n; \\x18n\\x150 (5.13)\\nwhereCis a regularization parameter that determines how heavily we penalize violations of the\\nhard margin constraints. A large Cpenalizes violation of the hard margin constraints more heavily,\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 76}),\n",
              " Document(page_content=\"5.4. CONVERSION TO DUAL FORM 69\\nFigure 5.4: An outlier can make the hard margin formulation impossible or unable to generalize\\nwell.\\nwhich means our model will follow the data closely and have little regularization. A small Cwon't\\nheavily penalize having data points inside the margin region, relaxing the constraint and allowing\\nour model to somewhat disregard more of the data. This means more regularization.\\n?Unlike most regularization parameters we've seen thus far, Cincreases regularization as it gets smaller.\\n5.3.3 Soft Margin Support Vectors\\nUnder the the hard margin formulation, the support vectors were those data points exactly d= 1\\nfrom the hyperplane, and they were also guaranteed to be the points closest to the hyperplane.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 77}),\n",
              " Document(page_content='Under the soft margin formulation, we no longer have this guarantee since we explicity relaxed it\\nin the name of creating better, more generalizable models.\\nThe support vectors for the soft margin case are determined by the value of the slack variable\\n\\x18nde\\x0cned in Equation 5.12: data points for which \\x18n\\x150 are the support vectors. Note that these\\nsupport vectors are either correctly classi\\x0ced but within/on the margin ( \\x18n2[0;1]) or incorrectly\\nclassi\\x0ced (\\x18n>1). We can visualize this in Figure 5.5.\\n?Data points for which \\x18n= 0 are on the margin and are still considered support vectors.\\n5.4 Conversion to Dual Form\\nNow that we have the formulation of the optimization problem for SVMs, we need to discuss how', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 77}),\n",
              " Document(page_content='we actually go about optimizing to produce a model solution. This will involve converting to a\\ndual form of our problem. We will do this in the hard margin case for notational simplicity, but\\nour solution will apply to the soft margin formulation as well.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 77}),\n",
              " Document(page_content='70 CHAPTER 5. SUPPORT VECTOR MACHINES\\nSoft Margin SVM Example\\nFigure 5.5: Example of the resulting hyperplane for a soft margin SVM. The \\x0clled in data points\\nare support vectors.\\n?A dual form is simply an equivalent manner of representing some expression, in this case the quadratic programming\\nproblem we need to optimize.\\n5.4.1 Lagrange Multipliers\\nBefore we get into deriving the dual form, we need to be aware of a critical piece of math that will\\nenable us to solve our optimization problem: Langrange multipliers .\\nA Lagrange multiplier is used to \\x0cnd optima of a function subject to certain constraints. This\\nis exactly what we need to solve the optimization problem described by Equation 5.11.\\nThe underlying theory behind Lagrange multipliers is not overly di\\x0ecult to understand, but it', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 78}),\n",
              " Document(page_content=\"is beyond the scope of this textbook. We will simply o\\x0ber the method by which you can use them\\nto solve optimization problems.\\nIf you have a function f(x) which you need to optimize (let's say maximization here to be\\nconcrete, but minimization applies just the same) subject to the constraint that some function\\ng(x) = 0, you can take the following steps. First, construct the Lagrangian function L(x;\\x15):\\nL(x;\\x15) =f(x) +\\x15g(x) (5.14)\\nThen, set the derivative of Lwith respect to both xand\\x15equal to 0:\\nrLx= 0;@L\\n@\\x15=g(x) = 0\\nIfxisD-dimensional, this will give you a system of D+1 equations. You can solve these equations\\nforxto \\x0cnd the optimal value of f(x) subject to the constraint g(x).\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 78}),\n",
              " Document(page_content=\"5.4. CONVERSION TO DUAL FORM 71\\nYou should also be aware of the case where your constraint g(x) is an inequality. If we have\\ng(x)\\x150, we will still have the Lagrangian function given by Equation 5.14. On the other hand, if\\nthe inequality constraint is g(x)\\x140, construct your Lagrangian function as follows:\\nL(x;\\x15) =f(x)\\x00\\x15g(x)\\nwhere only the sign has changed between the f(x) andg(x) terms. We will work in the g(x)\\x150\\ncase, which like before we optimize with respect to the parameters xand\\x15:\\nrLx= 0;@L\\n@\\x15=g(x)\\x150\\nRegardless of the direction of the inequality, we also now optimize subject to the constraints:\\n\\x15\\x150; \\x15g (x) = 0\\n?The exact reason for these new constraints when working with inequalities is beyond the scope of this textbook,\\nbut it's important to remember that they be met.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 79}),\n",
              " Document(page_content=\"Finally, note that when you are optimizing a function under many constraints, you simply\\nintroduce a Lagrange multiplier for each constraint.\\nExample 5.1 (Langrange Multiplier Example): Let's say we had a function f(x) we wish to\\nmaximize:\\nf(x) =x2\\n1+ 3x2\\n2+ 3\\nsubject to the constraint g(x):\\ng(x) = 4x1+ 4x2\\x006 = 0\\nWe begin by construction our Lagrangian function L(x;\\x15):\\nL(x;\\x15) =x2\\n1+ 3x2\\n2+ 3 +\\x15(4x1+ 4x2\\x006)\\nWe then compute rLxand@L\\n@\\x15to get a system of equations:\\n2x1+ 4\\x15= 0\\n6x2+ 4\\x15= 0\\n4x1+ 4x2\\x006 = 0\\nSolving these equations for x1,x2, and\\x15leaves us with the following mazimized solution:\\n(x\\x03\\n1;x\\x03\\n2) =\\x129\\n8;3\\n8\\x13\\n;\\x15\\x03=\\x009\\n16\\n5.4.2 Deriving the Dual Formulation\\nNow that we understand Lagrange multipliers and how we can use them for constrained optimiza-\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 79}),\n",
              " Document(page_content='tion, we can get back to the hard margin SVM optimization problem:\\narg min\\nw;w01\\n2jjwjj2s.t.8nyn(wTxn+w0)\\x151 (5.15)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 79}),\n",
              " Document(page_content=\"72 CHAPTER 5. SUPPORT VECTOR MACHINES\\nTo satisfy these Nconstraints, we introduce NLagrange multipliers \\x150;:::;\\x15N\\x001\\x150. We then\\nhave our Lagrangian function:\\nL(w;w0;\\x15) =1\\n2jjwjj2\\x00NX\\nn=1\\x15n(yn(wTxn+w0)\\x001) (5.16)\\nwhere\\x15=\\x150;:::;\\x15N\\x001. Using this Lagrangian function, we allow ourselves to switch from solving\\nEquation 5.15 to instead solving:\\narg min\\nw;w0max\\n\\x15\\x150L(w;w0;\\x15) (5.17)\\n?The `arg min\\nw;w0max\\n\\x15\\x150' in Equation 5.17 may be initially confusing. We introduce the maximum because the values of\\n\\x15are free and should be set such that L(w;w0;\\x15) is as large as possible prior to minimizing with respect to w;w0.\\nWe now wish to convert the objective in Equation 5.17 to a dual objective. Under the su\\x0ecient\\nconditions of strong duality which hold for this problem but whose explanation is beyond the scope\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 80}),\n",
              " Document(page_content='of this textbook, we can reformulate the objective as:\\nmax\\n\\x15\\x150arg min\\nw;w0L(w;w0;\\x15) (5.18)\\nAt this point, we can solve for w;w0. Taking the gradient, setting equal to 0, and solving for w:\\nrLw=w\\x00NX\\nn=1\\x15nynxn= 0\\nw\\x03=NX\\nn=1\\x15nynxn (5.19)\\nAnd now for w0:\\n@L\\n@w0=\\x00NX\\nn=1\\x15nyn= 0\\nNX\\nn=1\\x15nyn= 0 (5.20)\\nNow that we have these equations de\\x0cning the optimal values for wandw0we plug them back\\ninto our our Lagrangian function:\\nL(w;w0;\\x15) =1\\n2jjNX\\nn=1\\x15nynxnjj2\\x00NX\\nn=1\\x15nyn(NX\\nm=1\\x15mymxm)Txn\\x00NX\\nn=1\\x15nynw0+NX\\nn=1\\x15n\\n=1\\n2NX\\nn=1NX\\nm=1\\x15n\\x15mynymxT\\nnxm\\x00NX\\nn=1NX\\nm=1\\x15n\\x15mynymxT\\nnxm\\x00w0NX\\nn=1\\x15nyn+NX\\nn=1\\x15n\\n=NX\\nn=1\\x15n\\x001\\n2NX\\nn=1NX\\nm=1\\x15n\\x15mynymxT\\nnxm(5.21)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 80}),\n",
              " Document(page_content=\"5.4. CONVERSION TO DUAL FORM 73\\nWe're left with the result of Equation 5.21, which is another quadratic function that we wish to\\nmaximize subject to the constraint \\x15\\x150 andPN\\nn=1\\x15nyn= 0. We can solve for \\x15using the same\\nLangrangian techniques described above.\\nWhy do we wish to solve for the values of \\x15at all? To see this, we need to understand how to\\nmake predictions on new data points.\\n5.4.3 Making Predictions\\nRecall the classi\\x0ccation function described by Equation 5.1 at the beginning of this chapter:\\nf(x) =wT\\x1e(x) +w0\\nWe classifying new data points by looking at the sign produced by this function. Now that we've\\nsolved for w, we can rewrite this function as:\\nf(x) =NX\\nn=1\\x15nyn\\x1e(xn)T\\x1e(xn) +w0 (5.22)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 81}),\n",
              " Document(page_content=\"Data points for which f(x)>0 are classi\\x0ced as 1, while all other data points are classi\\x0ced as \\x001.\\nRemember also that since \\x15are Lagrange multipliers, we are bound by the constraints:\\n\\x15n\\x150; \\x15nfynf(xn)\\x001g= 0\\nwhich means that for every data point summed in the Equation 5.22, we either have that \\x15n= 0 or\\nynf(xn) = 1. Any data points where \\x15n= 0 don't appear in the summation and thus don't have\\nany impact on the prediction.\\nThe rest of the data points, for which \\x15n>0, are known as support vectors , and because\\nwe have that ynf(xn) = 1, these are the data points that lie on the margin of the hyperplane in\\nFigure 5.5.\\nThis is a major takeaway for the usefulness of SVMs: once we've trained our model, we can\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 81}),\n",
              " Document(page_content=\"discard most of our data. We only need to keep the support vectors to make predictions. This also\\nillustrates why we need to solve for the values of \\x15: those values dictate which data points are the\\nsupport vectors for our model.\\nFinally, note that the extension of this solution from the hard margin to the soft margin case is\\nstraightforward. In fact, the Lagrangian function ends up being identical and we only have a few\\nextra constraints.\\n5.4.4 Why is the Dual Formulation Necessary?\\nAt this point, you might be wondering what exactly we gained by moving to the dual formulation\\nof this problem.\\nFirst, the complexity of the optimization problem we're solving changed from one that is depen-\\ndent on the number of features Min our particular data domain to one that is linearly dependent on\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 81}),\n",
              " Document(page_content=\"the number of data points N. Thus, our model complexity is now independent of the dimensionality\\nof the feature space.\\nSecond, in the dual formulation, we have the opportunity to take advantage of what's known as\\nthekernel trick to map our data xninto higher dimensions without incurring performance costs.\\nThis works as follows: notice that during our training process and at prediction time through\\nEquation 5.22, we have the term \\x1e(xn)T\\x1e(xm). We rewrite this as follows:\\nk(xn;xm) =\\x1e(xn)T\\x1e(xm) (5.23)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 81}),\n",
              " Document(page_content=\"74 CHAPTER 5. SUPPORT VECTOR MACHINES\\nwherek(xn;xm) is known as the kernel function. Under certain conditions, we can skip the step\\nof projecting data points xninto the larger basis de\\x0cned by the transformation \\x1e, instead directly\\ncomputing the value of the kernel function. We can use this trick as long as k() is a valid kernel,\\nwhich we turn to next.\\n?This trick can even be used to work in an in\\x0cnite basis. If that is of interest, you should look into Taylor series\\nbasis expansion.\\n5.4.5 Kernel Composition\\nNow that we've seen the usefulness of the kernel trick for working in higher dimensional spaces\\nwithout incurring performance costs or memory overhead, it's reasonable to wonder what sort of\\nvalid kernels we can construct.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 82}),\n",
              " Document(page_content=\"To be explicit, by `kernel' we mean a function that produces a scalar product from two vectors\\nin your desired feature space. In other words, when applied to two data points, your kernel should\\nproduce a number. Although it is beyond the scope of this textbook, the condition for a kernel k(\\x01)\\nto be valid is that the matrix of elements given by k(xn;xm) should be positive semide\\x0cnite for all\\nchoices of the data set fxng.\\n?The matrix of elements k(xn;xm) is known as the Gram matrix , and is denoted by K.\\nIn practice we care that we can compose valid kernels from smaller valid kernels. To this end,\\nthere exists a set of rules that will preserve the validity of kernels through transformations. These\\ninclude such things as scalar multiplication\\x00c\\x01k(xn;xm)\\x01\\n, exponentiation\\x00\\nexpfk(xn;xm)g\\x01\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 82}),\n",
              " Document(page_content=', and\\naddition\\x00\\nk1(xn;xm)+k2(xn;xm)\\x01\\nand multiplication\\x00\\nk1(xn;xm)\\x01k2(xn;xm)\\x01\\nof di\\x0berent kernels.\\nIt is always possible to test the validity of a given kernel by demonstrating that its Gram matrix\\nKis positive semide\\x0cnite.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 82}),\n",
              " Document(page_content=\"Chapter 6\\nClustering\\nIn this chapter, we will explore a technique known as clustering. This represents our \\x0crst foray into\\nunsupervised machine learning techniques. Unlike the previous four chapters, where we explored\\ntechniques that assumed a data set of inputs and targets, with the goal of eventually making\\npredictions over unseen data, our data set will no longer contain explicit targets. Instead, these\\ntechniques are motivated by the goal of uncovering structure in our data. Identifying clusters of\\nsimilar data points is a useful and ubiquitous unsupervised technique.\\n6.1 Motivation\\nThe reasons for using an unsupervised technique like clustering are broad. We often don't have a\\nspeci\\x0cc task in mind; rather, we are trying to uncover more information about a potentially opaque\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 83}),\n",
              " Document(page_content=\"data set. For clustering speci\\x0ccally, our unsupervised goal is to group data points that are similar.\\nThere are many reasons why we might separate our data by similarity. For organizational\\npurposes, it's convenient to have di\\x0berent classes of data. It can be easier for a human to sift\\nthrough data if it's loosely categorized beforehand. It may be a preprocessing step for an inference\\nmethod; for example, by creating additional features for a supervised technique. It can help identify\\nwhich features make our data points most distinct from one another. It might even provide some\\nidea of how many distinct data types we have in our set.\\nThis idea of data being `similar' means that we need some measure of distance between our\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 83}),\n",
              " Document(page_content=\"data points. While there are a variety of clustering algorithms available, the importance of this\\ndistance measurement is consistent between them.\\nDistance is meant to capture how `di\\x0berent' two data points are from each other. Then, we can\\nuse these distance measurements to determine which data points are similar, and thus should be\\nclustered together. A common distance measurement for two data points xandx0is given by:\\njjx\\x00x'jjL2=vuutDX\\nd=1(xd\\x00x'd)2 (6.1)\\nwhereDis the dimensionality of our data. This is known as L2orEuclidean distance , and you\\ncan likely see the similarity to L2 regularization.\\nThere are a variety of distance measurements available for data points living in a D-dimensional\\nEuclidean space, but for other types of data (such as data with discrete features), we would need\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 83}),\n",
              " Document(page_content='to select a di\\x0berent distance metric. Furthermore, the metrics we choose to use will have an impact\\non the \\x0cnal results of our clustering.\\n75', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 83}),\n",
              " Document(page_content='76 CHAPTER 6. CLUSTERING\\nML Framework Cube: Clustering\\nClustering algorithms can operate on both continuous and discrete feature spaces, are fully unsu-\\npervised, and are non-probabilistic for the techniques we explore in this chapter.\\nDomain Training Probabilistic\\nContinuous/Discrete Unsupervised No\\n6.1.1 Applications\\nHere are a few speci\\x0cc examples of use cases for clustering:\\n1. Determining the number of phenotypes in a population.\\n2. Organizing images into folders according to scene similarity.\\n3. Grouping \\x0cnancial data as a feature for anticipating extreme market events.\\n4. Identifying similar individuals based on DNA sequences.\\nAs we mentioned above, there are di\\x0berent methods available for clustering. In this chapter, we', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 84}),\n",
              " Document(page_content='will explore two of the most common techniques: K-Means Clustering and Hierarchical Agglomer-\\native Clustering. We also touch on the \\ravors available within each of these larger techniques.\\n6.2 K-Means Clustering\\nThe high level procedure behind K-Means Clustering (known informally as k-means) is as follows:\\n1. Initialize cluster centers by randomly selecting points in our data set.\\n2. Using a distance metric of your choosing, assign each data point to the closest cluster.\\n3. Update the cluster centers based on your assignments and distance metric (for example, when\\nusing L2 distance, we update the cluster centers by averaging the data points assigned to each\\ncluster).\\n4. Repeat steps 1 and 2 until convergence.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 84}),\n",
              " Document(page_content=\"In the case where we are using the L2 distance metric, this is known as Lloyd's algorithm , which\\nwe derive in the next section.\\n6.2.1 Lloyd's Algorithm\\nLloyd's algorithm, named after Stuart P. Lloyd who \\x0crst suggested the algorithm in 1957, optimizes\\nour cluster assignments via a technique known as coordinate descent, which we will learn more about\\nin later chapters.\\nDerivation 6.2.1 (Lloyd's Algorithm Derivation):\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 84}),\n",
              " Document(page_content=\"6.2. K-MEANS CLUSTERING 77\\nWe begin by de\\x0cning the objective used by Lloyd's algorithm.\\nObjective\\nThe loss function for our current assignment of data points to clusters is given by:\\nL(X;\\x08\\n\\x16\\tC\\nc=1;\\x08\\nr\\tN\\nn=1) =NX\\nn=1CX\\nc=1rnc(xn\\x00\\x16c)2(6.2)\\nwhere Xis ourNxDdata set (Nis the number of data points and Dis the dimensionality of\\nour data),\\x08\\n\\x16\\tC\\nc=1is theCxDmatrix of cluster centers ( Cis the number of clusters we chose),\\nand\\x08\\nr\\tN\\nn=1is ourNxCmatrix of responsibility vectors . These are one-hot encoded vectors (one\\nper data point), where the 1 is in the position of the cluster to which we assigned the nth data point.\\nWe now de\\x0cne the algorithmic portion of Lloyd's clustering procedure.\\nAlgorithm\\nWe \\x0crst adjust our responsibility vectors to minimize each data point's distance from its cluster\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 85}),\n",
              " Document(page_content='center. Formally:\\nrnc=8\\n<\\n:= 1 ifc= arg min\\nc0jjxn\\x00\\x16c0jj\\n= 0 otherwise(6.3)\\nAfter updating our responsibility vectors, we now wish to minimize our loss by updating our cluster\\ncenters\\x16c. The cluster centers which minimize our loss can be computed by taking the derivative\\nof our loss with respect to \\x16c, setting equal to 0, and solving for our new cluster centers \\x16c:\\n@L\\n@\\x16c=\\x002NX\\nn=1rnc(xn\\x00\\x16c)\\n\\x16c=PN\\nn=1rncxnPN\\nn=1rnc(6.4)\\nIntuitively, this is the average of all the data points xnassigned to the cluster center \\x16c.\\nWe then update our responsibility vectors based on the new cluster centers, update the cluster\\ncenters again, and continue this cycle until we have converged on a stable set of cluster centers and\\nresponsibility vectors.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 85}),\n",
              " Document(page_content=\"Note that while Lloyd's algorithm is guaranteed to converge, it is only guaranteed to converge\\nto a locally optimal solution. Finding the globally optimal set of assignments and cluster centers is\\nan NP-hard problem. As a result, a common strategy is to execute Lloyd's algorithm several times\\nwith di\\x0berent random initializations of cluster centers, selecting the assignment that minimizes\\nloss across the di\\x0berent trials. Furthermore, to avoid nonsensical solutions due to scale mismatch\\nbetween features (which would throw our Euclidean distance measurements o\\x0b), it makes sense to\\nstandardize our data in a preprocessing step. This is as easy as subtracting the mean and dividing\\nby the standard deviation across each feature.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 85}),\n",
              " Document(page_content=\"78 CHAPTER 6. CLUSTERING\\n6.2.2 Example of Lloyd's\\nFor some more clarity on exactly how Lloyd's algorithm works, let's walk through an example.\\nExample 6.1 (Lloyd's Algorithm Example): We start with a data set of size N= 6. Each\\ndata point is two-dimensional, with each feature taking on a value between -3 and 3. We also\\nhave a `Red' and `Green' cluster. Here is a table and graph of our data points, labelled A through F:\\nCoordinates Dist. to Red Dist. to Green Cluster Assgn.\\nA (-3, -3) n/a n/a n/a\\nB (-1, -3) n/a n/a n/a\\nC (3, 0) n/a n/a n/a\\nD (-2, -1) n/a n/a n/a\\nE (0, 0) n/a n/a n/a\\nF (-1, -2) n/a n/a n/a\\nLet's say we wish to have 2 cluster centers. We then randomly initialize those cluster centers by\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 86}),\n",
              " Document(page_content=\"selecting two data points. Let's say we select B and F. We identify our cluster centers with a red\\nand green `X' respectively:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 86}),\n",
              " Document(page_content=\"6.2. K-MEANS CLUSTERING 79\\nWe now begin Lloyd's algorithm by assigning each data point to its closest cluster center:\\nCoordinates Dist. to Red Dist. to Green Cluster Assgn.\\nA (-3, -3) n/a n/a Red\\nB (-1, -3) n/a n/a Red\\nC (3, 0) n/a n/a Green\\nD (-2, -1) n/a n/a Green\\nE (0, 0) n/a n/a Green\\nF (-1, -2) n/a n/a Green\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 87}),\n",
              " Document(page_content=\"80 CHAPTER 6. CLUSTERING\\nWe then update our cluster centers by averaging the data points assigned to each:\\nCoordinates Dist. to Red Dist. to Green Cluster Assgn.\\nA (-3, -3) 2.00 2.24 Red\\nB (-1, -3) 0.00 1.00 Red\\nC (3, 0) 5.00 4.47 Green\\nD (-2, -1) 2.24 1.41 Green\\nE (0, 0) 3.16 2.24 Green\\nF (-1, -2) 1.00 0.00 Green\\nWe proceed like this, updating our cluster centers and assignments, until convergence. At conver-\\ngence, we've achieved these cluster centers and assignments:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 88}),\n",
              " Document(page_content=\"6.2. K-MEANS CLUSTERING 81\\nCoordinates Dist. to Red Dist. to Green Cluster Assgn.\\nA (-3, -3) 1.46 5.41 Red\\nB (-1, -3) 1.06 3.91 Red\\nC (3, 0) 5.26 1.50 Green\\nD (-2, -1) 1.27 3.64 Red\\nE (0, 0) 2.85 1.50 Green\\nF (-1, -2) 0.79 3.20 Red\\nWhere our red cluster is at (-1.75, -2.25) and our green cluster is at (1.5 , 0). Note that for this\\nrandom initialization of cluster centers, we deterministically identi\\x0ced the locally optimal set of\\nassignments and cluster centers. For a speci\\x0cc initialization, running Lloyd's algorithm will always\\nidentify the same set of assignments and cluster centers. However, di\\x0berent initializations will\\nproduce di\\x0berent results\\n6.2.3 Number of Clusters\\nYou may have wondered about a crucial, omitted detail: how do we choose the proper number of\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 89}),\n",
              " Document(page_content=\"clusters for our data set? There doesn't actually exist a `correct' number of clusters. The fewer\\nclusters we have, the larger our loss will be, and as we add more clusters, our loss will get strictly\\nsmaller. That being said, there is certainly a tradeo\\x0b to be made here.\\nHaving a single cluster is obviously useless - we will group our entire data set into the same\\ncluster. Having Nclusters is equally useless - each data point gets its own cluster.\\nOne popular approach to identifying a good number of clusters is to perform K-Means with a\\nvarying number of clusters, and then to plot the number of clusters against the loss. Typically,\\nthat graph will look like Figure 6.1.\\nNotice that at x=:::clusters, there appears to be a slight bend in the decrease of our loss.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 89}),\n",
              " Document(page_content=\"This is often called the knee , and it is common to choose the number of clusters to be where the\\nknee occurs.\\nIntuitively, the idea here is that up to a certain point, adding another cluster signi\\x0ccantly\\ndecreases the loss by more properly grouping our data points. However, eventually the bene\\x0ct of\\nadding another cluster stops being quite so signi\\x0ccant. At this point, we have identi\\x0ced a natural\\nnumber of groups for our data set.\\n6.2.4 Initialization and K-Means++\\nUp until now, we have assumed that we should randomly initialize our cluster centers and execute\\nLloyd's algorithm until convergence. We also suggested that since Lloyd's algorithm only produces\\na local minimum, it makes sense to perform several random initializations before settling on the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 89}),\n",
              " Document(page_content=\"most optimal assignment we've identi\\x0ced.\\nWhile this is a viable way to perform K-Means, there are other ways of initializing our orig-\\ninal cluster centers that can help us \\x0cnd more optimal results without needing so many random\\ninitializations. One of those techniques is known as K-Means++ .\\nThe idea behind K-Means++ is that our cluster centers will typically be spread out when we've\\nreached convergence. As a result, it might not make sense to initialize those cluster centers in an\\nentirely random manner. For example, Figure 6.2 would be a poor initialization.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 89}),\n",
              " Document(page_content='82 CHAPTER 6. CLUSTERING\\nFigure 6.1: Finding the Knee.\\nFigure 6.2: Bad Cluster Initialization.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 90}),\n",
              " Document(page_content='6.3. HIERARCHICAL AGGLOMERATIVE CLUSTERING 83\\nFigure 6.3: Good Cluster Initialization.\\nWe would much rather start with a random initialization that looks like Figure 6.3.\\nWe can use the hint that we want our cluster centers somewhat spread out to \\x0cnd a better\\nrandom initialization. This is where the initialization algorithm presented by K-Means++ comes\\nin.\\nFor K-Means++, we choose the \\x0crst cluster center by randomly selecting a point in our data\\nset, same as before. However, for all subsequent cluster center initializations, we select points in\\nour data set with probability proportional to the squared distance from their nearest cluster center.\\nThe e\\x0bect of this is that we end up with a set of initializations that are relatively far from one\\nanother, as in Figure 6.3.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 91}),\n",
              " Document(page_content=\"6.2.5 K-Medoids Alternative\\nRecall that in the cluster center update step (Equation 6.4) presented in the derivation of Lloyd's\\nalgorithm, we average the data points assigned to each cluster to compute the new cluster centers.\\nNote that in some cases, this averaging step doesn't actually make sense (for example, if we have\\ncategorical variables as part of our feature set). In these cases, we can use an alternative algorithm\\nknown as K-Medoids . The idea behind K-Medoids is simple: instead of averaging the data points\\nassigned to that cluster, update the new cluster center to be the data point assigned to that cluster\\nwhich is most like the others.\\n6.3 Hierarchical Agglomerative Clustering\\nThe motivating idea behind K-Means was that we could use a distance measurement to assign data\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 91}),\n",
              " Document(page_content='points to a \\x0cxed number of clusters, iteratively improving our assignments and cluster locations', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 91}),\n",
              " Document(page_content=\"84 CHAPTER 6. CLUSTERING\\nFigure 6.4: Dendrogram Example.\\nuntil convergence.\\nMoving on to Hierarchical Agglomerative Clustering (also known as HAC - pronounced `hack'),\\nthe motivating idea is instead to group data from the bottom up. This means every data point\\nstarts as its own cluster, and then we merge clusters together based on a distance metric that\\nwe de\\x0cne. This iterative merging allows us to construct a tree over our data set that describes\\nrelationships between our data. These trees are known as dendrograms , with an example found in\\nFigure 6.4. Notice that the individual data points are the leaves of our tree, and the trunk is the\\ncluster that contains the entirety of our data set.\\nWe now formally de\\x0cne the HAC algorithm, and in the process, explain how we construct such\\na tree.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 92}),\n",
              " Document(page_content=\"6.3.1 HAC Algorithm\\n1. Start with Nclusters, one for each data point.\\n2. Measure the distance between clusters. This will require an inter-cluster distance measure-\\nment that we will de\\x0cne shortly.\\n3. Merge the two `closest' clusters together, reducing the number of clusters by 1. Record the\\ndistance between these two merged clusters.\\n4. Repeat step 2 until we're left with only a single cluster.\\nIn the remainder of the chapter, we'll describe this procedure in greater detail (including how\\nto measure the distance between clusters), explain the clustering information produced by the tree,\\nand discuss how HAC di\\x0bers from K-Means. But \\x0crst, to make this algorithm a little more clear,\\nlet's perform HAC one step at a time on a toy data set, constructing the dendrogram as we go.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 92}),\n",
              " Document(page_content=\"Example 6.2 (HAC Algorithm Example): Let's say we have a data set of \\x0cve points A, B,\\nC, D, E that we wish to perform HAC on. These points will simply be scalar data that we can\\nrepresent on a number line. We start with 5 clusters and no connections at all:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 92}),\n",
              " Document(page_content=\"6.3. HIERARCHICAL AGGLOMERATIVE CLUSTERING 85\\nWe \\x0cnd the closest two clusters to merge \\x0crst. A and B are nearest (it's actually tied with C and D,\\nbut we can arbitrarily break these ties), so we start by merging them. Notice that we also annotate\\nthe distance between them in the tree, which in this case is 1:\\nWe now have four clusters: (A, B), C, D, and E. We again \\x0cnd the closest two clusters, which in\\nthis case is C and D:\\nWe now have three remaining clusters: (A, B), (C, D), and E. We proceed as before, identifying\\nthe two closest clusters to be (A, B) and (C, D). Merging them:\\nFinally we are left with two clusters: (A, B, C, D) and E. The remaining two clusters are obviously\\nthe closest together, so we merge them:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 93}),\n",
              " Document(page_content=\"86 CHAPTER 6. CLUSTERING\\nAt this point there is only a single cluster. We have constructed our tree and are \\x0cnished with\\nHAC.\\nNotice how the distance between two merged clusters manifests itself through the height of the\\ndendrogram where they merge (which is why we tracked those distances as we constructed the\\ntree). Notice also that we now have many layers of clustering: if we're only only interested in\\nclusters whose elements are at least kunits away from each other, we can `cut' the dendrogram at\\nthat height and examine all the clusters that exist below that cut point.\\nFinally, we need to handle the important detail of how to compute the distance between clusters.\\nIn the preceding example, we designated the distance between two clusters to be the minimum\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 94}),\n",
              " Document(page_content=\"distance between any two data points in the clusters. This is what is known as the Min-Linkage\\nCriterion . However, there are certainly other ways we could have computed the distance between\\nclusters, and using a di\\x0berent distance measurement can produce di\\x0berent clustering results. We\\nnow turn to these di\\x0berent methods and the properties of clusters they produce.\\n6.3.2 Linkage Criterion\\nHere are a few of the most common linkage criteria.\\nMin-Linkage Criteria\\nWe've already seen the Min-Linkage Criterion in action from the previous example. Formally, the\\ncriterion says that the distance dC;C0between each cluster pair CandC0is given by\\ndC;C0= min\\nk;k0jjxk\\x00xk0jj (6.5)\\nwhere xkare data points in cluster Candxk0are data points in cluster C0. After computing these\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 94}),\n",
              " Document(page_content='pairwise distances, we choose to merge the two clusters that are closest together.\\nMax-Linkage Criterion\\nWe could also imagine de\\x0cning the distance dC;C0between two clusters as being the distance between\\nthe two points that are farthest apart in each cluster. This is known as the Max-Linkage Criterion.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 94}),\n",
              " Document(page_content='6.3. HIERARCHICAL AGGLOMERATIVE CLUSTERING 87\\nFigure 6.5: Di\\x0berent Linkage Criteria.\\nThe distance between two clusters is then given by:\\ndC;C0= max\\nk;k0jjxk\\x00xk0jj (6.6)\\nAs with the Min-Linkage Criterion, after computing these pairwise distances, we choose to merge\\nthe two clusters that are closest together.\\n?Be careful not to confuse the linkage criterion with which clusters we choose to merge. We always merge the clusters\\nthat have the smallest distance between them. How we compute that distance is given by the linkage criterion.\\nAverage-Linkage Criterion\\nThe Average-Linkage Criterion averages the pairwise distance between each point in each cluster.\\nFormally, this is given by:\\ndC;C0=1\\nKK0KX\\nk=1K0X\\nk0=1jjxk\\x00xk0jj (6.7)\\nCentroid-Linkage Criterion', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 95}),\n",
              " Document(page_content=\"The Centroid-Linkage Criterion uses the distance between the centroid of each cluster (which is\\nthe average of the data points in a cluster). Formally, this is given by:\\ndC;C0=jj1\\nKKX\\nk=1xk\\x001\\nK0K0X\\nk0=1xk0jj (6.8)\\nDi\\x0berent Linkage Criteria Produce Di\\x0berent Clusterings\\nIt's important to note that the linkage criterion you choose to use will in\\ruence your \\x0cnal clustering\\nresults. For example, the min-linkage criterion tends to produce `stringy' clusters, while the max-\\nlinkage criterion tends to produce more compact clusters. You can see the di\\x0berence between the\\nresults of these two linkage criteria in Figure 6.5.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 95}),\n",
              " Document(page_content=\"88 CHAPTER 6. CLUSTERING\\n?You should convince yourself of the di\\x0berent \\ravors of linkage criteria. For example, when using the min-linkage\\ncriterion, we get these `stringy' results because we're most inclined to extend existing clusters by grabbing whichever\\ndata points are closest.\\n6.3.3 How HAC Di\\x0bers from K-Means\\nNow that we're aware of two distinct clustering techniques and their variants, we consider the\\ndi\\x0berences between the two methods.\\nFirst of all, there is a fundamental di\\x0berence in determinism between HAC and K-Means. In\\ngeneral, K-Means incurs a certain amount of randomness and needs to be run multiple times to\\nensure a good result. On the other hand, once you've selected a linkage criterion for HAC, the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 96}),\n",
              " Document(page_content=\"clusters you calculate are deterministic. You only need to run HAC a single time.\\nAnother di\\x0berence between HAC and K-Means comes from the assumptions we make. For K-\\nMeans, we need to specify the number of clusters up front before running our algorithm, potentially\\nusing something like the knee-method to decide on the number of clusters. On the other hand, you\\ndon't need to assume anything to run HAC, which simpli\\x0ces its usage. However, the downside for\\nHAC is that when you wish to present your \\x0cnal clustering results, you need to decide on the max\\ndistance between elements in each cluster (so that you can cut the dendrogram).\\nThe fact that you need to make a decision about where to cut the dendrogram means that\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 96}),\n",
              " Document(page_content=\"running HAC once gives you several di\\x0berent clustering options. Furthermore, the dendrogram in\\nand of itself can be a useful tool for visualizing data. We don't get the same interactivity from\\nK-Means clustering.\\n?We often use dendrograms to visualize evolutionary lineage.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 96}),\n",
              " Document(page_content=\"Chapter 7\\nDimensionality Reduction\\nIn previous chapters covering supervised learning techniques, we often used basis functions to\\nproject our data into higher dimensions prior to applying an inference technique. This allowed us\\nto construct more expressive models, which ultimately produced better results. While it may seem\\ncounterintuitive, in this chapter we're going to focus on doing exactly the opposite: reducing the\\ndimensionality of our data through a technique known as Principle Component Analysis (PCA).\\nWe will also explore why it is useful to reduce the dimensionality of some data sets.\\n7.1 Motivation\\nReal-world data is often very high dimensional, and it's common that our data sets contain infor-\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 97}),\n",
              " Document(page_content=\"mation we are unfamiliar with because the dimensionality is too large for us to comb through all\\nthe features the by hand.\\nIn these situations, it can be very di\\x0ecult to manipulate or utilize our data e\\x0bectively. We\\ndon't have a sense for which features are `important' and which ones are just noise. Fitting a\\nmodel to the data may be computationally expensive, and even if we were to \\x0ct some sort of model\\nto our data, it may be di\\x0ecult to interpret why we obtain speci\\x0cc results. It's also hard to gain\\nintuition about our data through visualization since humans struggle to think in more than three\\ndimensions. All of these are good reasons that we may wish to reduce the dimensionality of a data\\nset.\\nML Framework Cube: Dimensionality Reduction\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 97}),\n",
              " Document(page_content=\"Dimensionality reduction operates primarily on continuous feature spaces, is fully unsupervised,\\nand is non-probabilistic for the techniques we explore in this chapter.\\nDomain Training Probabilistic\\nContinuous Unsupervised No\\nWhile dimensionality reduction is considered an unsupervised technique, it might also be\\nthought of as a tool used to make data more manageable prior to taking some other action. In fact,\\nit's an important preprocessing step for a host of use cases.\\n89\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 97}),\n",
              " Document(page_content='90 CHAPTER 7. DIMENSIONALITY REDUCTION\\nBear Heights and Weights\\nFigure 7.1: Graph of bear heights and weights.\\n7.2 Applications\\nAs described above, we need a tool like dimensionality reduction in situations where high-dimensional\\ndata hinders us. Here are a few speci\\x0cc situations where we would use such a technique:\\n1. Presenting di\\x0berences between complex molecules in two dimensions (via a graph).\\n2. Understanding the results of a credit trustworthiness algorithm.\\n3. E\\x0eciently training a neural network to predict supermarket sales on a data set with many\\ninput features.\\n4. Identifying which costly measurements are worth collecting when experimenting with new\\nchemicals.\\nWith a few of these use cases in mind, we now turn to the math that underpins the dimension-', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 98}),\n",
              " Document(page_content=\"ality reduction technique known as Priniciple Component Analysis.\\n7.3 Principle Component Analysis\\nThe main idea behind Principle Component Analysis (PCA) is that we can linearly project our\\ndata set onto a subspace without losing too much information. For example, three-dimensional\\ndata might primarily exist in a subspace that is actually a two-dimensional plane.\\nOne way to think about this is to identify and preserve the features along which there is the\\nmost variance. For example, imagine we had a data set comprised of the heights and weights of\\nindividual bears. As an extreme case, let's suppose all the bears were exactly the same height but\\nhad a wide range of weights.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 98}),\n",
              " Document(page_content='7.3. PRINCIPLE COMPONENT ANALYSIS 91\\nBear Weights\\nFigure 7.2: Bear weights.\\nConverting Between Reduced and Original Data\\nFigure 7.3: Converting between the reduced data and original data.\\nTo di\\x0berentiate our data points, we obviously only need to report the weights of the bears. The\\nvariance of the heights is 0, and the variance of the weights is some non-zero number. Intuitively,\\nthe most interesting features from our data sets are those that vary the most.\\n?In this simple example, the direction of maximal variance occurs exactly along the x1axis, but in general it will\\noccur on a plane described by a combination of our input features.\\nThe second way to think about PCA is that we are minimizing the error we incur when we', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 99}),\n",
              " Document(page_content=\"move from the lower-dimensional representation back to the original representation. This is known\\nasreconstruction loss . We can consider the meaning of this using our bear example.\\nLet's say we project the data set from Figure 7.1 here down to a single dimension by recording\\nonly the weights:\\nThen, to reconstruct our original graph, we need only to keep track of a slope and bias term\\nin the form of the familiar equation x2=mx1+b. In this case our slope is m= 0 and our bias\\nb= 3. Note that this storage overhead is constant (just remembering the slope and bias) regardless\\nof how big our data set gets. Thus we can go from our low-dimensional representation back to our\\noriginal data:\\nIt will be our goal to determine a low-dimensional representation of our data that allows us\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 99}),\n",
              " Document(page_content='to return to our high-dimensional data while losing as little information as possible. We wish\\nto preserve everything salient about the data while discarding as much redundant information as\\npossible. We now turn to how this can be achieved.\\n7.3.1 Reconstruction Loss\\nWe identi\\x0ced a key tenet of dimensionality reduction in the previous section: \\x0cnding subspaces of\\nour data that preserve as much information as possible. Concretely, this means we want to convert\\nour original data point xninDdimensions into a data point x0\\nninD0dimensions where D0<D.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 99}),\n",
              " Document(page_content=\"92 CHAPTER 7. DIMENSIONALITY REDUCTION\\nData Reconstruction\\nFigure 7.4: Far left: our original data. Middle: our reduced data in scalar form after the projection\\ngiven by x\\x01w. Right: our reconstructed data points given by ( x\\x01w)w. Notice that our reconstructed\\ndata points are not the same as our original data.\\n?We're going to assume that our data set has been centered such that each feature in xnhas mean 0. This will not\\na\\x0bect our results (we can convert back to the uncentered data by adding back the mean of each feature), but will\\nmake our derivations more convenient to work with.\\nLet's consider a simple case \\x0crst: D0= 1. This means that we're projecting our Ddimensional\\ndata down onto just a single dimension, or in geometric terms, we're projecting our data points\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 100}),\n",
              " Document(page_content='xnonto a line through the origin. We can de\\x0cne this line as the unit vector w2RD\\x021, and the\\nprojection is given by the dot product x\\x01w.\\n?The unit vector wonto which we project our data is known as a principle component , from which PCA gets its\\nname.\\nThis projection produces a scalar, and that scalar de\\x0cnes how far our projection x\\x01wis from\\nthe origin. We can convert this scalar back to Ddimensional space by multiplying it with the\\nunit vector w. This means that ( x\\x01w)wis the result of projecting our data point xdown into\\none-dimension and then converting it to its coordinate location in Ddimensions. We refer to these\\nas our projection vectors , and we can observe what this looks like geometrically in Figure 7.4.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 100}),\n",
              " Document(page_content='The projection vectors we recover from the expression ( x\\x01w)wwill be inDdimensions, but\\nthey will obviously not be identical to the original Ddimensional vectors (Figure 7.4 demonstrates\\nwhy that is the case). This di\\x0berence between the original and projection vectors can be thought\\nof as error, since it is information lost from our original data. For a given data point xnand unit\\nvector w, we can measure this error through the expression:\\njjxn\\x00(x\\x01w)wjj2(7.1)\\nwhich is known as reconstruction loss because it measures the error incurred when reconstructing\\nour original data from its projection.\\nDe\\x0cnition 7.3.1 (Reconstruction Loss): Reconstruction loss is the di\\x0berence (measured via a\\ndistance metric such as Euclidean distance) between an original data set and its reconstruction from', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 100}),\n",
              " Document(page_content=\"a lower dimensional representation. It indicates how much information is lost during dimensionality\\nreduction.\\nReconstruction loss is then a metric for evaluating how `good' a subspace in D0dimensions is\\nat representing our original data in Ddimensions. The better it is, the less information we lose,\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 100}),\n",
              " Document(page_content='7.3. PRINCIPLE COMPONENT ANALYSIS 93\\nand the reconstruction loss is lower as a result.\\n7.3.2 Minimizing Reconstruction Loss\\nWe now know that our goal is to \\x0cnd a good subspace to project onto, and we also know that\\n\\x0cnding this good subspace is equivalent to minimizing the reconstruction loss it incurs. We can\\nnow formalize this as an optimization problem.\\nFirst, we simplify the reconstruction loss for a single data point xnas follows:\\njjxn\\x00(xn\\x01w)wjj2= (xn\\x00(xn\\x01w)w)(xn\\x00(xn\\x01w)w)\\n=jjxnjj2\\x002(xn\\x01w)2+ (xn\\x01w)2jjwjj2\\n=jjxnjj2\\x00(xn\\x01w)2\\nwherejjwjj2= 1 because it is a unit vector. Note that we can de\\x0cne reconstruction loss over our\\nentire data set as follows:\\nRL(w) =1\\nnNX\\nn=1jjxnjj2\\x00(xn\\x01w)2(7.2)\\nRecall that our goal is to minimize reconstruction loss over our data set by optimizing the subspace', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 101}),\n",
              " Document(page_content=\"de\\x0cned by w. Let's \\x0crst rewrite Equation 7.2 as:\\nmin\\nwRL(w) =1\\nnNX\\nn=1jjxnjj2\\x001\\nnNX\\nn=1(xn\\x01w)2\\nwhere we can see that our optimization will depend only on maximizing the second term:\\nmax\\nw1\\nnNX\\nn=1(xn\\x01w)2(7.3)\\nsince it is the only one involving w. Recall that the sample mean of a data set is given by the\\nexpression1\\nnPN\\nn=1xn, and note that Equation 7.3 is the sample mean of ( x\\x01w)2. Using the\\nde\\x0cnition of variance for a random variable Z(which is given by Var(Z) =E(Z2)\\x00(E(Z))2), we\\ncan rewrite Equation 7.3 as:\\n1\\nnNX\\nn=1(xn\\x01w)2=Var\\x02\\nfxn\\x01wgN\\nn=1\\x03\\n+\\x00\\nE\\x02\\nfxn\\x01wgN\\nn=1\\x03\\x012\\nRecall that we centered our data xnto have mean 0 such that the expression above simpli\\x0ces to:\\n1\\nnNX\\nn=1(xn\\x01w)2=Var\\x02\\nfxn\\x01wgN\\nn=1\\x03\\n(7.4)\\nand therefore Var\\x02\\nfxn\\x01wgN\\nn=1\\x03\\nis the term we wish to maximize. This means that minimizing\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 101}),\n",
              " Document(page_content='the reconstruction loss is equivalent to maximizing the variance of our projections\\nfxn\\x01wgN\\nn=1.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 101}),\n",
              " Document(page_content=\"94 CHAPTER 7. DIMENSIONALITY REDUCTION\\n?Note the intuitiveness of this result. We should like to \\x0cnd a subspace that maintains the spread in our data.\\n7.3.3 Multiple Principle Components\\nUp until now, we've been considering how we would project onto a single principle component\\nw2RD\\x021. This will reduce our data down to one dimension, just a scalar. In general, we will\\nwish to preserve more of our data than just a single dimension (in order to capture more of the\\nvariance in our data and reduce reconstruction loss), which means that we will need to have multiple\\nprincipal components. For now we'll assume that our principal components are orthogonal (we will\\nprove this later), which then allows us to describe the projection of our data xnonto this subspace\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 102}),\n",
              " Document(page_content='as the sum of the projections onto D0orthogonal vectors:\\nD0X\\nd0=1(xn\\x01wd0)wd0 (7.5)\\n7.3.4 Identifying Directions of Maximal Variance in our Data\\nWe now know from the previous section that we \\x0cnd our principle components (and thus the\\nsubspace we will project onto) by identifying the directions of maximum variance in our projected\\ndata set. We know from Equation 7.4 that the variance is equivalent to:\\n\\x1b2\\nw\\x11Var\\x02\\nfxn\\x01wgN\\nn=1\\x03\\n=1\\nnNX\\nn=1(xn\\x01w)2\\nRewriting this in terms of matrix notation we have that:\\n\\x1b2\\nw=1\\nn(Xw)T(Xw)\\nWe can further simplify this:\\n\\x1b2\\nw=1\\nnwTXTXw\\n\\x1b2\\nw=1\\nnwTXTXw\\n\\x1b2\\nw=wTXTX\\nnw\\n\\x1b2\\nw=wTSw\\nwhere S=XTX\\nnis the empirical covariance matrix of our data set.\\n?Notice that by convention we describe the empirical covariance of a data set with the term Sinstead of the usual', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 102}),\n",
              " Document(page_content='covariance term \\x06.\\nOur goal is to maximize the term \\x1b2\\nw=Var\\x02\\nfxn\\x01wgN\\nn=1\\x03\\nwith respect to w. Furthermore, wis\\na unit vector, so we must optimize subject to the constraint wTw= 1. Recalling the discussion of', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 102}),\n",
              " Document(page_content='7.3. PRINCIPLE COMPONENT ANALYSIS 95\\nLagrange multipliers from Chapter 6 on Support Vector Machines, we incorporate this constraint\\nby reformulating our optimization problem as the Lagrangian equation:\\nL(w;\\x15) =wTSw\\x00\\x15(wTw\\x001)\\nAs usual, we proceed by taking the derivative with respect to each parameter:\\ndL(w;\\x15)\\ndw= 2Sw\\x002\\x15w\\ndL(w;\\x15)\\nd\\x15=wTw\\x001\\nWe can now set these equal to 0 and solve for the optimal values:\\nSw=\\x15w\\nwTw= 1\\nThis result is very signi\\x0ccant! As we knew already, we needed wto be a unit vector. However, we\\nalso see that wis an eigenvector of the empirical covariance matrix w. Futhermore, the eigenvector\\nthat will maximize our quantity of interest \\x1b2\\nw=wTSwwill be the eigenvector with the largest', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 103}),\n",
              " Document(page_content=\"eigenvalue\\x15. Fortunately, linear algebra gives us many tools for \\x0cnding eigenvectors, and as a result\\nwe can e\\x0eciently identify our principal components. Note also that the eigenvectors of a symmetric\\nmatrix are orthogonal, which proves our earlier assumption that our principal components are\\northogonal.\\n?Each eigenvector is a principle component. The larger the eigenvalue associated with that principle component,\\nthe more variance there is along that principle component.\\nTo recap, we've learned that the optimal principal components (meaning the vectors describing\\nour projection subspace) are the eigenvectors of the empirical covariance matrix of our data set.\\nThe vector preserving the most variance in our data (and thus minimizing the reconstruction loss)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 103}),\n",
              " Document(page_content='is given by the eigenvector with the largest eigenvalue, followed by the eigenvector with the next\\nlargest eigenvalue, and so on. Furthermore, while it is somewhat outside the scope of this textbook,\\nwe are guaranteed to have Ddistinct, orthogonal eigenvectors with eigenvalues \\x150. This is a result\\nof linear algebra that hinges on the fact that our empirical covariance matrix Sis symmetric and\\npositive semi-de\\x0cnite.\\n7.3.5 Choosing the Optimal Number of Principal Components\\nWe now know that the eigenvectors of the empirical covariance matrix Sgive us the principal\\ncomponents that form our projection subspace. Note that the exact procedure for \\x0cnding these\\neigenvectors is a topic better suited for a book on linear algebra, but if you are interested, you can', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 103}),\n",
              " Document(page_content='look into a topic known as Singular Value Decomposition (SVD). For our purposes, we will assume\\nthere is a black box that accepts Sand returns a list of the Dprincipal components.\\nBecause these principal components are orthogonal, the projections they produce will be entirely\\nuncorrelated. This means we can project our original data onto each component individually and', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 103}),\n",
              " Document(page_content=\"96 CHAPTER 7. DIMENSIONALITY REDUCTION\\nFour Dimensional Iris Data Set in Three Dimensions\\nFigure 7.5: PCA applied to Fisher's Iris data set, which is originally in four dimensions. We reduce\\nit to three dimensions for visualization purposes and label the di\\x0berent \\rower types. This example\\nis taken from the sklearn documentation.\\nthen sum those projections to create our lower dimensional data points. Note that it doesn't make\\nsense that we would use every one of our Dprincipal components to de\\x0cne our projection subspace,\\nsince that wouldn't lead to a reduction in the dimensionality of our data at all (the Dorthogonal\\nprincipal components span the entire Ddimensional space of our original data set). We now need\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 104}),\n",
              " Document(page_content=\"to decide how many principal components we will choose to include, and therefore what subspace\\nwe will be projecting onto.\\nThe `right' number of principal components to use depends on our goals. For example, if we\\nsimply wish to visualize our data, then we would project onto a 2D or 3D space. Therefore, we\\nwould choose the \\x0crst 2 or 3 principal components, and project our original data onto the subspace\\nde\\x0cned by those vectors. This might look something like Figure 7.5.\\nHowever, it's more complicated to choose the optimal number of principal components when our\\ngoal is not simply visualization. We're now left with the task of trading o\\x0b how much dimensionality\\nreduction we wish to achieve with how much information we want to preserve in our data.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 104}),\n",
              " Document(page_content=\"One way to do this is similar to the informal `elbow' method described for K-Means clustering.\\nWe graph our reconstruction loss against the number of principal components used, as seen in\\nFigure 7.6. The idea is to add principal components to our subspace one at a time, calculating\\nthe reconstruction loss as we go. The \\x0crst few principal components will greatly reduce the recon-\\nstruction loss, before eventually leveling o\\x0b. We can identify the `elbow' where the reduction in\\nloss starts to diminish, and choose to use that number of principal components.\\nAnother way to do this is to consider how much variance we wish to preserve in our data. Each\\nprincipal component is associated with an eigenvalue \\x15dthat indicates what proportion of the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 104}),\n",
              " Document(page_content='variance that principal component is responsible for in our data set. Then the fraction of variance', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 104}),\n",
              " Document(page_content=\"7.4. CONCLUSION 97\\nReconstruction Loss vs. Number of Principal Components\\nFigure 7.6: Reconstruction loss versus the number of principal components. Notice the similarity\\nto the `elbow' method of K-Means clustering.\\nretained from our data set if we choose to keep D0principal components is given by:\\nretained variance =PD0\\nd0=1\\x15d0\\nPD\\nd=1\\x15d(7.6)\\nFor di\\x0berent applications, there may be di\\x0berent levels of acceptable variance retention, which can\\nhelp us decide how many principal components to keep.\\nFinally, once we have selected our principal components, we have also de\\x0cned the subspace onto\\nwhich we will be projecting our original data. And although this subspace is de\\x0cned by the basis\\ngiven by our principal components, these principal components are not a unique description of that\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 105}),\n",
              " Document(page_content=\"subspace. We could choose to use any basis after we've identi\\x0ced our subspace through the principal\\ncomponents. The importance of this idea is simply that although our principal components are\\nunique, they are not the only basis we could use to de\\x0cne the same projection subspace.\\n7.4 Conclusion\\nPrincipal component analysis is useful for visualization purposes, removing redundant informa-\\ntion, or making a data set more computationally manageable. PCA is also a good tool for data\\nexploration, particularly when digging into an unfamiliar data set for the \\x0crst time.\\nIt is not essential that we know by heart the exact derivation for arriving at the principal\\ncomponents of a data set. The same can be said of the linear algebra machinery needed to compute\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 105}),\n",
              " Document(page_content='principal components. However, it is important to have an intuitve grasp over how variance in\\nour data set relates to principal components, as well as an understanding of how subspaces in our', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 105}),\n",
              " Document(page_content='98 CHAPTER 7. DIMENSIONALITY REDUCTION\\ndata can provide compact representations of that data set. These are critical concepts for working\\ne\\x0bectively with real data, and they will motivate related techniques in machine learning.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 106}),\n",
              " Document(page_content=\"Chapter 8\\nGraphical Models\\nMathematics, statistics, physics, and other academic \\x0celds have useful notational systems. As a\\nhybrid of these and other disciplines, machine learning borrows from many of the existing systems.\\nNotational abstractions are important to enable consistent and e\\x0ecient communication of ideas, for\\nboth teaching and knowledge creation purposes. Much of machine learning revolves around mod-\\neling data processes, and then performing inference over those models to generate useful insights.\\nIn this chapter, we will be introducing a notational system known as the directed graphical model\\n(DGM) that will help us reason about a broad class of models.\\n8.1 Motivation\\nUp until this point, we've de\\x0cned notation on the \\ry, relied on common statistical concepts, and\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 107}),\n",
              " Document(page_content=\"used diagrams to convey meaning about the problem setup for di\\x0berent techniques. We've built\\nup enough working knowledge and intuition at this point to switch to a more general abstraction\\nfor de\\x0cning models: directed graphical models (DGMS). DGMs will allow us to both consolidate\\nour notation and convey information about arbitrary problem formulations. An example of what\\na DGM looks like for a linear regression problem setup is given in Figure 8.1, and over the course\\nof the chapter, we'll explain how to interpret the symbols in this diagram.\\nWe need graphical models for a couple of reasons. First, and most importantly, a graphical\\nmodel unambiguously conveys a problem setup. This is useful both to share models between\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 107}),\n",
              " Document(page_content='people (communication) and to keep all the information in a speci\\x0cc model clear in your own head\\n(consolidation). Once we understand the meaning of the symbols in a DGM, it will be far easier to\\nFigure 8.1: Linear regression model expressed with a DGM.\\n99', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 107}),\n",
              " Document(page_content=\"100 CHAPTER 8. GRAPHICAL MODELS\\nFigure 8.2: Random variables are denoted with an open circle, and it is shaded if the variable is\\nobserved.\\nFigure 8.3: Deterministic parameters are denoted with a tight, small dot.\\nexamine one of them than it will be to read several sentences describing the type of model we're\\nimagining for a speci\\x0cc problem. Another reason we use DGMs is that they help us reason about\\nindependence properties between di\\x0berent parts of our model. For simple problem setups this may\\nbe easy to keep track of in our heads, but as we introduce more complicated models it will be useful\\nto reason about independence properties simply by examining the DGM describing that model.\\nUltimately, directed graphical models are a tool to boost e\\x0eciency and clarity. We'll examine\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 108}),\n",
              " Document(page_content=\"the core components of a DGM, as well as some of their properties regarding independence and\\nmodel complexity. The machinery we develop here will be used heavily in the coming chapters.\\n8.2 Directed Graphical Models (Bayesian Networks)\\nThere are a few fundamental components to all of the models we've examined so far. In fact, we can\\nmodel just about everything we've discussed to this point using just random variables, deterministic\\nparameters, and arrows to indicate the relationships between them. Let's consider linear regression\\nas a simple but comprehensive example. We have a random variable yn, the object of predictive\\ninterest, which depend on deterministic parameters in the form of data xnand weights w. This\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 108}),\n",
              " Document(page_content=\"results in the DGM given by Figure 8.1. There are four primary pieces of notation that the linear\\nregression setup gives rise to, and these four components form the backbone of every DGM we\\nwould like to construct.\\nFirst, we have random variables represented by an open circle, shown in Figure 8.2. Note that\\nif we observe a random variable of a given model, then we shade it in. Otherwise, it's left open.\\nSecond, we have deterministic parameters represented by a tight, small dot, shown in Figure\\n8.3.\\nThird, we have arrows that indicate the dependence relationship between di\\x0berent random\\nvariables and parameters, shown in Figure 8.4. Note that an arrow from XintoYmeans that Y\\ndepends on X.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 108}),\n",
              " Document(page_content='8.2. DIRECTED GRAPHICAL MODELS (BAYESIAN NETWORKS) 101\\nFigure 8.4: Arrows indicate dependence relationships.\\nFigure 8.5: Plates indicate repeated sets of variables. Often there will be a number in one of the\\ncorners (N in this case) indicating how many times that variable is repeated.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 109}),\n",
              " Document(page_content=\"102 CHAPTER 8. GRAPHICAL MODELS\\nFigure 8.6: DGM for the joint distribution give by Equation 8.1.\\nAnd \\x0cnally, we have plate notation to indicate that we have repeated sets of variables in our\\nmodel setup, shown in Figure 8.5.\\nWith these four simple constructs, we can describe complex model setups with a simple diagram.\\nWe can have an arbitrary number of component with any sort of dependence structure baked in.\\nDGMs can be useful as a reference while working on a problem, and they also make it easy to\\niterate on an existing model setup.\\n8.2.1 Joint Probability Distributions\\nWe'll now consider how DGMs simplify the task of reasoning about a joint probability distribution\\nover multiple random variables. Note that for any joint probability distribution, regardless of our\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 110}),\n",
              " Document(page_content=\"knowledge about the dependence structure in the model, it's always valid to write a generic joint\\nprobability distribution as follows:\\np(A;B;C )\\nwhere in this setup, we are interested in the joint distribution between three random variables\\nA;B;C . However, this doesn't tell us anything about the structure of the problem at hand: where\\nthere is independence and how we can use that to simplify our model. For example, if we knew\\nthatBandCwere independent and we also knew the conditional distribution of AjB;C then we\\nwould much rather setup our joint probability equation as:\\np(A;B;C ) =p(B)p(C)p(AjB;C) (8.1)\\nDGMs assist in this process of identifying the appropriate factorization, as their structure allows\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 110}),\n",
              " Document(page_content='us to read o\\x0b valid factorizations directly. For example, the joint distribution given by Equation\\n8.1 can be read from Figure 8.6.\\nWe can move between a DGM and a valid factorized joint distribution by identifying the arrows\\nindicating dependencies. If a random variable has no dependencies (as neither BnorCdo in\\nthis example), they can be written on their own as marginal probabiilties p(B) andp(C). For\\nrandom variables with arrows coming into them, indicating dependence, we include them in the\\njoint factorization conditioned on the variables that they depend on, i.e. P(AjB;C). In this way\\nwe can move back and forth between DGMs and factorized joint distributions with ease.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 110}),\n",
              " Document(page_content='8.2. DIRECTED GRAPHICAL MODELS (BAYESIAN NETWORKS) 103\\nFigure 8.7: Example of a generative model.\\n8.2.2 Generative Models\\nWhile DGMs allow us to move quickly between a factorized joint distribution and a corresponding\\ngraphical model, they also show us the process by which data comes into existence (sometimes\\nreferred to as the data generating story or generative process). What this means is that if presented\\nwith a DGM, it is possible for us to identify how the data gets created, and if we have the proper\\ntools, how we could generate new data ourselves.\\nDe\\x0cnition 8.2.1 (Generative Models): A generative model describes the entire process by\\nwhich data comes into existence. While this is not always necessary if our goal is only to make', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 111}),\n",
              " Document(page_content=\"predictions or perform some other kind of inference, it does have the added bene\\x0ct of enabling the\\ncreation of new data by sampling from the generative model.\\n?Note that we can create graphical models for both generative and discriminative models. Discriminative models\\nwill only model the conditional distribution p(YjZ), while generative models will model the full joint distribution\\np(Z;Y).\\nLet's consider a simple example to see how this works in practice. Consider the \\row of in-\\nformation present in Figure 8.7. First, there is some realization of the random variable Z. Then\\nconditioned on that value of Z, there is some realization of the random variable Y. Obviously, the\\njoint factorization for this DGM is given by p(Z)p(YjZ), but on a more intuitive level, the data is\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 111}),\n",
              " Document(page_content=\"created by \\x0crst sampling from Z's distribution, and then based on that value, sampling from the\\nconditional distribution of Y.\\nTo make this concrete, we could consider Zto be a random variable that determines a speci\\x0cc\\nbreed of dog, and Yto be the random variable that, conditioned on the breed of dog, determines\\nthe snout length of that type of dog. Notice that we have not speci\\x0ced anything about the speci\\x0cc\\ndistributional form from which ZandYcome, only the story of how they relate to each other.\\nThis story also shows us that if we had some model for ZandYjZ, we could generate data\\npoints ourselves. Our procedure would simply be to sample from Zand then to sample from\\nYconditioned on that value of Z. We could perform this process as many times as we like to\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 111}),\n",
              " Document(page_content=\"generate new data. This is in contrast to sampling directly from the joint p(Z;Y), which is di\\x0ecult\\nif we don't know the exact form of the joint distribution (which we often do not) or if the joint\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 111}),\n",
              " Document(page_content='104 CHAPTER 8. GRAPHICAL MODELS\\nFigure 8.8: Notice we have to sample these in topological order: A, D, B, E, C.\\ndistribution is hard to sample from directly.\\nThe technique of sampling from distributions in the order indicated by their DGM is known as\\nancestral sampling , and it is a major bene\\x0ct of generative models.\\nDe\\x0cnition 8.2.2 (Ancestral Sampling): Ancestral sampling is a technique used to generate\\ndata from an arbitrary DGM. It works by sampling from the random variables in topological order,\\nmeaning that we \\x0crst sample from all random variables without any dependence, then from the\\nrandom variables that depend on those intially sampled random variables, and so on until all the\\nrandom variables have been sampled. This is demonstrated in Figure 8.8.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 112}),\n",
              " Document(page_content=\"8.2.3 Generative Modeling vs. Discriminative Modeling\\nIn the previous section, we described generative modeling. You may have wondered if there was\\nany other type of modeling possible, if not the model that describes how data comes into existence.\\nThere is another type of model known as a discriminative model, and we have already seen several\\nexamples of them.\\nA discriminitive model skips the step of describing how data was generated (i.e. it doesn't\\nmodel the joint p(Z;Y)), and instead it cuts right to our predictive objective (i.e. it models the\\nconditional p(YjZ)). For example, if we wish to predict what value a response variable will take\\non, we can consider the input data points to be parameters without an underlying distribution, and\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 112}),\n",
              " Document(page_content=\"then our model is simply tasked with predicting the response variable based on those parameters.\\nThis is in contrast to a generative model, which would model how all the various data points came\\ninto existence by assigning a distribution to each of them.\\nDiscriminative modeling is exactly what we did with linear and logistic regression, and it's\\ncommonly what we do with SVMs and neural networks as well. Let's consider the DGM describing\\nlinear regression again, from Figure 8.1. Notice that the data points xnare not random variables\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 112}),\n",
              " Document(page_content=\"8.2. DIRECTED GRAPHICAL MODELS (BAYESIAN NETWORKS) 105\\nFigure 8.9: Linear regression DGM, modeling xnas a random variable.\\nbut merely parameters of the DGM. If we wanted a generative model, we would instead have a\\nDGM that looks that of Figure 8.9.\\nThe di\\x0berence between these model setups is signi\\x0ccant. The generative model for linear re-\\ngression would allow us to generate new data points, but it is also signi\\x0ccantly more complex to\\nhandle because now instead of having just a single response variable to predict, we also have to\\ncontend with how we model the generation of the data points xn. This may be di\\x0ecult on both\\nconceptual and computational levels. This doesn't mean we'll never try to do this, but if our goal\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 113}),\n",
              " Document(page_content=\"is simply to make predictions about the response variable yn, it may be overkill to use a generative\\nmodel.\\nIn essence, the distinction between generative and discriminative models comes down to whether\\nor not the model tries to describe how the data is realized or if the model simply tries to perform\\na speci\\x0cc inference task without modeling the entirety of the data generating process. Neither one\\nis better, they are just di\\x0berent techniques that will apply di\\x0berently depending on your modeling\\nand inferential needs.\\n8.2.4 Understanding Complexity\\nWe've already motivated one of the primary uses of DGMs as being the ability to convert a joint\\ndistribution into a factorization. At the heart of that task was recognizing and exploiting indepen-\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 113}),\n",
              " Document(page_content=\"dence properties in a model over multiple random variables. Another bene\\x0ct of this process is that\\nit allows us to easily reason about the size (also called `complexity') of a joint factorization over\\ndiscrete random variables. In other words, it allows us to determine how many parameters we will\\nhave to learn to describe the factorization for a given DGM.\\nLet's consider an example to make this concept clear. Let's say we have four categorical random\\nvariables A, B, C, D which take on 2, 4, 8, and 16 values respectively. If we were to assume full\\ndependence between each of these random variables, then a joint distribution table over all of\\nthese random variables would require (2 \\x034\\x038\\x0316)\\x001 total parameters (where each parameter\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 113}),\n",
              " Document(page_content='corresponds to the probability of a speci\\x0cc permutation of the values A, B, C, D).', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 113}),\n",
              " Document(page_content='106 CHAPTER 8. GRAPHICAL MODELS\\nFigure 8.10: Conditioned on A, we have that B, C, and D are independent.\\nFigure 8.11: The three random variable relationships that will tell us about independence relation-\\nships.\\n?Notice that the number of parameters we need is (2 \\x034\\x038\\x0316)\\x001 and not (2\\x034\\x038\\x0316). This is simply because\\nif we know the \\x0crst (2 \\x034\\x038\\x0316)\\x001 parameters, we can calculate the value of the \\x0cnal one exactly.\\nHowever, if we knew that some of these random variables were conditionally independent, then\\nthe number of parameters would change. For example, consider the joint distribution given by\\np(A;B;C;D ) =p(A)p(BjA)p(CjA)p(DjA). This would imply that conditioned on A, each of\\nB;C;D were conditionally independent. This can also be shown by the DGM in Figure 8.10.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 114}),\n",
              " Document(page_content=\"In this case, a table of parameters to describe this joint distribution would only require 2 \\x03((4\\x00\\n1) + (8\\x001) + (16\\x001)) parameters, which is signi\\x0ccantly less.\\nThis leads to the natural conclusion that the more conditional independence we can identify\\nin a given model, the easier it becomes from a modeling and computational perspective. This is\\nanother major bene\\x0ct of DGMs: it's possible to visually reason about the independence properties\\nof a given model. We turn to how this works next.\\n8.2.5 Independence and D-Separation\\nWe can use the form of a graphical model directly to determine which variables are independent\\nunder speci\\x0cc observation assumptions. We have three base cases for the relationship between\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 114}),\n",
              " Document(page_content=\"variables from which we can reason about the structure in any arbitrarily complex model. The\\nthree cases look like what's found in Figure 8.11. For each of these cases, there is a notion of\\ninformation either \\rowing from one random variable to the other or being `blocked' (implying\\nindependence) by an observation. Speci\\x0ccally, case 1 and case 2 have information between nodes A\\nand C `blocked' by observing node B, and case 3 has information between nodes A and C `blocked'\\nbynotobserving node B.\\nLet's consider each of these cases more carefully, and gain a better notion of what it means\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 114}),\n",
              " Document(page_content=\"8.2. DIRECTED GRAPHICAL MODELS (BAYESIAN NETWORKS) 107\\nFigure 8.12: First structure, unobserved.\\nFigure 8.13: First structure, observed.\\nfor observations to cause information to be blocked. This will lead naturally to an understanding\\nof independence assumptions between random variables. Considering the \\x0crst example random\\nvariable structure, shown in Figure 8.12.\\nWe can factorize this as follows:\\np(A;B;C ) =p(B)p(AjB)p(CjB)\\nWe know that for this case, A and C are not independent (note that we have not observed B).\\nTherefore, we say that information \\rows from A to C. However, once we've observed B, we have\\nthat A and B are conditionally independent, shown in Figure 8.13.\\nWe now say that the \\row of information from A to C is `blocked' by the observation of B. Thus\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 115}),\n",
              " Document(page_content=\"they are conditionally independent. Intuitively, if we observe A but not B, then we have some\\ninformation about what B might be and therefore also what C might be. The same applies in the\\nother direction: observing C but not B.\\nMoving on to the second random variable structure, shown in Figure 8.14, we again consider\\nthe unobserved case \\x0crst.\\nThis allows us to write the joint distribution as:\\np(A;B;C ) =p(A)p(BjA)p(CjB)\\nWe have that for this case, A and C are not independent if we have not observed C. Information\\nis \\rowing from A to B through C. However, once we've observed B, then we have that A and C are\\nagain conditionally independent, shown in Figure 8.15.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 115}),\n",
              " Document(page_content=\"108 CHAPTER 8. GRAPHICAL MODELS\\nFigure 8.14: Second structure, unobserved.\\nFigure 8.15: Second structure, observed.\\nWe again say that the \\row of information from A to C is `blocked' by the observation of B.\\nIntuitively, if we observed A but not B, we have some information about what B might be and\\ntherefore what C might be as well. The same applies in the other direction: observing C but not\\nB.\\nNotice that these \\x0crst two cases behave in the same manner: observing a random variable\\nin between two other random variable `blocks' information from \\rowing between the two outer\\nrandom variables. In the third and \\x0cnal case the opposite is true. Not observing data in this case\\nwill `block' information, and we will explain this shift through an idea known as `explaining away'.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 116}),\n",
              " Document(page_content=\"We have the third and \\x0cnal random variable structure, shown in Figure 8.16. We consider the\\nunobserved case \\x0crst.\\nIn this setup, we say that information from A to C is being `blocked' by the unobserved variable\\nFigure 8.16: Third structure, unobserved.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 116}),\n",
              " Document(page_content=\"8.2. DIRECTED GRAPHICAL MODELS (BAYESIAN NETWORKS) 109\\nFigure 8.17: Third structure, observed.\\nB. Thus A and C are currently conditionally independent. However, once we've observed B, as\\nshown in Figure 8.17, the information \\row changes.\\nNow, information is \\rowing between A and C through the observed variable B, and thus A\\nand C are now conditionally independent. This phenomenon, where the observation of the random\\nvariable in the middle creates conditional dependence is known as explaining away . The idea relies\\non the fact that now that we know the value for B, we have some idea of how much A or C may\\nhave contributed to B adopting that value. An example might make this phenomenon more clear.\\nLet's consider that the random variable A corresponds to whether or not it rained on a certain\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 117}),\n",
              " Document(page_content=\"day, the random variable B corresponds to the lawn being wet, and the random variable C corre-\\nsponds to the sprinkler being on. Let's say we observe B: the lawn is wet. Let's say we then observe\\nvariable A: it has not rained today. Intuitively, we would now assume that variable C would have\\nthe value that the sprinkler has been on, because that's the only way for the lawn to be wet. This is\\nexactly the phenomenon of explaining away. Observing B unblocks the \\row of information between\\nA and C because we can now use an observation to `explain' how B got its value, and therefore\\ndetermine what the other unobserved value might have been.\\nNotice that we've only described three simple cases relating dependence relationships between\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 117}),\n",
              " Document(page_content=\"random variables in a DGM, but with just these three cases, we can determine the dependence\\nstructure of any arbitrarily complicated DGM. We just have to consider how information \\rows\\nfrom node to node. If information gets `blocked' at any point in our DGM network because of an\\nobservation (or lack thereof), then we gain some knowledge about independence within our model.\\nConsider the dependence between random variables A and F in Figure 8.18. Initially, before any\\nobservations are made, we can see that A and F are dependent (information \\rows from A through\\nB). However, after observing B, A and F become independent (because information blocked at both\\nthe observed B and unobserved D). Finally, after observing D, A and F are once again dependent.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 117}),\n",
              " Document(page_content=\"Now we have information that \\rows from A through D.\\n?In some other resources, you'll come upon the idea of `D-separation' or `D-connection'. D-separation is simply\\napplying the principles outlined above to determine if two nodes are independent, or D-separated. On the other\\nhand, two-nodes that are D-connected are dependent on one another.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 117}),\n",
              " Document(page_content=\"110 CHAPTER 8. GRAPHICAL MODELS\\nFigure 8.18: Notice how the independence between A and F depends on observations made within\\nthe network.\\nFigure 8.19: DGM for Naive Bayes problem setup.\\n8.3 Example: Naive Bayes\\nRecall from the chapter on classi\\x0ccation the Naive Bayes model. As a quick recap, Naive Bayes\\nmakes the assumption that for a single observation coming from a speci\\x0cc class (for example, our\\nclasses could be di\\x0berent dog breeds), the data associated with that observation are independent\\n(for example, the data could be fur color, snout length, weight, etc.).\\nWe can set up the Naive Bayes problem speci\\x0ccation using the DGM form, as we see in Figure\\n8.19.\\nEven if we hadn't heard of Naive Bayes before, we would understand this model and the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 118}),\n",
              " Document(page_content=\"implications of the model, simply by an examination of the DGM that describes it. We can\\ndirectly read o\\x0b the factorization described above that is the whole point of Naive Bayes:\\np(yn;xn1;:::;xnJ) =p(yn)p(xn1jyn)\\x01\\x01\\x01p(xnJjyn)\\nWriting this factorization is facilitated directly by our DGM, even if we've never heard of Naive\\nBayes before. It provides a common language for us to move \\ruidly between detailed probability\\nfactorizations and general modeling intuition.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 118}),\n",
              " Document(page_content=\"8.4. CONCLUSION 111\\n8.4 Conclusion\\nDirected graphical models are indispensible for model visualization and e\\x0bective communication of\\nmodeling ideas. With an understanding of what DGMs are meant to represent, it's much easier\\nto dig into more complex probabilistic models. In a lot of ways, this chapter is preparation for\\nwhere we head next. The topics of the following chapters will rely heavily on DGMs to explain\\ntheir structure, use cases, and interesting variants.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 119}),\n",
              " Document(page_content=\"Chapter 9\\nMixture Models\\nThe real world often generates observable data that falls into a combination of unseen categories.\\nFor example, at a speci\\x0cc moment in time I could record sound waves on a busy street that come\\nfrom a combination of cars, pedestrians, and animals. If I were to try to model my data points, it\\nwould be helpful if I could group them by source, even though I didn't observe where each sound\\nwave came from individually.\\nIn this chapter we explore what are known as mixture models. Their purpose is to handle data\\ngenerated by a combination of unobserved categories. We would like to discover the properties of\\nthese individual categories and determine how they mix together to produce the data we observe.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 120}),\n",
              " Document(page_content='We consider the statistical ideas underpinning mixture models, as well as how they can be used in\\npractice.\\n9.1 Motivation\\nMixture models are used to model data involving latent variables .\\nDe\\x0cnition 9.1.1 (Latent Variable): A latent variable is a piece of data that is not observed,\\nbut that in\\ruences the observed data. We often wish to create models that capture the behavior\\nof our latent variables.\\nWe are sometimes unable to observe all the data present in a given system. For example,\\nif we measure the snout length of di\\x0berent animals but only get to see the snout measurements\\nthemselves, the latent variable would be the type of animal we are measuring for each data point.\\nFor most data generating processes, we will only have access to a portion of the data and the rest', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 120}),\n",
              " Document(page_content='will be hidden from us. However, if we can \\x0cnd some way to also model the latent variables, our\\nmodel will potentially be much richer, and we will also be able to probe it with more interesting\\nquestions. To build some intuition about latent variable models, we present a simple directed\\ngraphical model with a latent variable znin Figure 9.1.\\nOne common means of modeling data involving latent variables, and the topic of this chapter,\\nis known as a mixture model .\\nDe\\x0cnition 9.1.2 (Mixture Model): A mixture model captures the behavior of data coming from\\na combination of di\\x0berent distributions.\\nAt a high level, a mixture model operates under the assumption that our data is generated by\\n\\x0crst sampling a discrete class, and then sampling a data point from within that category according\\n112', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 120}),\n",
              " Document(page_content=\"9.1. MOTIVATION 113\\nFigure 9.1: Directed graphical model with a latent variable z.\\nto the distribution for that category. For the example of animal snouts, we would \\x0crst sample a\\nspecies of animal, and then based on the distribution of snout lengths in that species, we would\\nsample an observation to get a complete data point.\\nProbabilistically, sampling a class (which is our latent variable, since we don't actually observe\\nit) happens according to a Categorical distribution, and we typically refer to the latent variable as\\nz. Thus:\\np(z=Ck;\\x12) =\\x12k\\nwhereCkis classk, and\\x12is the parameter to the Categorical distribution that speci\\x0ces the\\nprobability of drawing each class. Then, once we have a class, we have a distribution for the\\nobserved data point coming from that class:\\np(xjz=Ck;w)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 121}),\n",
              " Document(page_content='?The distribution given by p(xjz=Ck;w) is known as the class-conditional distribution .\\nThis distribution depends on the type of data we are observing, and is parameterized by an\\narbitrary parameter wwhose form depends on what is chosen as the class-conditional distribution.\\nFor the case of snout lengths, and many other examples, this conditional distribution is often\\nmodeled using a Gaussian distribution, in which case our model is known as a Gaussian Mixture\\nModel . We will discuss Gaussian Mixture Models in more detail later in the chapter.\\nIf we can e\\x0bectively model the distribution of our observed data points and the latent variables\\nresponsible for producing the data, we will be able to ask interesting questions of our model. For', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 121}),\n",
              " Document(page_content=\"example, upon observing a new data point x0we will be able to produce a probability that it came\\nfrom a speci\\x0cc class z0=Ckusing Bayes' rule and our model parameters:\\np(z0=Ckjx0) =p(x0jz0=Ck;w)p(z0=Ck;\\x12)P\\nk0p(x0jz0=Ck0;w)p(z0=Ck0;\\x12)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 121}),\n",
              " Document(page_content='114 CHAPTER 9. MIXTURE MODELS\\nFurthermore, after modeling the generative process, we will be able to generate new data points by\\nsampling from our categorical class distribution, and then from the class-conditional distribution\\nfor that category:\\nz\\x18Cat(\\x12)\\nx\\x18p(xjz=Ck;w)\\nFinally, it will also be possible for us to get a sense of the cardinality of z(meaning the number of\\nclasses our data falls into), even if that was not something we were aware of a priori.\\nML Framework Cube: Mixture Models\\nWhile the classes of data zin a mixture model will typically be discrete, the observed data xcan\\nbe either discrete or continuous. Notice also that this is an unsupervised technique: while we have\\na data set Xof observations, our goal is not to make predictions. Rather, we are trying to model', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 122}),\n",
              " Document(page_content='the generative process of this data by accounting for the latent variables that generated the data\\npoints. Finally, this is a probabilistic model both for the latent variables and for our observed data.\\nDomain Training Probabilistic\\nContinuous/Discrete Unsupervised Yes\\n9.2 Applications\\nSince much of the data we observe in our world has some sort of unobserved category associated\\nwith it, there are a wide variety of applications for mixture models. Here are just a few:\\n1. Handwriting image recognition. The categories are given by the characters (letters, numbers,\\netc.) and the class-conditional is a distribution over what each of those characters might look\\nlike.\\n2. Noise classi\\x0ccation. The categories are given by the source of a noise (e.g. we could have', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 122}),\n",
              " Document(page_content=\"di\\x0berent animal noises), and the class-conditional is a distribution over what the sound waves\\nfor each animal noise look like.\\n3. Vehicle prices. The categories are given by the brand of vehicle (we could alternatively\\ncategorize by size, safety, year, etc.), and the class-conditional is a distribution over the price\\nof each brand.\\n9.3 Fitting a Model\\nWe've de\\x0cned the general form of a mixture model: we have a distribution p(z;\\x12) over our classes\\nand a distribution p(xjz=Ck;w) as our class-conditional distribution. A natural approach would\\nbe to compute the maximum likelihood values for our parameters \\x12andw. Let's consider how me\\nmight go about this for a mixture model.\\n9.3.1 Maximum Likelihood for Mixture Models\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 122}),\n",
              " Document(page_content=\"Our goal is to maximize the likelihood of our observed data. Because we don't actually observe the\\nlatent variables znwhich determine the class of each observed data point xn, we can simply sum\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 122}),\n",
              " Document(page_content=\"9.4. EXPECTATION-MAXIMIZATION (EM) 115\\nover the possible classes for each of our Ndata points as follows:\\np(X;\\x12;w) =NY\\nn=1KX\\nk=1p(xn;zn;k;\\x12;w)\\nTaking the logarithm to get our log-likelihood as usual:\\nlogp(X;\\x12;w) =NX\\nn=1log\\x14KX\\nk=1p(xn;zn;k;\\x12;w)\\x15\\n(9.1)\\nIt may not be immediately obvious, but under this setup, the maximum likelihood calculation for\\nour parameters \\x12;wis now intractable. The summation over the Kclasses of our latent variable zn,\\nwhich is required because we don't actually observe those classes, is inside of the logarithm, which\\nprevents us from arriving at a closed form solution (it may be helpful to try to solve this yourself,\\nyou'll realize that consolidating a summation inside of a logarithm is not possible). The rest of this\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 123}),\n",
              " Document(page_content=\"chapter will deal with how we can optimize our mixture model in the face of this challenge.\\n9.3.2 Complete-Data Log Likelihood\\nWe have a problem with computing the MLE for our model parameters. If we only knew which\\nclasses our data points came from, we would be able to calculate log p(x;z) with relative ease\\nbecause we would no longer require a summation inside the logarithm:\\nlogp(X;Z) =NX\\nn=1logp(xn;zn;\\x12;w) (9.2)\\n=NX\\nn=1log[p(xnjzn=Ck;w)p(zn=Ck;\\x12)] (9.3)\\n=NX\\nn=1logp(xnjzn=Ck;w) + logp(zn=Ck;\\x12) (9.4)\\n(9.5)\\nNotice that because we've now observed zn, we don't have to marginalize over its possible values.\\nThis motivates an interesting approach that takes advantage of our ability to work with p(x;z) if\\nwe only knew z.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 123}),\n",
              " Document(page_content=\"The expression p( x,z) is known as the complete-data because it assumes that we have both our\\nobservation xand the classs zthatxcame from. Our ability to e\\x0eciently calculate the complete-\\ndata log likelihood log p(x;z) is the crucial piece of the algorithm we will present to optimize our\\nmixture model parameters. This algorithm is known as Expectation-Maximization , orEM for\\nshort.\\n9.4 Expectation-Maximization (EM)\\nThe motivation for the EM algorithm, as presented in the previous section, is that we do not have\\na closed form optimization for our mixture model parameters due to the summation inside of the\\nlogarithm. This summation was required because we didn't observe a crucial piece of data, the\\nclassz, and therefore we had to sum over its values.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 123}),\n",
              " Document(page_content='116 CHAPTER 9. MIXTURE MODELS\\nEM uses an iterative approach to optimize our model parameters. It proposes a value for zusing\\nan expectation calculation, and then based on that proposed value, it maximizes our complete-data\\nlog likelihood with respect to the model parameters \\x12andwvia a standard MLE procedure.\\nNotice that EM is composed of two distinct steps: taking an expectation over our latent class\\nvariables and performing a maximization over our model parameters. These two steps (expectation\\nand maximization) obviously give the algorithm its name, but more generally, this type of approach\\nis also referred to as coordinate ascent . The idea behind coordinate ascent is that we can replace\\na hard problem (maximizing the log likelihood for our mixture model directly) with two easier', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 124}),\n",
              " Document(page_content=\"problems (taking an expectation over our latent variables and maximizing our model parameters\\nbased on the complete-data, which relies on the current setting of our latent variables). We alternate\\nbetween the two easier problems, executing each of them until we reach a point of convergence or\\ndecide that we've done enough.\\nWe'll walk through the details of each of these two steps and then tie them together with the\\ncomplete algorithm.\\n?K-Means, an algorithm we discussed in the context of clustering, is also a form of coordinate ascent. K-Means is\\na maximization-maximization algorithm because we iteratively maximize our assignments (by assigning each data\\npoint to just a single cluster) and then update our cluster centers to maximize their likelihood with respect to the\\nnew assignments.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 124}),\n",
              " Document(page_content=\"9.4.1 Expectation Step\\nThe purpose of the expectation step (sometimes just referred to as the `E-step') in the EM algorithm\\nis to set the most likely values for our latent variables zn. In an ideal world, we would know what\\nthese classes are, and if we did, we could simply optimize our complete-data log likelihood directly\\nas we've seen above. However, since we don't get to observe these values, one way we can get\\naround this is just to compute the expectation of the latent variables. Let's consider what this\\nlooks like with a concrete example.\\nLet's say our data points xncan come from one of three classes. Then, we can represent the\\nlatent variable znassociated with each data point using a one-hot encoded vector. For example, if\\nzncame from class C1, we would denote this:\\nzn=2\\n41\\n0\\n03\\n5\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 124}),\n",
              " Document(page_content=\"As we've already explained, we don't know the true value of this latent variable. Instead, we will\\ncompute its conditional expectation based on the current setting of our model parameters and our\\nobserved data xn. We denote the expectation of our latent variables as qn, and we calculate them\\nas follows:\\nqn=E[znjxn] =2\\n4p(zn=C1jxn;\\x12;w)\\np(zn=C2jxn;\\x12;w)\\np(zn=C3jxn;\\x12;w)3\\n5\\n/2\\n4p(xnjzn=C1;w)p(zn=C1;\\x12)\\np(xnjzn=C2;w)p(zn=C2;\\x12)\\np(xnjzn=C3;w)p(zn=C3;\\x12)3\\n5\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 124}),\n",
              " Document(page_content=\"9.4. EXPECTATION-MAXIMIZATION (EM) 117\\nNotice that we can switch from proportionality in our qnvalues to actually probabilities by simply\\ntaking a softmax over the unnormalized values. Then, our qnvalues will look something like the\\nfollowing, where a larger number indicates a stronger belief that the data point xncame from that\\nclass:\\nqn=2\\n40:8\\n0:1\\n0:13\\n5\\nThere are two important things to note about the expectation step. First, the model parameters \\x12\\nandware held \\x0cxed. We're computing the expectation of our latent variables based on the current\\nsetting of those model parameters. Those parameters are randomly initialized if this is our \\x0crst\\ntime running the expectation step.\\nSecond, notice that we have a value of qnfor every data point xnin our data set. As a result,\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 125}),\n",
              " Document(page_content=\"qnare sometimes called local parameters, since there is one assigned to each data point. This is\\nin contrast to our model parameters \\x12andw, which are considered global parameters. The size of\\nthe global model parameters doesn't \\ructuate based on the size of our data set.\\nAfter performing the E-step, we now have an expectation for our latent variables, given by qn.\\nIn the maximization step, which we describe next, we use these qnvalues to optimize our model\\nparameters.\\n9.4.2 Maximization Step\\nAfter the expectation step, we have a qn2RKassociated with each data point xn, which de-\\nscribes our belief that the data point came from each class Ck. Now that we have these expected\\n`class assignments', it's possible for us to maximize the data likelihood with respect to our model\\nparameters\\x12andw.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 125}),\n",
              " Document(page_content=\"Recall that optimizing our parameters using the complete-data log likelihood is tractable be-\\ncause we avoid summing over the classes inside of the logarithm. Although we do not have the\\nactual complete-data (we don't know the true znvalues), we have an estimation of the complete-\\ndata through our qnvalues! We use these values of qnto make the optimization of our model\\nparameters tractable.\\nNotice that our qnvalues are `soft' assignments - meaning that unlike the znvalues, which are\\none-hot encodings of assignments to a class, the qnvalues have a probability that a data point xn\\ncame from each class. Fortunately, this does not a\\x0bect our maximization, which starts with out\\ncomplete-data log likelihood:\\nlogp(X;Z) =NX\\nn=1logp(xnjzn=Ck;w) + logp(zn=Ck;\\x12)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 125}),\n",
              " Document(page_content='Applying the expectation with respect to znjxn, which will require the qncomputed in the expec-', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 125}),\n",
              " Document(page_content='118 CHAPTER 9. MIXTURE MODELS\\ntation step:\\nEznjxn[logp(X;Z)] = E znjxn\\x14NX\\nn=1logp(xnjzn=Ck;w) + logp(zn=Ck;\\x12)\\x15\\n(9.6)\\n=NX\\nn=1Eznjxn\\x14\\nlogp(xnjzn=Ck;w) + logp(zn=Ck;\\x12)\\x15\\n(9.7)\\n=NX\\nn=1KX\\nk=1p(zn=Ckjxn)\\x00\\nlogp(xnjzn=Ck;w) + logp(zn=Ck;\\x12)\\x01\\n(9.8)\\n=NX\\nn=1KX\\nk=1qn;k\\x00\\nlogp(xnjzn=Ck;w) + logp(zn=Ck;\\x12)\\x01\\n(9.9)\\n(9.10)\\nNotice the crucial di\\x0berence between this summation and that of Equation 9.1: the summation\\nover the classes is now outside of the logarithm! Recall that using the log-likelihood directly was\\nintractable precisely because the summation over the classes was inside of the logarithm. This\\nmaximization became possible by taking the expectation over our latent variables (using the values\\nwe computed in the E-step), which moved the summation over the classes outside of the logarithm.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 126}),\n",
              " Document(page_content='We can now complete the M-step by maximizing the tractable Equation 9.6 with respect to\\nour model parameters \\x12andw. We simply take the derivative with respect to the parameter of\\ninterest, set to 0, solve, and update the parameter with the result.\\n9.4.3 Full EM Algorithm\\nNow that we have a grasp on the purpose of the EM algorithm, as well as an understanding of\\nthe expectation and maximization steps individually, we are ready to put everything together to\\ndescribe the entire EM algorithm.\\n1. Begin by initializing our model parameters wand\\x12, which we can do at random. Since\\nthe EM algorithm is performed over a number of iterative steps, we will denote these initial\\nparameter values w(0)and\\x12(0). We will increment those values as the algorithm proceeds.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 126}),\n",
              " Document(page_content='2. E-step: compute the values of qnbased on the current setting of our model parameters.\\nqn=E[znjxn] =2\\n64p(zn=C1jxn;\\x12(i);w(i))\\n...\\np(zn=CKjxn;\\x12(i);w(i))3\\n75/2\\n64p(xnjzn=C1;w(i))p(zn=C1;\\x12(i))\\n...\\np(xnjzn=CK;w(i))p(zn=CK;\\x12(i))3\\n75\\n3. M-step: compute the values of wand\\x12that maximize our expected complete-data log like-\\nlihood for the current setting of the values of qn.\\nw(i+1);\\x12(i+1)= arg max\\nw;\\x12Eqn[logp(X;Z;w;\\x12)]\\n4. Return to step 2, repeating this cycle until our likelihood converges. Note that the likelihood\\nis guaranteed to increase at each step using this procedure.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 126}),\n",
              " Document(page_content=\"9.4. EXPECTATION-MAXIMIZATION (EM) 119\\n9.4.4 Connection to K-Means Clustering\\nAt this point, it's worth considering the similarity between the EM algorithm and another coordi-\\nnate ascent algorithm that we considered in the context of clustering: K-Means.\\nRecall that K-Means proceeds according to a similar iterative algorithm: we \\x0crst make hard\\nassignments of data points to existing cluster centers, and then we update the cluster centers based\\non the most recent data point assignments.\\nIn fact, the main di\\x0berences between K-Means clustering and the EM algorithm are that:\\n1. In the EM setting, we make soft cluster assignments through our qnvalues, rather than\\nde\\x0cnitively assigning each data point to only one cluster.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 127}),\n",
              " Document(page_content='2. The EM algorithm is able to take advantage of arbitrary probability distributions to cap-\\nture the behavior of the observed data, whereas K-Means clustering relies only on distance\\nmeasurements to make assignments and update cluster centers.\\nIn summary, K-Means is simply a restricted form of the EM algorithm.\\n9.4.5 Dice Example: Mixture of Multinomials\\nConsider the following example scenario: we have two biased dice (with 6 faces) and one biased\\ncoin (with 2 sides). Data is generated as follows: \\x0crst, the biased coin is \\ripped. If it lands heads,\\nDice 1 is rolled. If it lands tails, Dice 2 is rolled. We record the result of the dice roll, but that is\\nour only observation. For example, our observations may look like:\\n1;5;3;4;2;2;3;1;6', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 127}),\n",
              " Document(page_content=\"We're going to try to infer the parameters of each of the dice based on these observation.\\nLet's consider how this scenario \\x0cts into our idea of a mixture model. First, the latent variable\\nznhas a natural interpretation as being which dice was rolled for the nthobserved data point xn.\\nWe can represent znusing a one-hot vector, so that if the nthdata point came from Dice 1, we'd\\ndenote that:\\nzn=\\x141\\n0\\x15\\nUnsurprisingly, we denote the probability vector associated with the biased coin as \\x122R2, with\\n\\x121being the probability of the biased coin landing heads and \\x122being the probability of the biased\\ncoin landing tails. Furthermore, we need parameters to describe the behavior of our biased dice.\\nWe can use\\x191;\\x1922R6, where each 6-dimensional parameter vector describes the probability that\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 127}),\n",
              " Document(page_content='each dice lands on that face. Notice that we now have our model parameters w=f\\x12;\\x191;\\x192g. Now\\nthat we have our model parameters and an understanding of how this problem \\x0cts into the mixture\\nmodel paradigm, we can optimize our model parameters using the EM algorithm. We start by\\ninitializing our parameters w(0). Next, we need to compute our qnvalues (the expectation step).', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 127}),\n",
              " Document(page_content='120 CHAPTER 9. MIXTURE MODELS\\nRecall that the formula for this is given by:\\nqn=\\x14p(zn=C1jxn;\\x12(i);w(i))\\np(zn=C2jxn;\\x12(i);w(i))\\x15\\n(9.11)\\n/\\x14p(xnjzn=C1;w(i))p(zn=C1;\\x12(i))\\np(xnjzn=C2;w(i))p(zn=C2;\\x12(i))\\x15\\n(9.12)\\n/\\x14(\\x1911)xn;1(\\x1912)xn;2(\\x1913)xn;3(\\x1914)xn;4(\\x1915)xn;5(\\x1916)xn;6\\x121\\n(\\x1921)xn;1(\\x1922)xn;2(\\x1923)xn;3(\\x1924)xn;4(\\x1925)xn;5(\\x1926)xn;6\\x122\\x15\\n(9.13)\\n(9.14)\\nwherexn;1;:::;xn;6denotes what was rolled for the data point xn. After computing the values of\\nqn, we are ready to perform the maximization step for our model parameters. Recall that we are\\nmaximizing the expected complete-data log likelihood, which takes the form:\\nEqn[logp(X;Z)] =Eqn\\x14NX\\nn=1logp(zn) + logp(xnjzn)\\x15\\n(9.15)\\n=NX\\nn=1Eqn\\x14\\nlogp(zn) + logp(xnjzn)\\x15\\n(9.16)\\n=NX\\nn=12X\\nk=1qn;k\\x12\\nlog\\x12k+6X\\nj=1xn;jlog\\x19k;j\\x13\\n(9.17)\\n(9.18)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 128}),\n",
              " Document(page_content=\"Note that to maximize the expected complete-data log likelihood, it's necessary to introduce La-\\ngrange multipliers to enforce the constraintsP\\nk\\x12k= 1 andP\\nj\\x19k;j= 1. After doing this, we\\nrecover the following update equations for our model parameters:\\n\\x12(i)\\nk PN\\nn=1qn;k\\nN\\n\\x19(i)\\nk PN\\nn=1qn;kxnPN\\nn=1P6\\nj=1qn;kxn;j\\nWe now have everything we need to perform EM for this setup. After initializing our parameters\\nw(0), we perform the E-step by evaluating 9.11. After calculating our values of qnin the E-step, we\\nupdate our parameters w=f\\x12;\\x191;\\x192gin the M-step by maximizing 9.15 with respect to \\x12;\\x191;\\x192.\\nWe perform these two steps iteratively, until convergence of our parameters.\\n9.5 Gaussian Mixture Models (GMM)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 128}),\n",
              " Document(page_content='Our previous example was a simple but somewhat restricted application of the EM algorithm to\\nsolving a latent variable problem. We now turn to a more practical example, used widely in di\\x0berent\\ncontexts, called a Gaussian Mixture Model (GMM). As you might expect, a GMM consists of a\\ncombination of multiple Gaussian distributions. Among other things, it is useful for modeling\\nscenarios where the observed data is continuous.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 128}),\n",
              " Document(page_content=\"9.5. GAUSSIAN MIXTURE MODELS (GMM) 121\\nLet's go over a more rigorous formulation of the GMM setup. First, we have observed continous\\ndataxn2Rmand latent variables znwhich indicate which Gaussian `cluster' our observed data\\npoint was drawn from. In other words:\\np(xnjzn=Ck) =N(xn;\\x16k;\\x06k)\\nwhere\\x16k;\\x06kare the mean and covariance parameters respectively for the kthcluster center.\\nThe data generation process works as follows: we \\x0crst sample a cluster center from a Categorical\\ndistribution parameterized by \\x122RK. Then, based on the sampled cluster center, we sample a\\ndata point xn2Rm, which is the only piece of data that we actually observe. As usual for a mixture\\nmodel, it is our goal to use the observed data to determine the cluster means and covariances, as\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 129}),\n",
              " Document(page_content=\"well as the parameters of the Categorical distribution that selects the cluster centers.\\nFortunately, this problem setup is perfectly suited for EM. We can apply the same machinery\\nwe've discussed throughout the chapter and used in the previous example.\\n1. First, we randomly initialize our parameters \\x12;f\\x16k;\\x06kgK\\nk=1.\\n2. [E-Step] Calculate the posterior distribution over zngiven by qn:\\nqn= E[znjxn] =2\\n64p(zn=C1jxn;\\x121;\\x161;\\x061)\\n...\\np(zn=CKjxn;\\x12K;\\x16K;\\x06K)3\\n75\\n/2\\n64\\x121N(xn;\\x161;\\x061)\\n...\\n\\x12KN(xn;\\x16K;\\x06K)3\\n75\\nThis is the current expectation for our latent variables zngiven our data xnand the current\\nsetting of our model parameters \\x12;f\\x16k;\\x06kgK\\nk=1.\\n3. [M-Step] Using our values of qn, calculate the expected complete-data log likelihood, and\\nthen use that term to optimize our model parameters:\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 129}),\n",
              " Document(page_content='Eqn[logp(X;Z)] =Eqn\\x14NX\\nn=1ln(p(xn;zn;\\x12;f\\x16k;\\x06kgK\\nk=1))\\x15\\n=NX\\nn=1KX\\nk=1qn;kln\\x12k+qn;klnN(xn;\\x16k;\\x06k)\\nWe can then use this expected complete-data log likelihood to optimize our model parameters\\n\\x12;f\\x16k;\\x06kgK\\nk=1by computing the MLE as usual. Using a Lagrange multiplier to enforce', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 129}),\n",
              " Document(page_content=\"122 CHAPTER 9. MIXTURE MODELS\\nPK\\nk=1\\x12k= 1, we recover the update equations:\\n\\x12(i+1)\\nk PN\\nn=1qn;k\\nN\\n\\x16(i+1)\\nk PN\\nn=1qn;kxnPN\\nn=1qn;k\\n\\x06(i+1)\\nk PN\\nn=1qn;k(xn\\x00\\x16(i+1)\\nk)(xn\\x00\\x16(i+1)\\nk)T\\nPN\\nn=1qn;k\\n4. Return to step 2. Repeat until convergence.\\nFinally, it's worth comparing EM and K-Means clustering as applied to GMMs. First, as dis-\\ncussed previously, EM uses soft assignments of data points to clusters rather than hard assignments.\\nSecond, the standard K-Means algorithm does not estimate the covariance of each cluster. How-\\never, if we enforce as a part of our GMM setup that the covariance matrices of all the clusters are\\ngiven by\\x0fI, then as\\x0f!0, EM and K-Means will in fact produce the same results.\\n9.6 Admixture Models: Latent Dirichlet Allocation (LDA)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 130}),\n",
              " Document(page_content=\"With a grasp on mixture models, it is not too di\\x0ecult to understand admixture models. In a\\nsentence: an admixture model is a mixture of mixture models. Latent Dirichlet Allocation (LDA)\\nis a common form of admixture models, and it is sometimes also referred to as topic modeling , for\\nreasons that will become apparent shortly. Describing LDA using an example will hopefully make\\nthe idea of an admixture model more concrete.\\n9.6.1 LDA for Topic Modeling\\nConsider the following data generating process for a set of text documents. We have a Dirichlet\\ndistribution\\x12\\x18Dir(\\x0b) over the possible topics a document can take on.\\n?If you haven't seen the Dirichlet before, it is a distribution over an n-dimensional vector whose components sum to\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 130}),\n",
              " Document(page_content='1. For example, a sample from a dirichlet distribution in 3-dimensions could produce a sample that is the vector\\n2\\n40:2\\n0:5\\n0:33\\n5\\n.\\nWe sample from that Dirichlet distribution to determine the mixture of topics \\x12nin our docu-\\nmentDn:\\n\\x12n\\x18Dir(\\x0b)\\nThen, for each possible topic, we sample from a Dirichlet distribution to determine the mixture of\\nwords\\x1ekin that topic:\\n\\x1ek\\x18Dir(\\x0c)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 130}),\n",
              " Document(page_content=\"9.6. ADMIXTURE MODELS: LATENT DIRICHLET ALLOCATION (LDA) 123\\nThen, for each word wn;jin the document Dn, we \\x0crst sample from a Categorical parameterized\\nby the topic mixture \\x12nto determine which topic that word will come from:\\nzn;j\\x18Cat(\\x12n)\\nThen, now that we have a topic given by zn;jfor this word wn;j, we sample from a Categorical\\nparameterized by that topic's mixture over words given by \\x1ezn;j:\\nwn;j\\x18Cat(\\x1ezn;j)\\nNotice the mixture of mixtures at play here: we have a mixture model over the topics to produce\\neach document in our corpus, and then for every word in a given document, we have a mixture\\nover the topics to generate each individual word.\\nThe indexing is particularly confusing because there are several layers of mixtures here, but to\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 131}),\n",
              " Document(page_content=\"clarify:n21::Nindexes each document Dnin our corpus, k21::Kindexes each possible topic,\\nandj21::Jindexes each word wn;jin document Dn, ande21::Eindexes each word in our\\ndictionary (note that wn;j2RE).\\n\\x12nspeci\\x0ces the distribution over topics in document Dn, and\\x0bis the hyperparameter for the\\ndistribution that produces \\x12n. Similarly,\\x1ekspeci\\x0ces the distribution over words for the kthtopic,\\nand\\x0cis the hyperparameter for the distribution that produces \\x1ek.\\n9.6.2 Applying EM to LDA\\nNow that the problem setup and notation are taken care of, let's consider how we can apply EM\\nto optimize the parameters \\x12n(the mixture over topics in a document) and \\x1ek(the mixture over\\nwords for a topic). Note that we can simplify the problem slightly by considering \\x12nand\\x1ekto be\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 131}),\n",
              " Document(page_content='deterministic parameters for optimization (rather than random variables parameterized by \\x0band\\n\\x0c). Then, EM proceeds as follows:\\n1. First, we randomly initialize our parameters f\\x12ngN\\nn=1;f\\x1ekgK\\nk=1.\\n2. [E-Step] Fix the topic distribution of the document given by \\x12nand the word distribution\\nunder a topic given by \\x1ek. Calculate the posterior distribution qn;j=p(zn;jjwn;j), and note\\nthat this is the distribution over the possible topics of a word:\\nqn;j= E[zn;jjwn;j] =2\\n64p(zn;j=C1jwn;j;\\x12n;\\x1e1)\\n...\\np(zn;j=CKjwn;j;\\x12n;\\x1eK)3\\n75\\n/2\\n64p(wn;jjzn;j=C1;\\x1e1)p(zn;j=C1;\\x12n)\\n...\\np(wn;jjzn;j=CK;\\x1eK)p(zn;j=CK;\\x12n)3\\n75\\n=2\\n64\\x1e1;wn;j\\x01\\x12n;1\\n...\\n\\x1eK;wn;j\\x01\\x12n;K3\\n75', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 131}),\n",
              " Document(page_content='124 CHAPTER 9. MIXTURE MODELS\\n3. [M-Step] Using our values of qn, calculate the expected complete-data log likelihood (which\\nmarginalizes over the unknown hidden variables zn;j), and then use that expression to optimize\\nour model parameters \\x12nand\\x1ek:\\nEqn[logp(W;Z)] =Eqn\\x14NX\\nn=1JX\\nj=1ln(p(wn;j;zn;j;f\\x12ngN\\nn=1;f\\x1ekgK\\nk=1\\x15\\n=NX\\nn=1JX\\nj=1KX\\nk=1qn;j;kln\\x12n;k+qn;j;kln\\x1ek;wn;j\\nWe can then use this expected complete-data log likelihood to optimize our model parameters\\nf\\x12ngN\\nn=1;f\\x1ekgK\\nk=1by computing the MLE as usual. Using Lagrange multipliers to enforce\\n8nPK\\nk=1\\x12n;k= 1 and8kPE\\ne=1\\x1ek;e= 1 (where eindexes each word in our dictionary), we\\nrecover the update equations:\\n\\x12(i+1)\\nn;k PJ\\nj=1qn;j;k\\nJ\\n\\x1e(i+1)\\nk;d PN\\nn=1PJ\\nj=1qn;j;kwn;j;dPN\\nn=1PJ\\nj=1qn;j;k\\n4. Return to step 2. Repeat until convergence.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 132}),\n",
              " Document(page_content=\"The largest headache for applying the EM algorithm to LDA is keeping all of the indices in\\norder, and this is the result of working with a mixture of mixtures. Once the bookkeeping is sorted\\nout, the actual updates are straightforward.\\n9.7 Conclusion\\nMixture models are one common way of handling data that we believe is generated through a\\ncombination of unobserved, latent variables. We've seen that training these models directly is\\nintractable (due to the marginalization over the latent variables), and so we turned to a coordinate\\nascent based algorithm known as Expectation-Maximization to get around this di\\x0eculty. We then\\nexplored a couple of common mixture models, including a multinomial mixture, Gaussian Mixture\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 132}),\n",
              " Document(page_content='Model, and an admixture model known as Latent Dirichlet Allocation. Mixture models are a subset\\nof a broader range of models known as latent variable models, and the examples seen in this chapter\\nare just a taste of the many di\\x0berent mixture models available to us. Furthermore, EM is just a\\nsingle algorithm for optimizing these models. A good grasp on the fundamentals of mixture models\\nand the EM algorithm will be useful background for expanding to more complicated, expressive\\nlatent variable models.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 132}),\n",
              " Document(page_content=\"Chapter 10\\nHidden Markov Models\\nMany of the techniques we've considered so far in this book have been motivated by the types of data\\nwe could expect to work with. For example, the supervised learning techniques (forms of regression,\\nneural networks, support vector machines, etc.) were motivated by the fact that we had labelled\\ntraining data. We ventured into clustering to group unlabelled data and discussed dimensionality\\nreduction to handle overly high-dimensional data. In the previous chapter, we examined techniques\\nfor managing incomplete data with latent variable models. In this chapter we turn to a technique\\nfor handling data indexed by time.\\n10.1 Motivation\\nOne major type of data we have not yet paid explicit attention to is time series data. Most of the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 133}),\n",
              " Document(page_content=\"information we record comes with some sort of a timestamp. For example, any time we take an\\naction online, there is a high probability that the database storing that data also tracks it with a\\ntimestamp. Physical sensors in the real world always record timestamps because it would be very\\ndi\\x0ecult to make sense of their information if it is not indexed by time. When we undergo medical\\nexams, the results are recorded along with a timestamp. It's almost inconceivable at this point\\nthat we would record information without also keeping track of when that data was generated, or\\nat the very least when we saved that data.\\nThere are a variety of reasons to treat time as a special type of data. As we've already discussed,\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 133}),\n",
              " Document(page_content=\"it's a near-universal feature because we so frequently record timestamp information. It's di\\x0ecult\\nto imagine a data set that couldn't come with timestamps attached to the individual data points.\\nTime also encodes a lot of information that we take for granted about the physical and digital\\nworlds. For example, if the sensors on a plane record the position of the plane at a speci\\x0cc point\\nin time, we would expect the surrounding data points to be relatively similar, or at least move in a\\nconsistent direction. In a more general sense, we expect that time constrains other aspects of the\\ndata it is attached to in speci\\x0cc ways.\\nBecause we know time posseses these unique properties, it follows that we should exploit them\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 133}),\n",
              " Document(page_content=\"to create more expressive models. In this chapter, we will focus on one such model known as a\\nHidden Markov Model orHMM . At a high level, the goal of an HMM is to model the state\\nof an entity over time, with the caveat that we never actually observe the state itself. Instead,\\nwe observe a data point xtat each time step (often called an `emission') that is some function of\\nthe true state st. For example, we could model the position of a robot over time given a noisy\\nestimation of the robot's current position at each time step. Furthermore, we have some belief\\nabout how one state sttransitions to the next state st+1. Graphically, an HMM looks like Figure\\n125\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 133}),\n",
              " Document(page_content=\"126 CHAPTER 10. HIDDEN MARKOV MODELS\\nFigure 10.1: The directed graphical model for an HMM.\\n10.1, which encodes the relationships between emissions and hidden states.\\nWe will probe HMMs in more detail over the course of the chapter, but for now let's consider\\ntheir high-level properties.\\nML Framework Cube: Hidden Markov Models\\nFirst, HMMs handle discrete states, and for the purpose of this text, we will only consider discrete-\\nvalued emissions as well. Second, since an HMM does not have access to the true states even\\nat training time, it works on an unsupervised basis to approximate the hidden states. Finally,\\nit's most common to probabilistically describe both the relationship between hidden states and\\nobserved emissions as well as the transitions between hidden states.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 134}),\n",
              " Document(page_content='Domain Training Probabilistic\\nDiscrete Unsupervised Yes\\n?Models that treat continuous state variables are commonly referred to as dynamical systems.\\n10.2 Applications\\nUnsurprisingly, there are many applications for models like HMMs that explicitly account for time\\nand unobserved states, especially those that relate to the physical world.\\n1. Robot position when movements are non-deterministic and sensor readings are noisy.\\n2. Speech recognition.\\n3. Analyzing sequences that occur in the natural world, such as DNA.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 134}),\n",
              " Document(page_content=\"10.3. HMM DATA, MODEL, AND PARAMETERIZATION 127\\n10.3 HMM Data, Model, and Parameterization\\nAs explained above, HMMs model the state of an entity over time given some noisy observations,\\nas shown in Figure 10.1.\\n10.3.1 HMM Data\\nA complete data point for an HMM consists of the sequence of one-hot encoded states s1;:::;sn\\nas well as the corresponding sequence of observed emissions x1;:::;xn. Each state corresponds to\\none ofKpossible options, meaning st2RK, and each emission corresponds to one of Mpossible\\noptions meaning xt2RM. Note that we don't have access to the complete data points, but only\\nthe observed emissions. It's our goal to infer the hidden states.\\n?In general the observed emissions don't have to be discrete, but for the sake of being explicit, we present the discrete\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 135}),\n",
              " Document(page_content=\"interpretation here.\\nNote that a single data point consists of a sequence of nemissions x1;:::;xn. A data set is said\\nto haveNdata points, meaning Nsequences where each sequence is composed of nemissions. To\\nsummarize:\\n\\x0fA data set consists of Nsequences.\\n\\x0fEach sequence is composed of nobserved emissions x1;:::;xn.\\n\\x0fIt's our goal to infer the hidden states s1;:::;snfor each sequence.\\n\\x0fEach emission xttakes on one of Mpossible options.\\n\\x0fEach hidden state sttake on one of Kpossible options.\\n10.3.2 HMM Model Assumptions\\nOne goal of an HMM is to optimize the joint distribution over hidden states and observed emissions\\ngiven by:\\np(s1;:::;sn;x1;:::;xn) =p(s1;:::;sn)p(x1;:::;xnjs1;:::;sn) (10.1)\\nIt's not immediately obvious how we should go about optimizing the model for this complex joint\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 135}),\n",
              " Document(page_content=\"distribution. Fortunately, HMMs make this problem easier via the following assumptions:\\n1. State st+1depends only on the previous state st:\\np(st+1js1;:::;st;x1;:::;xt) =p(st+1jst)\\nThis is the Markov Property , and it means that given information at the previous time step,\\nwe can ignore all earlier time steps.\\n2. At each time step t, the observed emission xtdepends only on the current state st.\\np(xtjs1;:::;st;x1;:::;xt\\x001) =p(xtjst)\\n?The Markovian assumption for transitions, as well as the fact that we don't observe the true states, gives rise to\\ntheHidden Markov Model name.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 135}),\n",
              " Document(page_content=\"128 CHAPTER 10. HIDDEN MARKOV MODELS\\nNotice that these two assumptions allow us to factorize the large joint distribution given by Equation\\n10.1 as follows:\\np(s1;:::;sn)p(x1;:::;xnjs1;:::;sn) =p(s1)n\\x001Y\\nt=1p(st+1jst)nY\\nt=1p(xtjst) (10.2)\\nThis factorization will prove important for making HMM training and inference tractable.\\n10.3.3 HMM Parameterization\\nNow that we understand the form of the data as well as the modeling assumptions made by\\nan HMM, we can specify the model parameterization explicitly. Referencing the factorized joint\\ndistribution from Equation 10.2, it's clear that we will need three distinct sets of parameters.\\n1. One set of parameters is for the prior over our initial hidden state p(s1). It will be denoted\\n\\x122RK, such that:\\np(s1=k) =\\x12k\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 136}),\n",
              " Document(page_content='2. Another set of parameters is for the transition probabilities between states p(st+1jst). It will\\nbe denoted T2RK\\x02K, such that:\\np(st+1=jjst=i) =Ti;j\\nwhereTi;jis the probability of transitioning from state ito statej.\\n3. Finally, we have a set of parameters for the conditional probability of the observed emission\\ngiven the hidden state, meaning p(xtjst). It will be denoted \\x192RK\\x02M, such that:\\np(xt=mjs=k) =\\x19k;m\\nA natural interpretation of the parameter matrix \\x19is that each possible state (of which there\\nareKoptions) has an M-dimensional vector describing the probability of an emission given\\nthat state.\\nIn sum, we have three sets of parameters \\x122RK,T2RK\\x02K, and\\x192RK\\x02Mthat we need to\\nlearn from our data set. Then, using this trained model, we will be able to perform several types', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 136}),\n",
              " Document(page_content=\"of inference over our hidden states, which are detailed down below.\\n10.4 EM for HMMs and the Forward-Backward Algorithm\\nRecall the motivation for the Expectation-Maximization algorithm from the previous chapter: we\\nhad parameters we wished to optimize, but the presence of unobserved variables made direct op-\\ntimization of those parameters intractable. We're faced with a similar problem in the context of\\nHMMs.\\nGiven a data set of observed emissions fxigN\\ni=1where each data point xirepresents the sequence\\n(xi\\n1;:::;xi\\nn), our goal is to estimate the parameters \\x12;T;\\x19described in the previous section. If we\\nknew the hidden states, it would be possible for us to write the joint probability p(si;xi) directly,\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 136}),\n",
              " Document(page_content='and maximizing our parameters would be no issue. However, the true states are latent variables, and', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 136}),\n",
              " Document(page_content='10.4. EM FOR HMMS AND THE FORWARD-BACKWARD ALGORITHM 129\\nthus we would need to sum over their possible values, which is what makes the direct maximization\\nof our parameters intractable.\\nInstead, we will use the Expectation-Maximization algorithm we developed in the previous\\nchapter. This amounts to computing the expectation over our hidden states in the E-step, and\\nthen based on those \\x0cxed expectations, we can update our parameters via a maximization of the\\nexpected complete-data in the M-step. As usual, we perform these operations iteratively until\\nconvergence.\\nSo far, there is no clear departure from the same exact EM algorithm we saw in the last chapter.\\nHowever, before we go about detailing the E and M steps, we need to consider something known\\nas the Forward-Backward Algorithm .', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 137}),\n",
              " Document(page_content=\"10.4.1 Forward-Backward Algorithm\\nLet's consider what would actually be required of us to perform the E-step for the hidden states of\\nan HMM. To compute the expected value of state stusing the full joint distribution given by:\\np(s1;:::;sn;x1;:::;xn) =p(s1)n\\x001Y\\nt=1p(st+1jst)nY\\nt=1p(xtjst)\\nwould require marginalizing over all the unobserved states other than stas follows:\\nE[stjs1;:::;st\\x001;st+1;:::;sn;x1;:::;xn] =p(stjs1;:::;st\\x001;st+1;:::;sn;x1;:::;xn) =\\nX\\nk(1)2K:::X\\nk(t\\x001)2KX\\nk(t+1)2K:::X\\nk(n)2Kp(stjs1=k(1);:::;st\\x001=k(t\\x001);st+1=k(t+1);:::;sn=k(n);x1;:::;xn)\\nIf we were to do this naively by marginalizing over all states at each time step, it would be\\na very expensive and wasteful computation. For example, computing the expected value of the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 137}),\n",
              " Document(page_content=\"state at time step 2 would require summing over all possible states for s1;s3;:::;sn. Then, to get\\nthe expected value of the state at time step 3, we would need to sum over all possible states for\\ns1;s2;s4;:::;sn. Notice that this approach duplicates a lot of work. Rather than performing these\\nsummations over and over again, we can instead memoize (or reuse) these summations using the\\nForward-Backward algorithm.\\nThe Forward-Backward algorithm is an example of a message-passing scheme, which means we\\ncompute information once and then pass it around our model in the form of compact, reusable\\nmessages. The goal is to avoid duplicating work, instead using the messages directly. If you've\\nencounted dynamic programming before, the Forward-Backward Algorithm is an example. Ulti-\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 137}),\n",
              " Document(page_content=\"mately, the purpose of the Foward-Backward algorithm is to make the expectation step over our\\nHMM more e\\x0ecient.\\nThis algorithm passes messages, unsurprisingly, forwards and backwards through `time', mean-\\ning up and down the chain shown in the graphical model representation given by Figure 10.1. The\\nforward messages are de\\x0cned at each state as \\x0bt(st), while the backward messages are de\\x0cned at\\neach state as \\x0ct(st). Let's de\\x0cne these \\x0band\\x0cvalues explicitly.\\nThe\\x0bt's represent the joint probability of all our observed emissions from time 1 ;:::;t as well\\nas the state exactly at time t:\\n\\x0bt(st) =p(x1;:::;xt;st) (10.3)\\nGraphically, this means that the \\x0bt's are capturing the portion of the DGM shown in Figure 10.2.\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 137}),\n",
              " Document(page_content='Note that Equation 10.3 is an unfactorized joint probability over observed emissions and a\\nhidden state. We can factorize this joint probability using what we know about the conditional', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 137}),\n",
              " Document(page_content=\"130 CHAPTER 10. HIDDEN MARKOV MODELS\\nFigure 10.2: \\x0bt's capture the joint probability for the boxed portion of this DGM.\\nindependence properties of HMMs as follows:\\n\\x0bt(st) =p(x1;:::;xt;st) (10.4)\\n=p(xtjst)X\\nst\\x001p(stjst\\x001)p(x1;:::;xt\\x001;st\\x001) (10.5)\\n=p(xtjst)X\\nst\\x001p(stjst\\x001)\\x0bt\\x001(st\\x001) (10.6)\\nPay careful attention to the last line of Equation 10.4. Notice that our expression for \\x0bt(st) actually\\nincludes the expression for \\x0bt\\x001(st\\x001), which is the \\x0bfrom the previous time step. This is signi\\x0ccant\\nbecause it means we can de\\x0cne our messages recursively . After we've computed the \\x0b's at one time\\nstep, instead of having to recompute those values to get the alphas at the next time step, we can\\nsimply pass them forwards along the chain. In other words, we compute the \\x0bat state s1, then\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 138}),\n",
              " Document(page_content=\"pass that message along to compute the \\x0bat state s2, on and on until we've reached the end of the\\nchain and have all the \\x0b's in hand.\\n?These\\x0bvalues will be useful when performing the expectation step during training, as well as for general inference\\nonce we've \\x0cnished training our HMM.\\nAt this point, we've now handled the forward messages, which send information from the be-\\nginning to the end of the chain. We also need to send information from the end of the chain back\\nto the beginning, which constitutes the backwards portion of the algorithm. This is where we will\\ncompute our \\x0cvalues.\\nThe\\x0ct's represent the joint probability over all the observed emissions from time t+ 1;:::;n\\nconditioned on the state at time t:\\n\\x0ct(st) =p(xt+1;:::;xnjst) (10.7)\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 138}),\n",
              " Document(page_content=\"Graphically, this means that the \\x0ct's are capturing the portion of the DGM shown in Figure 10.3.\\nWe can factorize Equation 10.7 in a similar way to how we factorized the distribution described\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 138}),\n",
              " Document(page_content=\"10.4. EM FOR HMMS AND THE FORWARD-BACKWARD ALGORITHM 131\\nFigure 10.3: \\x0ct's capture the joint probability for the boxed portion of this DGM.\\nby the\\x0b's:\\n\\x0ct(st) =p(xt+1;:::;xnjst) (10.8)\\n=X\\nst+1p(st+1jst)p(xt+1;:::;xnjst+1) (10.9)\\n=X\\nst+1p(st+1jst)p(xt+1jst+1)p(xt+2;:::;xnjst+1) (10.10)\\n=X\\nst+1p(st+1jst)p(xt+1jst+1)\\x0ct+1(st+1) (10.11)\\nAgain, as we saw with our calculation of the \\x0b's, we have our \\x0c's de\\x0cned recursively. Once again,\\nthis means that we can propagate messages e\\x0eciently. In this case, we start at the end of the chain,\\nand compute our \\x0c's for each state by passing messages back toward the front.\\nTo summarize, the Forward-Backward algorithm is an optimization that will boost e\\x0eciency\\nfor the EM algorithm as well as for inference over a trained HMM. We calculate the \\x0band\\x0cvalues\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 139}),\n",
              " Document(page_content=\"as follows:\\n\\x0bt(st) =(\\np(xtjst)P\\nst\\x001p(stjst\\x001)\\x0bt\\x001(st\\x001) 1<t\\x14n\\np(x1js1)p(s1) otherwise\\n\\x0ct(st) =(P\\nst+1p(st+1jst)p(xt+1jst+1)\\x0ct+1(st+1) 1\\x14t<n\\n1 otherwise\\n?Notice that the base case for the \\x0c's is 1. This is just a quirk of our indexing, and it ensures we have valid messages\\nwhen we pass messages back from the \\x0cnal state sn.\\n10.4.2 Using \\x0b's and \\x0c's for Training and Inference\\nNow that we know how to compute these \\x0band\\x0cvalues, we need to consider how we actually use\\nthem for training and inference within our HMM setup. Indeed, it's not immediately clear how the\\ndistributions de\\x0cned by the \\x0b's and\\x0c's are useful.\\nLet's begin by assuming we randomly initialized our model parameters \\x12;T;\\x19, and then used\\nthese to compute all the \\x0band\\x0cvalues by passing messages up and down the chain (using the\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 139}),\n",
              " Document(page_content='132 CHAPTER 10. HIDDEN MARKOV MODELS\\nrecurrences de\\x0cned at the end of the last section). We now have \\x0band\\x0cvalues de\\x0cned at every\\ntime step in our HMM. Consider the product of the \\x0band\\x0cvalue at a speci\\x0cc time t:\\n\\x0bt(st)\\x0ct(st) =p(x1;:::;xt;st)p(xt+1;:::;xnjst) =p(x1;:::;xn;st)\\nwhich is just the joint distribution over all our observed emissions and the state at time t. Using\\nthis as a building block, there are many distributions over the variables in our HMM that we can\\nevaluate. For example, we might like to evaluate the joint distribution over our observed emissions.\\nJoint Distribution Over Emissions\\np(x1;:::;xn) =X\\nst2K\\x0bt(st)\\x0ct(st) (10.12)\\nwhere we can sum over the possible state values at any time step 1 ;:::;n .', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 140}),\n",
              " Document(page_content='Another useful distribution is that of the state at time tgiven all the observed emissions.\\nThis has the name smoothing , which in some contexts means updating our beliefs given observed\\nevidence.\\nSmoothing\\np(stjx1;:::;xn)/p(x1;:::;xt;st) =\\x0bt(st)\\x0ct(st) (10.13)\\nNotice that the proportionality of the smoothing operation means we can normalize to recover\\nprobabilities by taking the softmax over the possible values for the state st.\\nAnother common task is predicting the value of the next emission given the previous emissions.\\nPrediction\\np(xn+1jx1;:::;xn) (10.14)\\nTo compute this we can sum over the \\x0cnal state snas well as the next state sn+1as follows:\\np(xn+1jx1;:::;xn)/X\\nsnX\\nsn+1p(x1;:::;xn;sn)p(sn+1jsn)p(xn+1jsn+1) (10.15)\\n/X\\nsnX\\nsn+1\\x0bn(sn)p(sn+1jsn)p(xn+1jsn+1) (10.16)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 140}),\n",
              " Document(page_content='Again, we recover a proportional result from this operation. We can use the softmax over the\\nemissions states to normalize.\\nFinally, we may wish to approximate the transition probabilities between states standst+1\\ngiven all the observed evidence.\\nTransition\\np(st;st+1jx1;:::;xn)/p(x1;:::;xt;st)p(st+1jst)p(xt+1jst+1)p(xt+2;:::;xnjst+1) (10.17)\\n/\\x0bt(st)p(st+1jst)p(xt+1jst+1)\\x0ct+1(st+1) (10.18)\\n(10.19)\\nwhere we again have proportionality results that can be normalized if necessary.\\nNow that we understand how exactly \\x0band\\x0cvalues can be used to evaluate di\\x0berent distribu-\\ntions of interest for an HMM, we can \\x0cnally turn to using EM to optimize the parameters of our\\nmodel.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 140}),\n",
              " Document(page_content='10.4. EM FOR HMMS AND THE FORWARD-BACKWARD ALGORITHM 133\\n10.4.3 E-Step\\nRecall that the goal of the expectation step is to compute the expected values of the hidden variables\\nin our model given a \\x0cxed set of parameters. Our parameters are \\x12;T;\\x19. Note that the \\x0band\\n\\x0cvalues described in the previous section are exact functions of these parameters, so at the start\\nof the E-step, we should compute them using the e\\x0ecient Forward-Backward algorithm. It will\\nbecome clear why we need the \\x0band\\x0cvalues as we explain the E-step.\\nUnder the HMM setup, our hidden variables are the states s1;:::;sn. Since we have Nemission\\nsequences xi= (xi\\n1;:::;xi\\nn)8i2Nin our data set, we will end up with Nexpected sequences\\nover our hidden states:\\nqi=E[(si\\n1;:::;si\\nn)j(xi\\n1;:::;xi\\nn)]8i2N', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 141}),\n",
              " Document(page_content=\"Where qi2Rn\\x02K, corresponding to the expectation of each state at each time step. Let's consider\\nqi\\nt;kwhich is the expectation over a single state value kat a single point in time t. We can write\\nthis as:\\nqi\\nt;k=E[si\\nt;kj(xi\\n1;:::;xi\\nn)] (10.20)\\n=p(si\\nt=kj(xi\\n1;:::;xi\\nn)) (10.21)\\nThis calculates the probability of a single state given all of our observed emissions for a single data\\npoint. This is exactly the smoothing operation described in the previous section! That is why we\\ncalculated our \\x0band\\x0cvalues at the beginning of the E-step using our \\x0cxed parameters, because\\nwe can now easily use the smoothing operation given by Equation 10.13 to compute our qi\\ntvalues.\\nOrdinarily, we'd be done with the E-step after computing the expectations of our hidden vari-\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 141}),\n",
              " Document(page_content=\"ables, but under the HMM setup, we need to take one more expectation before moving on to the\\nM-step. Recall that we have transition probabilities between our hidden states given by the pa-\\nrameter matrix T. Because these are transitions between latent variables, we also need to compute\\nthe expectation over the joint distribution between pairs of latent variables next to each other in\\ntime, which we will denote Qi\\nt;t+12RK\\x02K. Formally:\\nQi\\nt;t+1=E[si\\nt;si\\nt+1j(xi\\n1;:::;xi\\nn)] (10.22)\\nLet's consider Qi\\nt;t+1;k;lwhich is the transition from state kat time step tto statelat time step\\nt+ 1:\\nQi\\nt;t+1;k;l=E[si\\nt=k;si\\nt+1=lj(xi\\n1;:::;xi\\nn)] (10.23)\\n=p(si\\nt=k;si\\nt+1=lj(xi\\n1;:::;xi\\nn)) (10.24)\\n(10.25)\\nThis is calculating the probability of a speci\\x0cc latent variable transition at a speci\\x0cc time step,\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 141}),\n",
              " Document(page_content='which is exactly the transition operation described in the previous section. We can directly use our\\n\\x0band\\x0cvalues in the transition operation given by Equation 10.17.\\nWith our qiandQivalues as expectations over the hidden states and hidden joint states\\nrespectively (with the current setting of our parameters \\x0cxed), we are ready to move on to the\\nmaximization step.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 141}),\n",
              " Document(page_content='134 CHAPTER 10. HIDDEN MARKOV MODELS\\n10.4.4 M-Step\\nThe M-step mirrors what we saw in the previous chapter. In the E-step we calculated expectations\\nover our hidden variables, which allows us to set up our expected complete-data log likelihood for\\na single data point:\\nEq;Q[logp(xi;si;\\x12;T;\\x19)] =Eq;Q\\x14\\nlogp(xijsi;\\x19) + logp(si;\\x12;T)\\x15\\n=nX\\nt=1KX\\nk=1qi\\nt;kMX\\nm=1log\\x19k;xi\\nt;m+KX\\nk=1qi\\nklog\\x12k+n\\x001X\\nt=1KX\\nk=1KX\\nl=1Qi\\nt;t+1;k;llogTk;l\\nApplying the appropriate Lagrange multipliers and maximizing with respect to each of the param-\\neters of interest, we recover the following update equations:\\n\\x12k=PN\\ni=1qi\\n1;k\\nN(10.26)\\nTk;l=PN\\ni=1Pn\\x001\\nt=1Qi\\nt;t+1;k;lPN\\ni=1Pn\\x001\\nt=1qi\\nt;k(10.27)\\n\\x19k;m=PN\\ni=1Pn\\nt=1qi\\nt;kxi\\nt;mPN\\ni=1Pn\\nt=1qi\\nt;k(10.28)', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 142}),\n",
              " Document(page_content=\"After updating our parameter matrices \\x12;T;\\x19, we switch back to the E-step, continuing in this\\nway until convergence of our parameters.\\n10.4.5 From HMM Training to Inference\\nIn the preceding sections, we described the process for training an HMM. In doing so, we've actually\\nbuilt up all the machinery needed to perform inference on our trained HMM for free. Speci\\x0ccally,\\nwe've described four types of queries we can execute over a trained HMM:\\n\\x0fJoint Estimation\\n\\x0fPrediction\\n\\x0fSmoothing\\n\\x0fTransition\\nWe analyzed these already because we needed them to train the HMM, but once we've completed\\ntraining, we can use our optimized parameters along with the \\x0band\\x0cvalues that we compute with\\nthe Forward-Backward algorithm to query our HMM.\\n10.5 Conclusion\", metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 142}),\n",
              " Document(page_content='The Hidden Markov Model is a type of latent variable model motivated by the combination of\\ntime series and discrete state space data. We relied on the Expectation-Maximization algorithm\\ndescribed in the previous chapter, and developed the e\\x0ecient Forward-Backward algorithm to make\\nboth training and inference feasible for HMMs. Many of the ideas developed in this chapter will\\no\\x0ber good intuition for dynamical systems and other time series models.', metadata={'source': '/content/3. Undergraduate Fundamentals of Machine Learning Author William J. Deuschle.pdf', 'page': 142}),\n",
              " Document(page_content='[ 1 ]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 0}),\n",
              " Document(page_content='Advanced Machine Learning \\nwith Python\\nSolve challenging data science problems by mastering cutting-edge machine learning techniques in Python\\nJohn Hearty\\n \\nBIRMINGHAM - MUMBAI', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 1}),\n",
              " Document(page_content='Advanced Machine Learning with Python\\nCopyright © 2016 Packt Publishing\\nAll rights reserved. No part of this book may be reproduced, stored in a retrieval \\nsystem, or transmitted in any form or by any means, without the prior written permission of the publisher, except in the case of brief quotations embedded in critical articles or reviews.\\nEvery effort has been made in the preparation of this book to ensure the accuracy \\nof the information presented. However, the information contained in this book is sold without warranty, either express or implied. Neither the author, nor Packt Publishing, and its dealers and distributors will be held liable for any damages caused or alleged to be caused directly or indirectly by this book.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 2}),\n",
              " Document(page_content='Packt Publishing has endeavored to provide trademark information about all of the \\ncompanies and products mentioned in this book by the appropriate use of capitals. However, Packt Publishing cannot guarantee the accuracy of this information.\\nFirst published: July 2016Production reference: 1220716\\nPublished by Packt Publishing Ltd.\\nLivery Place35 Livery StreetBirmingham B3 2PB, UK.\\nISBN 978-1-78439-863-7\\nwww.packtpub.com', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 2}),\n",
              " Document(page_content='Credits\\nAuthor\\nJohn Hearty\\nReviewers\\nJared Huffman\\nAshwin Pajankar\\nCommissioning Editor\\nAkram Hussain\\nAcquisition Editor\\nSonali Vernekar\\nContent Development Editor\\nMayur Pawanikar\\nTechnical Editor\\nSuwarna Patil\\nCopy Editor\\nTasneem FatehiProject Coordinator\\nNidhi Joshi\\nProofreader\\nSafis Editing\\nIndexer\\nMariammal Chettiyar\\nGraphics\\nDisha Haria\\nProduction Coordinator\\nArvindkumar Gupta\\nCover Work\\nArvindkumar Gupta', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 3}),\n",
              " Document(page_content='About the Author\\nJohn Hearty  is a consultant in digital industries with substantial expertise in data \\nscience and infrastructure engineering. Having started out in mobile gaming, he was \\ndrawn to the challenge of AAA console analytics.\\nKeen to start putting advanced machine learning techniques into practice, he \\nsigned on with Microsoft to develop player modelling capabilities and big data \\ninfrastructure at an Xbox studio. His team made significant strides in engineering \\nand data science that were replicated across Microsoft Studios. Some of the more \\nrewarding initiatives he led included player skill modelling in asymmetrical games, \\nand the creation of player segmentation models for individualized game experiences.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 4}),\n",
              " Document(page_content='Eventually John struck out on his own as a consultant offering comprehensive \\ninfrastructure and analytics solutions for international client teams seeking new insights or data-driven capabilities. His favourite current engagement involves creating predictive models and quantifying the importance of user connections  for a popular social network.\\nAfter years spent working with data, John is largely unable to stop asking questions. \\nIn his own time, he routinely builds ML solutions in Python to fulfil a broad set of personal interests. These include a novel variant on the StyleNet computational creativity algorithm and solutions for algo-trading and geolocation-based recommendation. He currently lives in the UK.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 4}),\n",
              " Document(page_content=\"About the Reviewers\\nJared Huffman  is a lifelong gamer and extreme data geek. After completing \\nhis bachelor's degree in computer science, he started his career in his hometown \\nof Melbourne, Florida. While there, he honed his software development skills, including work on a credit card-processing system and a variety of web tools. He finished it off with a fun contract working at NASA's Kennedy Space Center before migrating to his current home in the Seattle area.\\nDiving head first into the world of data, he took up a role working on Microsoft's\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 5}),\n",
              " Document(page_content='internal finance tools and reporting systems. Feeling that he could no longer resist his love for video games, he joined the Xbox division to build their Business. To date, Jared has helped ship and support 12 games and presented at several events on various machine learning and other data topics. His latest endeavor has him applying both his software skills and analytics expertise in leading the data science efforts for Minecraft. There he gets to apply machine learning techniques, trying out fun and impactful projects, such as customer segmentation models, churn prediction, and recommendation systems.\\nOutside of work, Jared spends much of his free time playing board games and \\nvideo games with his family and friends, as well as dabbling in occasional game \\ndevelopment.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 5}),\n",
              " Document(page_content=\"First I'd like to give a big thanks to John for giving me the honor of \\nreviewing this book; it's been a great learning experience. Second, thanks to my amazing wife, Kalen, for allowing me to repeatedly skip chores to work on it. Last, and certainly not least, I'd like to thank God for providing me the opportunities to work on things  \\nI love and still make a living doing it. Being able to wake up every day and create games that bring joy to millions of players is truly  a pleasure.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 5}),\n",
              " Document(page_content=\"Ashwin Pajankar  is a software professional and IoT enthusiast with more than  \\n8 years of experience in software design, development, testing, and automation.\\nHe graduated from IIIT Hyderabad, earning an M. Tech in computer science \\nand engineering. He holds multiple professional certifications from Oracle, IBM, Teradata, and ISTQB in development, databases, and testing. He has won several awards in college through outreach initiatives, at work for technical achievements, and community service through corporate social responsibility programs.\\nHe was introduced to Raspberry Pi while organizing a hackathon at his workplace, \\nand has been hooked on Pi ever since. He writes plenty of code in C, Bash, Python, \\nand Java on his cluster of Pis. He's already authored two books on Raspberry Pi and\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 6}),\n",
              " Document(page_content='reviewed three other titles related to Python for Packt Publishing.\\nHis LinkedIn Profile is \\nhttps://in.linkedin.com/in/ashwinpajankar .\\nI would like to thank my wife, Kavitha, for the motivation.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 6}),\n",
              " Document(page_content=\"www.PacktPub.com\\neBooks, discount offers, and more\\nDid you know that Packt offers eBook versions of every book published, with PDF \\nand ePub files available? You can upgrade to the eBook version at www.PacktPub.com  \\nand as a print book customer, you are entitled to a discount on the eBook copy. Get in touch with us at \\ncustomercare@packtpub.com  for more details.\\nAt www.PacktPub.com , you can also read a collection of free technical articles, sign \\nup for a range of free newsletters and receive exclusive discounts and offers on Packt books and eBooks.\\nTM\\nhttps://www2.packtpub.com/books/subscription/packtlib\\nDo you need instant solutions to your IT questions? PacktLib is Packt's online digital book library. Here, you can search, access, and read Packt's entire library of books.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 7}),\n",
              " Document(page_content='Why subscribe?\\n• Fully searchable across every book published by Packt\\n• Copy and paste, print, and bookmark content\\n• On demand and accessible via a web browser', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 7}),\n",
              " Document(page_content=\"Of the many people I feel gratitude towards, I particularly want to thank my \\nparents … mostly for their patience. I'd like to extend thanks to Tyler Lowe for his \\ninvaluable friendship, to Mark Huntley for his bothersome emphasis on accuracy, \\nand to the former team at Lionhead Studios. I also greatly value the excellent work \\ndone by Jared Huffman and the industrious editorial team at Packt Publishing, who \\nwere hugely positive and supportive throughout the creation of this book.\\nFinally, I'd like to dedicate the work and words herein to you, the reader. There \\nhas never been a better time to get to grips with the subjects of this book; the \\nworld is stuffed with new opportunities that can be seized using creativity and an\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 9}),\n",
              " Document(page_content='appropriate model. I hope for your every success in the pursuit of those solutions.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 9}),\n",
              " Document(page_content='[ i ]Table of Contents\\nPreface v\\nChapter 1: Unsupervised Machine Learning 1\\nPrincipal component analysis 2\\nPCA – a primer 2\\nEmploying PCA  4\\nIntroducing k-means clustering 7\\nClustering – a primer 8\\nKick-starting clustering analysis 8\\nTuning your clustering configurations 13\\nSelf-organizing maps 18\\nSOM – a primer 18\\nEmploying SOM 20\\nFurther reading 24\\nSummary 25\\nChapter 2: Deep Belief Networks 27\\nNeural networks – a primer 28\\nThe composition of a neural network 28\\nNetwork topologies 29\\nRestricted Boltzmann Machine 33\\nIntroducing the RBM 33\\nTopology 34\\nTraining 35\\nApplications of the RBM 37\\nFurther applications of the RBM 49\\nDeep belief networks 49\\nTraining a DBN 50\\nApplying the DBN 50\\nValidating the DBN 54', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 11}),\n",
              " Document(page_content='Table of Contents[ ii ]Further reading 55\\nSummary 56\\nChapter 3: Stacked Denoising Autoencoders 57\\nAutoencoders 57\\nIntroducing the autoencoder 58\\nTopology 58\\nTraining 59\\nDenoising autoencoders 60\\nApplying a dA  62\\nStacked Denoising Autoencoders 66\\nApplying the SdA  67\\nAssessing SdA performance 74\\nFurther reading 75\\nSummary 75\\nChapter 4: Convolutional Neural Networks 77\\nIntroducing the CNN 77\\nUnderstanding the convnet topology 79\\nUnderstanding convolution layers 81\\nUnderstanding pooling layers 85\\nTraining a convnet 88\\nPutting it all together 88\\nApplying a CNN 92\\nFurther Reading 99\\nSummary 100\\nChapter 5: Semi-Supervised Learning 101\\nIntroduction 101\\nUnderstanding semi-supervised learning 102\\nSemi-supervised algorithms in action 103\\nSelf-training 103\\nImplementing self-training 105', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 12}),\n",
              " Document(page_content='Finessing your self-training implementation 110\\nContrastive Pessimistic Likelihood Estimation 114\\nFurther reading 126\\nSummary 127\\nChapter 6: Text Feature Engineering 129\\nIntroduction 129\\nText feature engineering 130\\nCleaning text data 131\\nText cleaning with BeautifulSoup 131\\nManaging punctuation and tokenizing 132\\nTagging and categorising words 136', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 12}),\n",
              " Document(page_content='Table of Contents[ iii ]Creating features from text data 141\\nStemming 141\\nBagging and random forests 143\\nTesting our prepared data 146\\nFurther reading 153\\nSummary 154\\nChapter 7: Feature Engineering Part II 155\\nIntroduction 155\\nCreating a feature set 156\\nEngineering features for ML applications 157\\nUsing rescaling techniques to improve the learnability of features 157\\nCreating effective derived variables 160\\nReinterpreting non-numeric features 162\\nUsing feature selection techniques 165\\nPerforming feature selection 167\\nFeature engineering in practice 175\\nAcquiring data via RESTful APIs 176\\nTesting the performance of our model 177\\nTwitter 180\\nDeriving and selecting variables using feature engineering techniques 187\\nFurther reading 199\\nSummary 200\\nChapter 8: Ensemble Methods 201', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 13}),\n",
              " Document(page_content='Introducing ensembles 202\\nUnderstanding averaging ensembles 203\\nUsing bagging algorithms 203\\nUsing random forests 205\\nApplying boosting methods 209\\nUsing XGBoost 212\\nUsing stacking ensembles 215\\nApplying ensembles in practice 218\\nUsing models in dynamic applications 221\\nUnderstanding model robustness 222\\nIdentifying modeling risk factors 228\\nStrategies to managing model robustness 230\\nFurther reading 233\\nSummary 234\\nChapter 9: Additional Python Machine Learning Tools 235\\nAlternative development tools 236\\nIntroduction to Lasagne 236\\nGetting to know Lasagne 236', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 13}),\n",
              " Document(page_content='Table of Contents[ iv ]Introduction to TensorFlow 239\\nGetting to know TensorFlow 239\\nUsing TensorFlow to iteratively improve our models 241\\nKnowing when to use these libraries 244\\nFurther reading 245\\nSummary 245\\nAppendix: Chapter Code Requirements 249\\nIndex 251', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 14}),\n",
              " Document(page_content=\"[ v ]Preface\\nHello! Welcome to this guide to advanced machine learning using Python. It's \\npossible that you've picked this up with some initial interest, but aren't quite sure what to expect. In a nutshell, there has never been a more exciting time to learn and use machine learning techniques, and working in the field is only getting more rewarding. If you want to get up-to-speed with some of the more advanced data modeling techniques and gain experience using them to solve challenging problems, this is a good book for you!\\nWhat is advanced machine learning?\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 15}),\n",
              " Document(page_content=\"Ongoing advances in computational power (per Moore's Law) have begun to make machine learning, once mostly a research discipline, more viable in commercial contexts. This has caused an explosion of new applications and new or rediscovered techniques, catapulting the obscure concepts of data science, AI, and machine learning into the public consciousness and strategic planning of companies internationally.\\nThe rapid development of machine learning applications is fueled by an ongoing\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 15}),\n",
              " Document(page_content='struggle to continually innovate, playing out at an array of research labs. The techniques developed by these pioneers are seeding new application areas and experiencing growing public awareness. While some of the innovations sought in AI and applied machine learning are still elusively far from readiness, others are a reality. Self-driving cars, sophisticated image recognition and altering capability, ever-greater strides in genetics research, and perhaps most pervasively of all, increasingly tailored content in our digital stores, e-mail inboxes, and online lives.\\nWith all of these possibilities and more at the fingertips of the committed data \\nscientist, the profession is seeing a meteoric, if clumsy, growth. Not only are there far', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 15}),\n",
              " Document(page_content='more data scientists and AI practitioners now than there were even two years ago (in \\nearly 2014), but the accessibility and openness around solutions at the high end of \\nmachine learning research has increased.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 15}),\n",
              " Document(page_content='Preface[ vi ]Research teams at Google and Facebook began to share more and more of their \\narchitecture, languages, models, and tools in the hope of seeing them applied and improved on by the growing data scientist population.\\nThe machine learning community matured enough to begin seeing trends as popular \\nalgorithms were defined or rediscovered. To put this more accurately, pre-existing trends from a mainly research community began to receive great attention from industry, with one product being a group of machine learning experts straddling \\nindustry and academia. Another product, the subject of this section, is a growing \\nawareness of advanced algorithms that can be used to crack the frontier problems of', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 16}),\n",
              " Document(page_content=\"the current day. From month to month, we see new advances made, scores rise, and the frontier moves ever further out.\\nWhat all of this means is that there may never have been a better time to move into \\nthe field of data science and develop your machine learning skillset. The introductory \\nalgorithms (including clustering, regression models, and neural network architectures) \\nand tools are widely covered in web courses and blog content. While the techniques at \\nthe cutting edge of data science (including deep learning, semi-supervised algorithms, and ensembles) remain less accessible, the techniques themselves are now available through software libraries in multiple languages. All that's needed is the combination\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 16}),\n",
              " Document(page_content=\"of theoretical knowledge and practical guidance to implement models correctly. That \\nis the requirement that this book was written to address.\\nWhat should you expect from this book?\\nYou've begun to read a book that focuses on teaching some of the advanced \\nmodeling techniques that've emerged in recent years. This book is aimed at anyone who wants to learn about those algorithms, whether you're an experienced data scientist or developer looking to parlay existing skills into a new environment.\\nI aimed first and foremost at making sure that you understand the algorithms in \\nquestion. Some of them are fairly tricky and tie into other concepts in statistics and machine learning.\\nFor neophyte readers, I definitely recommend gathering an initial understanding of\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 16}),\n",
              " Document(page_content='key concepts, including the following:\\n• Neural network architectures including the MLP architecture\\n• Learning method components including gradient descent and \\nbackpropagation\\n• Network performance measures, for example, root mean squared error\\n• K-means clustering', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 16}),\n",
              " Document(page_content=\"Preface[ vii ]At times, this book won't be able to give a subject the attention that it deserves. \\nWe cover a lot of ground in this book and the pace is fairly brisk as a result! At the end of each chapter, I refer you to further reading, in a book or online article, so that you can build a broader base of relevant knowledge. I'd suggest that it's worth doing additional reading around any unfamiliar concept that comes up as you work through this book, as machine learning knowledge tends to tie together synergistically; the more you have, the more readily you'll understand new concepts as you expand your toolkit.\\nThis concept of expanding a toolkit of skills is fundamental to what I've tried to\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 17}),\n",
              " Document(page_content=\"achieve with this book. Each chapter introduces one or multiple algorithms and looks to achieve several goals:\\n• Explaining at a high level what the algorithm does, what problems it'll solve well, and how you should expect to apply it\\n• Walking through key components of the algorithm, including topology, learning method, and performance measurement\\n• Identifying how to improve performance by reviewing model output\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 17}),\n",
              " Document(page_content='Beyond the transfer of knowledge and practical skills, this book looks to achieve a more important goal; specifically, to discuss and convey some of the qualities that are common to skilled machine learning practitioners. These include creativity, demonstrated both in the definition of sophisticated architectures and problem-specific cleaning techniques. Rigor is another key quality, emphasized throughout this book by a focus on measuring performance against meaningful targets and critically assessing early efforts.\\nFinally, this book makes no effort to obscure the realities of working on solving \\ndata challenges: the mixed results of early trials, large iteration counts, and frequent impasses. Yet at the same time, using a mixture of toy examples, dissection of expert', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 17}),\n",
              " Document(page_content=\"approaches and, toward the end of the book, more real-world challenges, we show \\nhow a creative, tenacious, and rigorous approach can break down these barriers and \\ndeliver meaningful results.\\nAs we proceed, I wish you the best of luck and encourage you to enjoy yourself as \\nyou go, tackling the content prepared for you and applying what you've learned to new domains or data.\\nLet's get started!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 17}),\n",
              " Document(page_content=\"Preface[ viii ]What this book covers\\nChapter 1, Unsupervised Machine Learning , shows you how to apply unsupervised \\nlearning techniques to identify patterns and structure within datasets.\\nChapter 2, Deep Belief Networks, explains how the RBM and DBN algorithms work; \\nyou'll know how to use them and will feel confident in your ability to improve the quality of the results that you get out of them.\\nChapter 3, Stacked Denoising Autoencoders , continues to build our skill with deep \\narchitectures by applying stacked denoising autoencoders to learn feature \\nrepresentations for high-dimensional input data.\\nChapter 4, Convolutional Neural Networks , shows you how to apply the convolutional \\nneural network (or Convnet).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 18}),\n",
              " Document(page_content=\"Chapter 5, Semi-Supervised Learning , explains how to apply several semi-supervised \\nlearning techniques, including CPLE, self-learning, and S3VM.\\nChapter 6, Text Feature Engineering , discusses data preparation skills that significantly \\nincrease the effectiveness of all the models that we've previously discussed.\\nChapter 7, Feature Engineering Part II , shows you how to interrogate the data to weed \\nout or mitigate quality issues, transform it into forms that are conducive to machine \\nlearning, and creatively enhance that data.\\nChapter 8, Ensemble Methods, looks at building more sophisticated model ensembles \\nand methods of building robustness into your model solutions.\\nChapter 9, Additional Python Machine Learning Tools , reviews some of the best in recent\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 18}),\n",
              " Document(page_content=\"tools available to data scientists, identifies the benefits that they offer, and discusses \\nhow to apply them alongside tools and techniques discussed earlier in this book, within a consistent working process.\\nAppendix A, Chapter Code Requirements , discusses tool requirements for the book, \\nidentifying required libraries for each chapter.\\nWhat you need for this book\\nThe entirety of this book's content leverages openly available data and code, \\nincluding open source Python libraries and frameworks. While each chapter's example code is accompanied by a README file documenting all the libraries required to run the code provided in that chapter's accompanying scripts,  the content of these files is collated here for your convenience.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 18}),\n",
              " Document(page_content=\"Preface[ ix ]It is recommended that some libraries required for earlier chapters be available when \\nworking with code from any later chapter. These requirements are identified using bold text. Particularly, it is important to set up the first chapter's required libraries for any content later in the book.\\nWho this book is for\\nThis title is for Python developers and analysts or data scientists who are looking to add to their existing skills by accessing some of the most powerful recent trends in data science. If you've ever considered building your own image or text-tagging solution or entering a Kaggle contest, for instance, this book is for you!\\nPrior experience of Python and grounding in some of the core concepts of machine \\nlearning would be helpful.\\nConventions\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 19}),\n",
              " Document(page_content='In this book, you will find a number of text styles that distinguish between different \\nkinds of information. Here are some examples of these styles and an explanation of their meaning.\\nCode words in text, database table names, folder names, filenames, file extensions, \\npathnames, dummy URLs, user input, and Twitter handles are shown as follows: \"We will begin applying PCA to the handwritten \\ndigits  dataset with the following code.\"\\nA block of code is set as follows:\\nimport numpy as np\\nfrom sklearn.datasets import load_digitsimport matplotlib.pyplot as pltfrom sklearn.decomposition import PCAfrom sklearn.preprocessing import scalefrom sklearn.lda import LDAimport matplotlib.cm as cm\\ndigits = load_digits()\\ndata = digits.data\\nn_samples, n_features = data.shape', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 19}),\n",
              " Document(page_content='n_digits = len(np.unique(digits.target))labels = digits.target', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 19}),\n",
              " Document(page_content=\"Preface[ x ]Any command-line input or output is written as follows:\\n[ 0.39276606  0.49571292  0.43933243  0.53573558  0.42459285           \\n  0.55686854  0.4573401   0.49876358  0.50281585  0.4689295 ]\\n0.4772857426\\nWarnings or important notes appear in a box like this.\\nTips and tricks appear like this.\\nReader feedback\\nFeedback from our readers is always welcome. Let us know what you think about \\nthis book—what you liked or disliked. Reader feedback is important for us as it helps us develop titles that you will really get the most out of.\\nTo send us general feedback, simply e-mail \\nfeedback@packtpub.com , and mention \\nthe book's title in the subject of your message.If there is a topic that you have expertise in and you are interested in either writing\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 20}),\n",
              " Document(page_content='or contributing to a book, see our author guide at \\nwww.packtpub.com/authors .\\nCustomer support\\nNow that you are the proud owner of a Packt book, we have a number of things to help you to get the most from your purchase.\\nDownloading the example code\\nYou can download the example code files for this book from your account at \\nhttp://www.packtpub.com . If you purchased this book elsewhere, you can  \\nvisit http://www.packtpub.com/support  and register to have the files e-mailed \\ndirectly to you.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 20}),\n",
              " Document(page_content=\"Preface[ xi ]You can download the code files by following these steps:\\n1. Log in or register to our website using your e-mail address and password.\\n2. Hover the mouse pointer on the SUPPORT  tab at the top.\\n3. Click on Code Downloads & Errata.\\n4. Enter the name of the book in the Search box.\\n5. Select the book for which you're looking to download the code files.\\n6. Choose from the drop-down menu where you purchased this book from.\\n7. Click on Code Download.\\nOnce the file is downloaded, please make sure that you unzip or extract the folder \\nusing the latest version of:\\n• WinRAR / 7-Zip for Windows\\n• Zipeg / iZip / UnRarX for Mac\\n• 7-Zip / PeaZip for Linux\\nThe code bundle for the book is also hosted on GitHub at https://github.com/\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 21}),\n",
              " Document(page_content='PacktPublishing/Advanced-Machine-Learning-with-Python . We also have  \\nother code bundles from our rich catalog of books and videos available at.  \\nhttps://github.com/PacktPublishing/  Check them out!\\nDownloading the color images of this book\\nWe also provide you with a PDF file that has color images of the screenshots/diagrams used in this book. The color images will help you better understand the changes in the output. You can download this file from \\nhttps://www.packtpub.\\ncom/sites/default/files/downloads/AdvancedMachineLearningwithPython_\\nColorImages.pdf .\\nErrata\\nAlthough we have taken every care to ensure the accuracy of our content, mistakes', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 21}),\n",
              " Document(page_content='do happen. If you find a mistake in one of our books—maybe a mistake in the text or the code—we would be grateful if you could report this to us. By doing so, you can save other readers from frustration and help us improve subsequent versions of this book. If you find any errata, please report them by visiting \\nhttp://www.packtpub.\\ncom/submit-errata , selecting your book, clicking on the Errata Submission Form \\nlink, and entering the details of your errata. Once your errata are verified, your submission will be accepted and the errata will be uploaded to our website or added to any list of existing errata under the Errata section of that title.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 21}),\n",
              " Document(page_content='Preface[ xii ]To view the previously submitted errata, go to https://www.packtpub.com/books/\\ncontent/support  and enter the name of the book in the search field. The required \\ninformation will appear under the Errata section.\\nPiracy\\nPiracy of copyrighted material on the Internet is an ongoing problem across all \\nmedia. At Packt, we take the protection of our copyright and licenses very seriously. If you come across any illegal copies of our works in any form on the Internet, please provide us with the location address or website name immediately so that we can pursue a remedy.\\nPlease contact us at \\ncopyright@packtpub.com  with a link to the suspected  \\npirated material.We appreciate your help in protecting our authors and our ability to bring you \\nvaluable content.\\nQuestions', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 22}),\n",
              " Document(page_content='If you have a problem with any aspect of this book, you can contact us at \\nquestions@packtpub.com , and we will do our best to address the problem.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 22}),\n",
              " Document(page_content=\"[ 1 ]Unsupervised  \\nMachine Learning\\nIn this chapter, you will learn how to apply unsupervised learning techniques to \\nidentify patterns and structure within datasets.\\nUnsupervised learning techniques are a valuable set of tools for exploratory analysis. \\nThey bring out patterns and structure within datasets, which yield information that may be informative in itself or serve as a guide to further analysis. It's critical to have a solid set of unsupervised learning tools that you can apply to help break up unfamiliar or complex datasets into actionable information.\\nWe'll begin by reviewing Principal Component Analysis  (PCA), a fundamental data \\nmanipulation technique with a range of dimensionality reduction applications. Next,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 23}),\n",
              " Document(page_content=\"we will discuss k-means clustering , a widely-used and approachable unsupervised \\nlearning technique. Then, we will discuss Kohenen's Self-Organizing Map (SOM), a \\nmethod of topological clustering that enables the projection of complex datasets into \\ntwo dimensions.\\nThroughout the chapter, we will spend some time discussing how to effectively\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 23}),\n",
              " Document(page_content='apply these techniques to make high-dimensional datasets readily accessible. We will use the UCI Handwritten Digits dataset to demonstrate technical applications of each algorithm. In the course of discussing and applying each technique, we will review practical applications and methodological questions, particularly regarding how to calibrate and validate each technique as well as which performance measures are valid. To recap, then, we will be covering the following topics in order:\\n• Principal component analysis\\n• k-means clustering\\n• Self-organizing maps', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 23}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 2 ]Principal component analysis\\nIn order to work effectively with high-dimensional datasets, it is important to have a \\nset of techniques that can reduce this dimensionality down to manageable levels. The advantages of this dimensionality reduction include the ability to plot multivariate data in two dimensions, capture the majority of a dataset's informational content within a minimal number of features, and, in some contexts, identify collinear  model components.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 24}),\n",
              " Document(page_content=\"For those in need of a refresher, collinearity in a machine learning context refers to model features that share an approximately linear relationship. For reasons that will likely be obvious, these features tend to be unhelpful as the related features are unlikely to add information mutually that either one provides independently. Moreover, collinear features may emphasize local minima or other false leads.\\nProbably the most widely-used dimensionality reduction technique today is PCA. As we'll be applying PCA in multiple contexts throughout this book, it's appropriate for us to review the technique, understand the theory behind it, and write Python code to effectively apply it.\\nPCA – a primer\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 24}),\n",
              " Document(page_content=\"PCA is a powerful decomposition technique; it allows one to break down a highly multivariate dataset into a set of orthogonal components. When taken together in sufficient number, these components can explain almost all of the dataset's variance. In essence, these components deliver an abbreviated description of the dataset. PCA has a broad set of applications and its extensive utility makes it well worth our time to cover.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 24}),\n",
              " Document(page_content='Note the slightly cautious phrasing here—a given set of components of length less than the number of variables in the original dataset will almost always lose some amount of the information content within the source dataset. This lossiness is typically minimal, given enough components, but in cases where small numbers of principal components are composed from very high-dimensional datasets, there may be substantial lossiness. As such, when performing PCA, it is always appropriate to consider how many components will be necessary to effectively model the dataset in question.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 24}),\n",
              " Document(page_content=\"Chapter 1[ 3 ]PCA works by successively identifying the axis of greatest variance in a dataset (the \\nprincipal components). It does this as follows:\\n1. Identifying the center point of the dataset.\\n2. Calculating the covariance matrix of the data.\\n3. Calculating the eigenvectors of the covariance matrix.\\n4. Orthonormalizing the eigenvectors.\\n5. Calculating the proportion of variance represented by each eigenvector.\\nLet's unpack these concepts briefly:\\n• Covariance is effectively variance applied to multiple dimensions; it is the variance between two or more variables. While a single value can capture the variance in one dimension or variable, it is necessary to use a 2 x 2 matrix to \\ncapture the covariance between two variables, a 3 x 3 matrix to capture the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 25}),\n",
              " Document(page_content=\"covariance between three variables, and so on. So the first step in PCA is to \\ncalculate this covariance matrix.\\n• An Eigenvector is a vector that is specific to a dataset and linear \\ntransformation. Specifically, it is the vector that does not change in direction \\nbefore and after the transformation is performed. To get a better feeling for \\nhow this works, imagine that you're holding a rubber band, straight, between both hands. Let's say you stretch the band out until it is taut between your \\nhands. The eigenvector is the vector that did not change direction between \\nbefore the stretch and during it; in this case, it's the vector running directly \\nthrough the center of the band from one hand to the other.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 25}),\n",
              " Document(page_content='• Orthogonalization is the process of finding two vectors that are  orthogonal (at right angles) to one another. In an n-dimensional data space, the process of orthogonalization takes a set of vectors and yields a set of orthogonal vectors.\\n• Orthonormalization is an orthogonalization process that also normalizes  \\nthe product.\\n• Eigenvalue (roughly corresponding to the length of the eigenvector) is used to calculate the proportion of variance represented by each eigenvector. This is done by dividing the eigenvalue for each eigenvector by the sum of eigenvalues for all eigenvectors.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 25}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 4 ]In summary, the covariance matrix is used to calculate Eigenvectors. An \\northonormalization process is undertaken that produces orthogonal, normalized vectors from the Eigenvectors. The eigenvector with the greatest eigenvalue is the first principal component with successive components having smaller eigenvalues. In this way, the PCA algorithm has the effect of taking a dataset and transforming it into a new, lower-dimensional coordinate system.\\nEmploying PCA\\nNow that we've reviewed the PCA algorithm at a high level, we're going to jump straight in and apply PCA to a key Python dataset—the UCI handwritten \\ndigits  \\ndataset, distributed as part of scikit-learn .\\nThis dataset is composed of 1,797 instances of handwritten digits gathered from\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 26}),\n",
              " Document(page_content=\"44 different writers. The input (pressure and location) from these authors' writing is resampled twice across an 8 x 8 grid so as to yield maps of the kind shown in the \\nfollowing image:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 26}),\n",
              " Document(page_content='Chapter 1[ 5 ]These maps can be transformed into feature vectors of length 64, which are then \\nreadily usable as analysis input. With an input dataset of 64 features, there is an immediate appeal to using a technique like PCA to reduce the set of variables to a manageable amount. As it currently stands, we cannot effectively explore the dataset with exploratory visualization!\\nWe will begin applying PCA to the handwritten \\ndigits  dataset with the  \\nfollowing code:\\nimport numpy as np\\nfrom sklearn.datasets import load_digitsimport matplotlib.pyplot as pltfrom sklearn.decomposition import PCAfrom sklearn.preprocessing import scalefrom sklearn.lda import LDAimport matplotlib.cm as cm\\ndigits = load_digits()\\ndata = digits.data\\nn_samples, n_features = data.shape', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 27}),\n",
              " Document(page_content='n_digits = len(np.unique(digits.target))labels = digits.target\\nThis code does several things for us:\\n1. First, it loads up a set of necessary libraries, including numpy , a set of \\ncomponents from scikit-learn, including the digits  dataset itself, PCA and \\ndata scaling functions, and the plotting capability of matplotlib.\\n2. The code then begins preparing the digits  dataset. It does several things  \\nin order:\\n °First, it loads the dataset before creating helpful variables\\n °The data  variable is created for subsequent use, and the number of \\ndistinct digits  in the target  vector (0 through to 9, so n_digits \\n= 10 ) is saved as a variable that we can easily access for subsequent \\nanalysis\\n °The target  vector is also saved as labels for later use', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 27}),\n",
              " Document(page_content='°All of this variable creation is intended to simplify subsequent analysis', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 27}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 6 ]3. With the dataset ready, we can initialize our PCA algorithm and apply it to \\nthe dataset:\\npca = PCA(n_components=10)\\ndata_r = pca.fit(data).transform(data)\\nprint('explained variance ratio (first two components): %s' % \\nstr(pca.explained_variance_ratio_))\\nprint('sum of explained variance (first two components): %s' % \\nstr(sum(pca.explained_variance_ratio_)))\\n4. This code outputs the variance explained by each of the first ten principal \\ncomponents ordered by explanatory power.\\nIn the case of this set of 10 principal components, they collectively explain 0.589 \\nof the overall dataset variance. This isn't actually too bad, considering that it's a reduction from 64 variables to \\n10 components. It does, however, illustrate the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 28}),\n",
              " Document(page_content=\"potential lossiness of PCA. The key question, though, is whether this reduced set of components makes subsequent analysis or classification easier to achieve; that is, whether many of the remaining components contained variance that disrupts classification attempts.\\nHaving created a \\ndata_r  object containing the output of pca performed over the \\ndigits  dataset, let's visualize the output. To do so, we'll first create a vector of \\ncolors  for class coloration. We then simply create a scatterplot with colorized \\nclasses:\\nX = np.arange(10)\\nys = [i+x+(i*x)**2 for i in range(10)]\\nplt.figure()\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 28}),\n",
              " Document(page_content=\"colors = cm.rainbow(np.linspace(0, 1, len(ys)))for c, i target_name in zip(colors, [1,2,3,4,5,6,7,8,9,10], labels):   plt.scatter(data_r[labels == I, 0], data_r[labels == I, 1],        c=c, alpha = 0.4)   plt.legend()   plt.title('Scatterplot of Points plotted in first \\\\n'   '10 Principal Components')   plt.show()\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 28}),\n",
              " Document(page_content=\"Chapter 1[ 7 ]The resulting scatterplot looks as follows:\\nThis plot shows us that, while there is some separation between classes in the first \\ntwo principal components, it may be tricky to classify highly accurately with this \\ndataset. However, classes do appear to be clustered and we may be able to get reasonably good results by employing a clustering analysis. In this way, PCA has given us some insight into how the dataset is structured and has informed our subsequent analysis.\\nAt this point, let's take this insight and move on to examine clustering by the \\napplication of the k-means clustering algorithm.\\nIntroducing k-means clustering\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 29}),\n",
              " Document(page_content='In the previous section, you learned that unsupervised machine learning algorithms are used to extract key structural or information content from large, possibly complex datasets. These algorithms do so with little or no manual input and function without the need for training data (sets of labeled explanatory and response variables needed to train an algorithm in order to recognize the desired classification boundaries). This means that unsupervised algorithms are effective tools to generate information about the structure and content of new or unfamiliar datasets. They allow the analyst to build a strong understanding in a fraction of the time.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 29}),\n",
              " Document(page_content='Unsupervised Machine Learning[ 8 ]Clustering – a primer\\nClustering is probably the archetypal unsupervised learning technique for several \\nreasons.\\nA lot of development time has been sunk into optimizing clustering algorithms, with \\nefficient implementations available in most data science languages including Python.\\nClustering algorithms tend to be very fast, with smoothed implementations \\nrunning in polynomial time. This makes it uncomplicated to run multiple clustering \\nconfigurations, even over large datasets. Scalable clustering implementations also \\nexist that parallelize the algorithm to run over TB-scale datasets.\\nClustering algorithms are frequently easily understood and their operation is thus \\neasy to explain if necessary.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 30}),\n",
              " Document(page_content='The most popular clustering algorithm is k-means; this algorithm forms k-many \\nclusters by first randomly initiating the clusters as k-many points in the data space. Each of these points is the mean of a cluster. An iterative process then occurs, running as follows:\\n• Each point is assigned to a cluster based on the least (within cluster) sum of squares, which is intuitively the nearest mean.\\n• The center (centroid) of each cluster becomes the new mean. This causes each of the means to shift.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 30}),\n",
              " Document(page_content='Over enough iterations, the centroids move into positions that minimize a performance metric (the performance metric most commonly used is the \"within cluster least sum of squares\" measure). Once this measure is minimized, observations are no longer reassigned during iteration; at this point the algorithm has converged on a solution.\\nKick-starting clustering analysis\\nNow that we\\'ve reviewed the clustering algorithm, let\\'s run through the code and see what clustering can do for us:\\nfrom time import time\\nimport numpy as npimport matplotlib.pyplot as plt\\nnp.random.seed()\\ndigits = load_digits()', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 30}),\n",
              " Document(page_content='Chapter 1[ 9 ]data = scale(digits.data)\\nn_samples, n_features = data.shape\\nn_digits = len(np.unique(digits.target))labels = digits.target\\nsample_size = 300print(\"n_digits: %d, \\\\t n_samples %d, \\\\t n_features %d\"\\n   % (n_digits, n_samples, n_features))\\nprint(79 * \\'_\\')\\nprint(\\'% 9s\\' % \\'init\\'\\'         time   inertia   homo   compl   v-meas   \\nARI     AMI  silhouette\\')\\ndef bench_k_means(estimator, name, data):', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 31}),\n",
              " Document(page_content=\"t0 = time()   estimator.fit(data)   print('% 9s %.2fs %i %.3f %.3f %.3f %.3f %.3f %.3f'      % (name, (time() - t0), estimator.inertia_,         metrics.homogeneity_score(labels, estimator.labels_),         metrics.completeness_score(labels, estimator.labels_),         metrics.v_measure_score(labels, estimator.labels_),         metrics.adjusted_rand_score(labels, estimator.labels_),         metrics.silhouette_score(data, estimator.labels_,            metric='euclidean',            sample_size=sample_size)))\\nOne critical difference between this code and the PCA code we saw\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 31}),\n",
              " Document(page_content=\"previously is that this code begins by applying a scale function to the digits dataset. This function scales values in the dataset between 0 and 1. It's critically important to scale data wherever needed, either on a log scale or bound scale, so as to prevent the magnitude of different feature values to have disproportionately powerful effects on the dataset. The key to determining whether the data needs scaling at all (and what kind of scaling is needed, within which range, and so on) is very much tied to the shape and nature of the data. If the distribution of the data shows outliers or variation within a large range, it may be appropriate to apply log-scaling. Whether this is done manually through visualization and exploratory analysis techniques or through the use of summary\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 31}),\n",
              " Document(page_content='statistics, decisions around scaling are tied to the data under inspection and the analysis techniques to be used. A further discussion of scaling decisions and considerations may be found in Chapter 7, Feature Engineering Part II .', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 31}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 10 ]Helpfully, scikit-learn uses the k-means++ algorithm by default, which improves \\nover the original k-means algorithm in terms of both running time and success rate in avoiding poor clusterings.\\nThe algorithm achieves this by running an initialization procedure to find cluster \\ncentroids that approximate minimal variance within classes.\\nYou may have spotted from the preceding code that we're using a set of performance \\nestimators to track how well our k-means application is performing. It isn't practical \\nto measure the performance of a clustering algorithm based on a single correctness \\npercentage or using the same performance measures that are commonly used with \\nother algorithms. The definition of success for clustering algorithms is that they\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 32}),\n",
              " Document(page_content='provide an interpretation of how input data is grouped that trades off between \\nseveral factors, including class separation, in-group similarity, and cross-group \\ndifference.\\nThe homogeneity score is a simple, zero-to-one-bounded measure of the degree to \\nwhich clusters contain only assignments of a given class. A score of one indicates that all clusters contain measurements from a single class. This measure is complimented by the completeness score, which is a similarly bounded measure of the extent \\nto which all members of a given class are assigned to the same cluster. As such, a completeness score and homogeneity score of one indicates a perfect clustering solution.\\nThe validity measure (v-measure) is a harmonic mean of the homogeneity and', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 32}),\n",
              " Document(page_content='completeness scores, which is exactly analogous to the F-measure for binary classification. In essence, it provides a single, 0-1-scaled value to monitor both homogeneity and completeness.\\nThe Adjusted Rand Index  (ARI) is a similarity measure that tracks the consensus \\nbetween sets of assignments. As applied to clustering, it measures the consensus \\nbetween the true, pre-existing observation labels and the labels predicted as an \\noutput of the clustering algorithm. The Rand index measures labeling similarity on a \\n0-1 bound scale, with one equaling perfect prediction labels.\\nThe main challenge with all of the preceding performance measures as well as other', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 32}),\n",
              " Document(page_content=\"similar measures (for example, Akaike's mutual information criterion) is that they require an understanding of the ground truth, that is, they require some or all of the data under inspection to be labeled. If labels do not exist and cannot be generated, these measures won't work. In practice, this is a pretty substantial drawback as very few datasets come prelabeled and the creation of labels can be time-consuming.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 32}),\n",
              " Document(page_content='Chapter 1[ 11 ]One option to measure the performance of a k-means clustering solution without \\nlabeled data is the Silhouette Coefficient. This is a measure of how well-defined the clusters within a model are. The Silhouette Coefficient for a given dataset is the mean of the coefficient for each sample, where this coefficient is calculated as follows:\\n( )max ,b asa b−=\\nThe definitions of each term are as follows:\\n• a: The mean distance between a sample and all other points in the same cluster\\n• b: The mean distance between a sample and all other points in the next nearest cluster\\nThis score is bounded between -1 and 1 , with -1 indicating incorrect clustering, 1 \\nindicating very dense clustering, and scores around 0  indicating overlapping clusters.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 33}),\n",
              " Document(page_content='This tends to fit our expectations of how a good clustering solution is composed.\\nIn the case of the \\ndigits  dataset, we can employ all of the performance measures \\ndescribed here. As such, we\\'ll complete the preceding example by initializing our \\nbench_k_means  function over the digits  dataset:\\nbench_k_means(KMeans(init=\\'k-means++\\', n_clusters=n_digits, n_\\ninit=10), name=\"k-means++\", data=data)\\nprint(79 * \\'_\\')\\nThis yields the following output (note that the random seed means your results will \\nvary from mine!):\\nLets take a look at these results in more detail.\\nThe Silhouette score at 0.123  is fairly low, but not surprisingly so, given that the \\nhandwritten digits data is inherently noisy and does tend to overlap. However, some', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 33}),\n",
              " Document(page_content='of the other scores are not that impressive. The V-measure at 0.619  is reasonable, but \\nin this case is held back by a poor homogeneity measure, suggesting that the cluster centroids did not resolve perfectly. Moreover, the ARI at \\n0.465  is not great.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 33}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 12 ]Let's put this in context. The worst case classification attempt, \\nrandom assignment, would give at best 10% classification accuracy. All of our performance measures would be accordingly very low. \\nWhile we're definitely doing a lot better than that, we're still trailing \\nfar behind the best computational classification attempts. As we'll \\nsee in Chapter 4, Convolutional Neural Networks , convolutional \\nnets achieve results with extremely low classification errors on handwritten digit datasets. We're unlikely to achieve this level of \\naccuracy with traditional k-means clustering!\\nAll in all, it's reasonable to think that we could do better.\\nTo give this another try, we'll apply an additional stage of processing. To learn\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 34}),\n",
              " Document(page_content='how to do this, we\\'ll apply PCA—the technique we previously walked through—to reduce the dimensionality of our input dataset. The code to achieve this is very simple, as follows:\\npca = PCA(n_components=n_digits).fit(data)\\nbench_k_means(KMeans(init=pca.components_, n_clusters=10),name=\"PCA-based\",data=data) \\nThis code simply applies PCA to the digits  dataset, yielding as many principal \\ncomponents as there are classes (in this case, digits). It can be sensible to review the \\noutput of PCA before proceeding as the presence of any small principal components \\nmay suggest a dataset that contains collinearity or otherwise merits further inspection.\\nThis instance of clustering shows noticeable improvement:\\nThe V-measure and ARI have increased by approximately 0.08 points, with the', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 34}),\n",
              " Document(page_content='V-measure reading a fairly respectable 0.693 . The Silhouette Coefficient did not \\nchange significantly. Given the complexity and interclass overlap within the digits  \\ndataset, these are good results, particularly stemming from such a simple code addition!', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 34}),\n",
              " Document(page_content='Chapter 1[ 13 ]Inspection of the digits  dataset with clusters superimposed shows that some \\nmeaningful clusters appear to have been formed. It is also apparent from the \\nfollowing plot that actually detecting the character from the input feature vectors may be a challenging task:\\nTuning your clustering configurations\\nThe previous examples described how to apply k-means, walked through relevant code, showed how to plot the results of a clustering analysis, and identified appropriate performance metrics. However, when applying k-means to real-world datasets, there are some extra precautions that need to be taken, which we will discuss.\\nAnother critical practical point is how to select an appropriate value for k. Initializing', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 35}),\n",
              " Document(page_content=\"k-means clustering with a specific k value may not be harmful, but in many cases it is not clear initially how many clusters you might find or what values of k may be helpful.\\nWe can rerun the preceding code for multiple values of k in a batch and look at the \\nperformance metrics, but this won't tell us which instance of k is most effectively capturing structure within the data. The risk is that as k increases, the Silhouette \\nCoefficient or unexplained variance may decrease dramatically, without meaningful \\nclusters being formed. The extreme case of this would be if k = o, where o is the \\nnumber of observations in the sample; every point would have its own cluster, the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 35}),\n",
              " Document(page_content=\"Silhouette Coefficient would be low, but the results wouldn't be meaningful. There are, however, many less extreme cases in which overfitting may occur due to an overly high k value.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 35}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 14 ]To mitigate this risk, it's advisable to use supporting techniques to motivate a \\nselection of k. One useful technique in this context is the elbow method. The elbow \\nmethod is a very simple technique; for each instance of k, plot the percentage of \\nexplained variance against k. This typically leads to a plot that frequently looks like a bent arm.\\nFor the PCA-reduced dataset, this code looks like the following snippet:\\nimport numpy as np\\nfrom sklearn.cluster import KMeansfrom sklearn.datasets import load_digitsfrom scipy.spatial.distance import cdistimport matplotlib.pyplot as pltfrom sklearn.decomposition import PCAfrom sklearn.preprocessing import scale\\ndigits = load_digits()\\ndata = scale(digits.data)\\nn_samples, n_features = data.shape\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 36}),\n",
              " Document(page_content=\"n_digits = len(np.unique(digits.target))labels = digits.target\\nK = range(1,20)\\nexplainedvariance= []for k in K:   reduced_data = PCA(n_components=2).fit_transform(data)   kmeans = KMeans(init = 'k-means++', n_clusters = k, n_init = k)   kmeans.fit(reduced_data)   explainedvariance.append(sum(np.min(cdist(reduced_data,    kmeans.cluster_centers_, 'euclidean'), axis =      1))/data.shape[0])   plt.plot(K, meandistortions, 'bx-')   plt.show()\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 36}),\n",
              " Document(page_content=\"Chapter 1[ 15 ]This application of the elbow method takes the PCA reduction from the previous code \\nsample and applies a test of the explained variance (specifically, a test of the variance \\nwithin clusters). The result is output as a measure of unexplained variance for each value of k in the range specified. In this case, as we're using the \\ndigits  dataset \\n(which we know to have ten classes), the range  specified was 1 to 20:\\nThe elbow method involves selecting the value of k that maximizes explained variance while minimizing \\nK; that is, the value of k at the crook of the elbow.  \\nThe technical sense underlying this is that a minimal gain in explained variance  at greater values of k is offset by the increasing risk of overfitting.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 37}),\n",
              " Document(page_content=\"Elbow plots may be more or less pronounced and the elbow may not always be \\nclearly identifiable. This example shows a more gradual progression than may be observable in other cases with other datasets. It's worth noting that, while we know the number of classes within the dataset to be ten, the elbow method starts to show diminishing returns on k increases almost immediately and the elbow is located at around five classes. This has a lot to do with the substantial overlap between classes, which we saw in previous plots. While there are ten classes, it becomes increasingly difficult to clearly identify more than five or so.\\nWith this in mind, it's worth noting that the elbow method is intended for use \\nas a heuristic rather than as some kind of objective principle. The use of PCA as\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 37}),\n",
              " Document(page_content='a preprocess to improve clustering performance also tends to smooth the graph, \\ndelivering a more gradual curve than otherwise.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 37}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 16 ]In addition to making use of the elbow method, it can be valuable to look at the \\nclusters themselves, as we did earlier in the chapter, using PCA to reduce the dimensionality of the data. By plotting the dataset and projecting cluster assignation onto the data, it is sometimes very obvious when a k-means implementation has fitted to a local minima or has overfit the data. The following plot demonstrates extreme overfitting of our previous k-means clustering algorithm to the \\ndigits  \\ndataset, artificially prompted by using K = 150. In this example, some clusters \\ncontain a single observation; there's really no way that this output would generalize to other samples well:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 38}),\n",
              " Document(page_content=\"Plotting the elbow function or cluster assignments is quick to achieve and straightforward to interpret. However, we've spoken of these techniques in terms of being heuristics. If a dataset contains a deterministic number of classes, we may not be sure that a heuristic method will deliver generalizable results.\\nAnother drawback is that visual plot checking is a very manual technique, which \\nmakes it poorly-suited for production environments or automation. In such circumstances, it's ideal to find a code-based, automatable method. One solid option in this case is v-fold cross-validation, a widely-used validation technique.\\nCross-validation is simple to undertake. To make it work, one splits the dataset into\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 38}),\n",
              " Document(page_content=\"v parts. One of the parts is set aside individually as a test set. The model is trained against the training data, which is all parts except the test set. Let's try this now, again using the \\ndigits  dataset:\\nimport numpy as np\\nfrom sklearn import cross_validationfrom sklearn.cluster import KMeans\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 38}),\n",
              " Document(page_content=\"Chapter 1[ 17 ]from sklearn.datasets import load_digits\\nfrom sklearn.preprocessing import scale\\ndigits = load_digits()\\ndata = scale(digits.data)\\nn_samples, n_features = data.shape\\nn_digits = len(np.unique(digits.target))labels = digits.target\\nkmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=n_\\ndigits)\\ncv = cross_validation.ShuffleSplit(n_samples, n_iter = 10, test_size = \\n0.4, random_state = 0)\\nscores = cross_validation.cross_val_score(kmeans, data, labels, cv = \\ncv, scoring = 'adjusted_rand_score')\\nprint(scores)print(sum(scores)/cv.n_iter)\\nThis code performs  some now familiar data loading and preparation and initializes \\nthe k-means clustering algorithm. It then defines cv, the cross-validation parameters.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 39}),\n",
              " Document(page_content=\"This includes specification of the number of iterations, n_iter , and the amount \\nof data that should be used in each fold. In this case, we're using 60% of the data \\nsamples as training data and 40% as test data.\\nWe then apply the k-means model and cv parameters that we've specified within the \\ncross-validation scoring function and print the results as scores . Let's take a look at \\nthese scores now:\\n[ 0.39276606  0.49571292  0.43933243  0.53573558  0.42459285           \\n  0.55686854  0.4573401   0.49876358  0.50281585  0.4689295 ]\\n0.4772857426\\nThis output gives us, in order, the adjusted Rand score for cross-validated, \\nk-means++ clustering performed across each of the 10 folds in order. We can see \\nthat results do fluctuate between around 0.4 and 0.55 ; the earlier ARI score for\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 39}),\n",
              " Document(page_content=\"k-means++ without PCA fell within this range (at 0.465 ). What we've created, then, \\nis code that we can incorporate into our analysis in order to check the quality of our clustering automatically on an ongoing basis.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 39}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 18 ]As noted earlier in this chapter, your choice of success measure is contingent on what \\ninformation you already have. In most cases, you won't have access to ground truth labels from a dataset and will be obliged to use a measure such as the Silhouette Coefficient that we discussed previously.\\nSometimes, even using both cross-validation and visualizations won't provide a conclusive result. Especially with unfamiliar datasets, it's not unheard of to run into issues where some noise or \\nsecondary signal resolves better at a different \\nk value than the signal \\nyou're attempting to analyze.\\nAs with every other algorithm discussed in this book, it is imperative\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 40}),\n",
              " Document(page_content=\"to understand the dataset one wishes to work with. Without this insight, it's entirely possible for even a technically correct and rigorous analysis to deliver inappropriate conclusions. Chapter 6, \\nText Feature Engineering  will discuss principles and techniques for the \\ninspection and preparation of unfamiliar datasets more thoroughly.\\nSelf-organizing maps\\nA SOM is a technique to generate topological representations of data in reduced \\ndimensions. It is one of a number of techniques with such applications, with a  \\nbetter-known alternative being PCA. However, SOMs present unique opportunities, both as dimensionality reduction techniques and as a visualization format.\\nSOM – a primer\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 40}),\n",
              " Document(page_content=\"The SOM algorithm involves iteration over many simple operations. When applied at a smaller scale, it behaves similarly to k-means clustering (as we'll see shortly). At a larger scale, SOMs reveal the topology of complex datasets in a powerful way.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 40}),\n",
              " Document(page_content='Chapter 1[ 19 ]An SOM is made up of a grid (commonly rectangular or hexagonal) of nodes, where \\neach node contains a weight vector that is of the same dimensionality as the input dataset. The nodes may be initialized randomly, but an initialization that roughly approximates the distribution of the dataset will tend to train faster.\\nThe algorithm iterates as observations are presented as input. Iteration takes the \\nfollowing form:\\n• Identifying the winning node in the current configuration—the Best \\nMatching Unit  (BMU). The BMU is identified by measuring the Euclidean \\ndistance in the data space of all the weight vectors.\\n• The BMU is adjusted (moved) towards the input vector.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 41}),\n",
              " Document(page_content=\"• Neighboring nodes are also adjusted, usually by lesser amounts, with the magnitude of neighboring movement being dictated by a neighborhood function. (Neighborhood functions vary. In this chapter, we'll use a Gaussian neighborhood function.)\\nThis process repeats over potentially many iterations, using sampling if appropriate, until the network converges (reaching a position where presenting a new input does not provide an opportunity to minimize loss).\\nA node in an SOM is not unlike that of a neural network. It typically possesses a \\nweight vector of length equal to the dimensionality of the input dataset. This means that the topology of the input dataset can be preserved and visualized through a lower-dimensional mapping.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 41}),\n",
              " Document(page_content=\"The code for this SOM class implementation is available in the book repository  \\nin the \\nsom.py  script. For now, let's start working with the SOM algorithm in a \\nfamiliar context.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 41}),\n",
              " Document(page_content='Unsupervised Machine Learning[ 20 ]Employing SOM\\nAs discussed previously, the SOM algorithm is iterative, being based around \\nEuclidean distance comparisons of vectors.\\nThis mapping tends to form a fairly readable 2D grid. In the case of the  \\ncommonly-used Iris tutorial dataset, an SOM will map it out pretty cleanly:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 42}),\n",
              " Document(page_content=\"In this diagram, the classes have been separated and also ordered spatially. The background coloring in this case is a clustering density measure. There is some minimal overlap between the blue and green classes, where the SOM performed an imperfect separation. On the Iris dataset, an SOM will tend to approach a converged solution on the order of 100 iterations, with little visible improvement after 1,000. For more complex datasets containing less clearly divisible cases, this process can take tens of thousands of iterations.\\nAwkwardly, there aren't implementations of the SOM algorithm within pre-existing \\nPython packages like scikit-learn. This makes it necessary for us to use our own implementation.\\nThe SOM code we'll be working with for this purpose is located in the associated\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 42}),\n",
              " Document(page_content=\"GitHub repository. For now, let's take a look at the relevant script and get an \\nunderstanding of how the code works:\\nimport numpy as np\\nfrom sklearn.datasets import load_digitsfrom som import Som\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 42}),\n",
              " Document(page_content='Chapter 1[ 21 ]from pylab import plot,axis,show,pcolor,colorbar,bone\\ndigits = load_digits()\\ndata = digits.datalabels = digits.target\\nAt this point, we\\'ve loaded the digits  dataset and identified labels  as a separate \\nset of data. Doing this will enable us to observe how the SOM algorithm separates \\nclasses when assigning them to map:\\nsom = Som(16,16,64,sigma=1.0,learning_rate=0.5)\\nsom.random_weights_init(data)print(\"Initiating SOM.\")som.train_random(data,10000) print(\"\\\\n. SOM Processing Complete\")\\nbone()\\npcolor(som.distance_map().T) colorbar()\\nAt this point, we have utilized a Som class that is provided in a separate file, Som.\\npy, in the repository. This class contains the methods required to deliver the SOM', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 43}),\n",
              " Document(page_content=\"algorithm we discussed earlier in the chapter. As arguments to this function, we \\nprovide the dimensions of the map (After trialing a range of options, we'll start out with 16 x 16 in this case—this grid size gave the feature map enough space to spread out while retaining some overlap between groups.) and the dimensionality of the input data. (This argument determines the length of the weight vector within the SOM's nodes.) We also provide values for sigma and learning rate.\\nSigma, in this case, defines the spread of the neighborhood function. As noted\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 43}),\n",
              " Document(page_content=\"previously, we're using a Gaussian neighborhood function. The appropriate value for sigma varies by grid size. For an 8 x 8 grid, we would typically want to use a value of 1.0 for Sigma, while in this case we're using 1.3 for a 16 x 16 grid. It is fairly obvious when one's value for sigma is off; if the value is too small, values tend to cluster near the center of the grid. If the values are too large, the grid typically ends up with several large, empty spaces towards the center.\\nThe learning rate self-explanatorily defines the initial learning rate for the SOM. As \\nthe map continues to iterate, the learning rate adjusts according to the following function:\\n( ) ( ) ( ) 1 0.5 learning rate t l earnin g rate t t = + ∗\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 43}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 22 ]Here, t is the iteration index.\\nWe follow up by first initializing our SOM with random weights.\\nAs with k-means clustering, this initialization method is slower than \\ninitializing based on an approximation of the data distribution. A preprocessing step similar to that employed by the k-means++ algorithm would accelerate the SOM's runtime. Our SOM runs sufficiently quickly over the digits dataset to make this optimization unnecessary for now.\\nNext, we set up label and color assignations for each class, so that we can distinguish classes on the plotted SOM. Following this, we iterate through each data point.\\nOn each iteration, we plot a class-specific marker for the BMU as calculated by our \\nSOM algorithm.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 44}),\n",
              " Document(page_content='When the SOM finishes iteration, we add a U-Matrix (a colorized matrix of relative \\nobservation density) as a monochrome-scaled plot layer:\\nlabels[labels == \\'0\\'] = 0\\nlabels[labels == \\'1\\'] = 1labels[labels == \\'2\\'] = 2labels[labels == \\'3\\'] = 3labels[labels == \\'4\\'] = 4labels[labels == \\'5\\'] = 5labels[labels == \\'6\\'] = 6labels[labels == \\'7\\'] = 7labels[labels == \\'8\\'] = 8labels[labels == \\'9\\'] = 9\\nmarkers = [\\'o\\', \\'v\\', \\'1\\', \\'3\\', \\'8\\', \\'s\\', \\'p\\', \\'x\\', \\'D\\', \\'*\\']\\ncolors = [\"r\", \"g\", \"b\", \"y\", \"c\", (0,0.1,0.8), (1,0.5,0), (1,1,0.3), \\n\"m\", (0.4,0.6,0)]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 44}),\n",
              " Document(page_content=\"for cnt,xx in enumerate(data):   w = som.winner(xx)    plot(w[0]+.5,w[1]+.5,markers[labels[cnt]],       markerfacecolor='None', markeredgecolor=colors[labels[cnt]],    markersize=12, markeredgewidth=2)   axis([0,som.weights.shape[0],0,som.weights.shape[1]])   show()\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 44}),\n",
              " Document(page_content=\"Chapter 1[ 23 ]This code generates a plot similar to the following:\\nThis code delivers  a 16 x 16 node SOM plot. As we can see, the map has done a \\nreasonably good job of separating each cluster into topologically distinct areas of \\nthe map. Certain classes (particularly the digits five in cyan circles and nine in green stars) have been located over multiple parts of the SOM space. For the most part, though, each class occupies a distinct region and it's fair to say that the SOM has been reasonably effective. The U-Matrix shows that regions with a high density of points are co-habited by data from multiple classes. This isn't really a surprise as we saw similar results with k-means and PCA plotting.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 45}),\n",
              " Document(page_content=\"Unsupervised Machine Learning[ 24 ]Further reading\\nVictor Powell and Lewis Lehe provide a fantastic interactive, visual explanation of \\nPCA at http://setosa.io/ev/principal-component-analysis/ , this is ideal for \\nreaders who are new to the core concepts of PCA or who are not quite getting it.\\nFor a lengthier and more mathematically-involved treatment of PCA, touching on \\nunderlying matrix transformations, Jonathon Shlens from Google research provides \\na clear and thorough explanation at http://arxiv.org/abs/1404.1100 .\\nFor a thorough worked example that translates Jonathon's description into clear Python code, consider Sebastian Raschka's demonstration using the Iris dataset at \\nhttp://sebastianraschka.com/Articles/2015_pca_in_3_steps.html .\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 46}),\n",
              " Document(page_content=\"Finally, consider the sklearn documentation for more details on arguments to the PCA class at \\nhttp://scikit-learn.org/stable/modules/generated/sklearn.\\ndecomposition.PCA.html .\\nFor a lively and expert treatment of k-means, including detailed investigations of the conditions that cause it to fail, and potential alternatives in such cases, consider David Robinson's fantastic blog, variance explained at \\nhttp://varianceexplained.\\norg/r/kmeans-free-lunch/ . \\nA specific discussion of the Elbow method is provided by Rick Gove at  \\nhttps://bl.ocks.org/rpgove/0060ff3b656618e9136b .\\nFinally, consider sklearn's documentation for another view on unsupervised learning algorithms, including k-means at \\nhttp://scikit-learn.org/stable/tutorial/\\nstatistical_inference/unsupervised_learning.html .\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 46}),\n",
              " Document(page_content=\"Much of the existing material on Kohonen's SOM is either rather old, very  high-level, or formally expressed. A decent alternative to the description in this book is provided by John Bullinaria at \\nhttp://www.cs.bham.ac.uk/~jxb/NN/l16.pdf .\\nFor readers interested in a deeper understanding of the underlying mathematics,  I'd recommend reading the work of Tuevo Kohonen directly. The 2012 edition of self-organising maps is a great place to start.\\nThe concept of multicollinearity, referenced in the chapter, is given a clear \\nexplanation for the unfamiliar at \\nhttps://onlinecourses.science.psu.edu/\\nstat501/node/344 .\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 46}),\n",
              " Document(page_content=\"Chapter 1[ 25 ]Summary\\nIn this chapter, we've reviewed three techniques with a broad range of applications \\nfor preprocessing and dimensionality reduction. In doing so, you learned a lot about an unfamiliar dataset.\\nWe started out by applying PCA, a widely-utilized dimensionality reduction \\ntechnique, to help us understand and visualize a high-dimensional dataset. We then followed up by clustering the data using k-means clustering, identifying means of improving and measuring our k-means analysis through performance metrics, the elbow method, and cross-validation. We found that k-means on the \\ndigits  dataset,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 47}),\n",
              " Document(page_content=\"taken as is, didn't deliver exceptional results. This was due to class overlap that we spotted through PCA. We overcame this weakness by applying PCA as a preprocess to improve our subsequent clustering results.\\nFinally, we developed an SOM algorithm that delivered a cleaner separation of the \\ndigit  classes than PCA.\\nHaving learned some key basics around unsupervised learning techniques and \\nanalytical methodology, let's dive into the use of some more powerful unsupervised \\nlearning algorithms.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 47}),\n",
              " Document(page_content='[ 27 ]Deep Belief Networks\\nIn the preceding chapter, we looked at some widely-used dimensionality reduction \\ntechniques, which enable a data scientist to get greater insight into the nature  \\nof datasets.\\nThe next few chapters will focus on some more sophisticated techniques, \\ndrawing from the area of deep learning. This chapter is dedicated to building an understanding of how to apply the Restricted Boltzmann Machine  (RBM) and \\nmanage the deep learning architecture one can create by chaining RBMs—the deep \\nbelief network (DBN). DBNs are trainable to effectively solve complex problems in text, image, and sound recognition. They are used by leading companies for object recognition, intelligent image search, and robotic spatial recognition.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 49}),\n",
              " Document(page_content=\"The first thing that we're going to do is get a solid grounding in the algorithm \\nunderlying DBN; unlike clustering or PCA, this code isn't widely-known by data \\nscientists and we're going to review it in some depth to build a strong working \\nknowledge. Once we've worked through the theory, we'll build upon it by stepping through code that brings the theory into focus and allows us to apply the technique to real-world data. The diagnosis of these techniques is not trivial and needs to be \\nrigorous, so we'll emphasize the thought processes and diagnostic techniques that \\nenable us to effectively watch and control the success of your implementation.\\nBy the end of this chapter, you'll understand how the RBM and DBN algorithms\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 49}),\n",
              " Document(page_content='work, know how to use them, and feel confident in your ability to improve the quality of the results you get out of them. To summarize, the contents of this  chapter are as follows:\\n• Neural networks – a primer\\n• Restricted Boltzmann Machines\\n• Deep belief networks', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 49}),\n",
              " Document(page_content=\"Deep Belief Networks[ 28 ]Neural networks – a primer\\nThe RBM is a form of recurrent neural network. In order to understand how the RBM \\nworks, it is necessary to have a more general understanding of neural networks. Readers with an understanding of artificial neural network (hereafter neural network, for the sake of simplicity) algorithms will find familiar elements in the following description.\\nThere are many accounts that cover neural networks in great theoretical detail; we \\nwon't go into great detail retreading this ground. For the purposes of this chapter, we will first describe the components of a neural network, common architectures, and prevalent learning processes.\\nThe composition of a neural network\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 50}),\n",
              " Document(page_content='For unfamiliar readers, neural networks are a class of mathematical models that train to produce and optimize a definition for a function (or distribution) over a set of input features. The specific objective of a given neural network application can be defined by the operator using a performance measure (typically a cost function); in this way, neural networks may be used to classify, predict, or transform their inputs.\\nThe use of the word neural in neural networks is the product of a long tradition \\nof drawing from heavy-handed biological metaphors to inspire machine learning research. Hence, artificial neural networks algorithms originally drew (and frequently still draw) from biological neuronal structures.\\nA neural network is composed of the following elements:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 50}),\n",
              " Document(page_content='• A learning process: A neural network learns by adjusting parameters \\nwithin the weight function of its nodes. This occurs by feeding the output \\nof a performance measure (as described previously, in supervised learning contexts this is frequently a cost function, some measure of inaccuracy relative to the target output of the network) into the learning function of the network. This learning function outputs the required weight adjustments (Technically, it typically calculates the partial derivatives—terms required by gradient descent.) to minimize the cost function.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 50}),\n",
              " Document(page_content='Chapter 2[ 29 ]• A set of neurons or weights: Each contains a weight function (the activation \\nfunction) that manipulates input data. The activation function may vary substantially between networks (with one well-known example being the hyperbolic tangent). The key requirement is that the weights must be adaptive, that is,, adjustable based on updates from the learning process. In order to model non-parametrically (that is, to model effectively without defining details of the probability distribution), it is necessary to use both visible and hidden units. Hidden units are never observed.\\n• Connectivity functions: They control which nodes can relay data to which other nodes. Nodes may be able to freely relay input to one another in an', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 51}),\n",
              " Document(page_content=\"unrestricted or restricted fashion, or they may be more structured in layers through which input data must flow in a directed fashion. There is a broad range of interconnection patterns, with different patterns producing very different network properties and possibilities.\\nUtilizing this set of elements enables us to build a broad range of neural networks, \\nranging from the familiar directed acyclic graph (with perhaps the best-known \\nexample being the Multi-Layer Perceptron (MLP)) to creative alternatives. The  \\nSelf-Organizing Map (SOM) that we employed in the preceding chapter was a type of neural network, with a unique learning process. The algorithm that we'll examine \\nlater in this chapter, that of the RBM, is another neural network algorithm with some \\nunique properties.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 51}),\n",
              " Document(page_content=\"Network topologies\\nThere are many variations on how the neurons in a neural network are connected, with structural decisions being an important factor in determining the network's learning capabilities. Common topologies in unsupervised learning tend to differ from those common to supervised learning. One common and now familiar unsupervised learning topology is that of the SOM that we discussed in the last chapter.\\nThe SOM, as we saw, directly projects individual input cases onto a weight vector\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 51}),\n",
              " Document(page_content='contained by each node. It then proceeds to reorder these nodes until an appropriate mapping of the dataset is converged on. The actual structure of the SOM was a variant based on the details of training, specific outcome of a given instance of training, and design decisions taken in structuring the network, but square or hexagonal grid structures are becoming increasingly common.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 51}),\n",
              " Document(page_content='Deep Belief Networks[ 30 ]A very common topology type in supervised learning is that of a three-layer, \\nfeedforward network, with the classical case being the MLP. In this network topology model, the neurons in the network are split into layers, with each layer communicating to the layer \"beyond\" it. The first layer contains inputs that are fed to a hidden layer. The hidden layer develops a representation of the data using weight activations (with the right activation function, for example, sigmoid or gauss, an MLP can act as a universal function approximator) and activation values are communicated to the output layer. The output layer typically delivers network results. This topology, therefore, looks as follows:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 52}),\n",
              " Document(page_content='Chapter 2[ 31 ]Other network topologies deliver different capabilities. The topology of a Boltzmann \\nMachine, for instance, differs from those described previously. The Boltzmann machine contains hidden and visible neurons, like those of a three-layer network, but all of these neurons are connected to one another in a directed, cyclic graph:\\nThis topology makes Boltzmann machines stochastic—probabilistic rather than deterministic—and able to develop in one of several ways given a sufficiently complex problem. The Boltzmann machine is also generative, which means that it is able to fully (probabilistically) model all of the input variables, rather than using the observed variables to specifically model the target variables.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 53}),\n",
              " Document(page_content='Which network topology is appropriate depends to a large extent on your \\nspecific challenge and the desired output. Each tends to be strong in certain areas. Furthermore, each of the topologies described here will be accompanied by a \\nlearning process that enables the network to iteratively converge on an (ideally \\noptimal) solution.\\nThere are a broad range of learning processes, with specific processes and topologies \\nbeing more or less compatible with one another. The purpose of a learning process is to enable the network to adjust its weights, iteratively, in such a way as to create an increasingly accurate representation of the input data.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 53}),\n",
              " Document(page_content=\"Deep Belief Networks[ 32 ]As with network topologies, there are a great many learning processes to consider. \\nSome familiarity is assumed and a great many excellent resources on learning processes exist (some good examples are given at the end of this chapter). This section will focus on delivering a common characterization of learning processes, while later in the chapter, we'll look in greater detail at a specific example.\\nAs noted, the objective of learning in a neural network is to iteratively improve \\nthe distribution of weights across the model so that it approximates the function \\nunderlying input data with increasing accuracy. This process requires a performance \\nmeasure. This may be a classification error measure, as is commonly used in\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 54}),\n",
              " Document(page_content='supervised, classification contexts (that is, with the backpropagation learning algorithm in MLP networks). In stochastic networks, it may be a probability maximization term (such as energy in energy-based networks).\\nIn either case, once there is a measure to increase probability, the network is \\neffectively attempting to reduce that measure using an optimization method. In \\nmany cases, the optimization of the network is achieved using gradient descent . \\nAs far as the gradient descent algorithm method is concerned, the size of your \\nperformance measure value on a given training iteration is analogous to the slope of your gradient. Minimizing the performance measure is therefore a question of \\ndescending that gradient to the point at which the error measure is at its lowest for', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 54}),\n",
              " Document(page_content=\"that set of weights.\\nThe size of the network's updates for the next iteration (the learning rate of your \\nalgorithm) may be influenced by the magnitude of your performance measure, or it may be hard-coded.\\nThe weight updates by which your network adjusts may be derived from the error \\nsurface itself; if so, your network will typically have a means of calculating the gradient, that is, deriving the values to which updates need to adjust the parameters on your network's activated weight functions so as to continue to reduce the performance measure.\\nHaving reviewed the general concepts underlying network topologies and learning \\nmethods, let's move into the discussion of a specific neural network, the RBM. As we'll see, the RBM is a key part of a powerful deep learning algorithm.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 54}),\n",
              " Document(page_content=\"Chapter 2[ 33 ]Restricted Boltzmann Machine\\nThe RBM is a fundamental part of this chapter's subject deep learning architecture—\\nthe DBN. The following sections will begin by introducing the theory behind an RBM, including the architectural structure and learning processes.\\nFollowing that, we'll dive straight into the code for an RBM class, making links \\nbetween the theoretical elements and functions in code. We'll finish by touching  on the applications of RBMs and the practical factors associated with implementing an RBM.\\nIntroducing the RBM\\nA Boltzmann machine is a particular type of stochastic, recurrent neural network. It is an energy-based model, which means that it uses an energy function to associate an energy value with each configuration of the network.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 55}),\n",
              " Document(page_content=\"We briefly discussed the structure of a Boltzmann machine in the previous section. \\nAs mentioned, a Boltzmann machine is a directed cyclic graph, where every node is connected to all other nodes. This property enables it to model in a recurrent fashion, such that the model's outputs evolve and can be viewed over time.\\nThe learning loop in a Boltzmann machine involves maximizing the probability of \\nthe training dataset, X. As noted, the specific performance measure used is energy, \\nwhich is characterized as the negative log of the probability for a dataset X, given a \\nvector of model parameters, Θ. This measure is calculated and used to update the \\nnetwork's weights in such a way as to minimize the free energy in the network.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 55}),\n",
              " Document(page_content=\"The Boltzmann machine has seen particular success in processing image data, \\nincluding photographs, facial features, and handwriting classification contexts.\\nUnfortunately, the Boltzmann machine is not practical for more challenging ML \\nproblems. This is due to the fact that there are challenges with the machine's ability to scale; as the number of nodes increases, the compute time grows exponentially, eventually leaving us in a position where we're unable to compute the free energy of the network.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 55}),\n",
              " Document(page_content='Deep Belief Networks[ 34 ]For those with an interest in the underlying formal reasoning, this \\nhappens because the probability of a data point, x, p(x; Θ), must \\nintegrate to 1 over all x. Achieving this requires that we use a partition \\nfunction, Z, used as a normalizing constant. ( Z is a constant such that \\nmultiplying a non-negative function by Z will make the non-negative \\nfunction integrate to 1 over all inputs; in this case, over all x.)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 56}),\n",
              " Document(page_content=\"The probability model function is a function of a set of normal distributions. In order to get the energy for our model, we need to differentiate for each of the model's parameters; however, this becomes complicated because of the partition function. Each model parameter produces equations dependent on other model parameters and we ultimately find ourselves unable to calculate the energy without (potentially) hugely expensive calculations, whose cost increases as the network scales.\\nIn order to overcome the weaknesses of the Boltzmann machine, it is necessary to \\nmake adjustments to both the network topology and training process.\\nTopology\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 56}),\n",
              " Document(page_content='The main topological change that delivers efficiency improvements is the restriction of connectivity between nodes. First, one must prevent connection between nodes within the same layer. Additionally, all skip-layer connections (that is, direct connections between non-consecutive layers) must be prevented. A Boltzmann machine with this architecture is referred to as an RBM and appears as shown in the following diagram:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 56}),\n",
              " Document(page_content=\"Chapter 2[ 35 ]One advantage of this topology is that the hidden and visible layers are conditionally \\nindependent given one another. As such, it is possible to sample from one layer using the activations of the other.\\nTraining\\nWe observed previously that, for Boltzmann machines, the training time of the machine scales extremely poorly as the machine is scaled up to additional nodes, \\nputting us in a position where we cannot evaluate the energy function that we're attempting to use in training.\\nThe RBM is typically trained using a procedure with a different learning algorithm at \\nits heart, the Permanent Contrastive Divergence ( PCD) algorithm, which provides\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 57}),\n",
              " Document(page_content=\"an approximation of maximum likelihood. PCD doesn't evaluate the energy function itself, but instead allows us to estimate the gradient of the energy function. With this \\ninformation, we can proceed by making very small adjustments in the direction of the \\nsteepest gradient via which we may progress, as desired, toward the local minimum.\\nThe PCD algorithm is made up of two phases. These are referred to as the positive\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 57}),\n",
              " Document(page_content='and negative phases, and each phase has a corresponding effect on the energy  of the model. The positive phase increases the probability of the training dataset, X, thus reducing the energy of the model. Following this, the negative phase uses a sampling approach from the model to estimate the negative phase gradient. The overall effect of the negative phase is to decrease the probability of samples generated by the model.\\nSampling in the negative phase and throughout the update process is achieved using \\na form of sampling called Gibbs sampling .', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 57}),\n",
              " Document(page_content='Deep Belief Networks[ 36 ]Gibbs sampling is a variant of the Markov Chain Monte Carlo  (MCMC) \\nfamily of algorithms, and samples from an approximated multivariate \\nprobability distribution. What this means is, rather than using a summed calculation in building our probabilistic model (just as we might do, for instance, when we flip a coin a certain number of times; in such cases, we may sum the number of heads attempts as a proportion of the sum of all attempts), we approximate the value of an integral instead. The subject of how to create a probabilistic model by approximating an integral deserves more time than this book can give it. As such the Further reading', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 58}),\n",
              " Document(page_content='section of this chapter provides an excellent paper reference. The key points to bear in mind for now (and stripping out a lot of important detail!) are that, instead of summing each case exactly once, we sample based on the (often non-uniform) distribution of the data in question. Gibbs sampling is a probabilistic sampling method for each parameter in a model, based on all of the other parameter values in that model. As soon as a new parameter value is obtained, it is immediately used in sampling calculations for other parameters.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 58}),\n",
              " Document(page_content=\"Some of you may be asking at this point why PCD is necessary. Why not use a more familiar method, such as gradient descent with line search? To put it simply, we cannot easily calculate the free energy of our network as this calculation involves an integration across all the network's nodes. We recognized this limitation when we called out the big weakness of the Boltzmann machine—that the compute time grows exponentially as the number of nodes increases, leaving us in a situation where we're trying to minimize a function whose value we cannot calculate!\\nWhat PCD provides is a way to estimate the gradient of the energy function. This \\nenables an approximation of the network's free energy, which is fast enough to be\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 58}),\n",
              " Document(page_content=\"viable for application and has shown to be generally accurate. (Refer to the Further \\nreading section for a performance comparison.)\\nAs we saw previously, the RBM's probability model function is the joint distribution \\nof our model parameters, making Gibbs sampling appropriate!\\nThe training loop in an initialized RBM involves several steps:\\n1. We obtain the current iteration's activated hidden layer weight values.\\n2. We perform the positive phase of PCD, using the state of the Gibbs chain \\nfrom the previous iteration as input.\\n3. We perform the negative phase of PCD using the pre-existing state of the \\nGibbs chain. This gives us the free energy value.\\n4. We update the activated weights on the hidden layer using the energy value we've calculated.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 58}),\n",
              " Document(page_content=\"Chapter 2[ 37 ]This algorithm allows the RBM to iteratively step toward a decreased free  \\nenergy value. The RBM continues to train until both the probability of the training \\ndataset integrates to one and free energy is equal to zero, at which point the RBM  \\nhas converged.\\nNow that we've had a chance to review the RBM's topology and training process, \\nlet's apply the algorithm to classify a substantial real dataset.\\nApplications of the RBM\\nNow that we have a general working knowledge of the RBM algorithm, let's walk through code to create an RBM. We'll be working with an RBM class that will allow us to classify the MNIST handwritten digits dataset. The code we're about to review does the following:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 59}),\n",
              " Document(page_content='• It sets up the initial parameters of an RBM, including layer size, shareable bias vectors, and shareable weight matrix for connectivity with external network structures (this enables deep belief networks)\\n• It defines functions for communication and inference between hidden and visible layers\\n• It defines functions that allow us to update the parameters of network nodes\\n• It defines functions that handle efficient sampling for the learning process, using PCD-k to accelerate sampling (making it possible to compute in a reasonable frame of time)\\n• It defines functions that compute the free energy of the model (used to calculate the gradient required for PCD-k updates)\\n• It identifies the Psuedo-Likelihood  (PL), usable as a log-likelihood proxy to', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 59}),\n",
              " Document(page_content=\"guide the selection of appropriate hyperparameters\\nLet's begin examining our \\nRBM class:\\nclass RBM(object):\\n    def __init__(        self,        input=None,        n_visible=784,        n_hidden=500,        w=None,        hbias=None,        vbias=None,        numpy_rng=None,        theano_rng=None    ):\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 59}),\n",
              " Document(page_content=\"Deep Belief Networks[ 38 ]The first element that we need to build is an RBM constructor, which we can use to \\ndefine the parameters of the model, such as the number of visible and hidden nodes \\n(n_visible  and n_hidden ) as well as additional parameters that can be used to \\nadjust how the RBM's inference functions and CD updates are performed.\\nThe w parameter can be used as a pointer to a shared weight matrix. This becomes \\nmore relevant when implementing a DBN, as we'll see later in the chapter; in such \\narchitectures, the weight matrix needs to be shared between different parts of  \\nthe network.\\nThe hbias  and vbias  parameters are used similarly as optional references to shared \\nhidden and visible (respectively) units' bias vectors. Again, these are used in DBNs.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 60}),\n",
              " Document(page_content=\"The input  parameter enables the RBM to be connected, top-to-tail, to other graph \\nelements. This allows one to, for instance, chain RBMs.\\nHaving set up this constructor, we next need to flesh out each of the preceding \\nparameters:\\n        self.n_visible = n_visible\\n        self.n_hidden = n_hidden\\n        if numpy_rng is None:\\n            numpy_rng = numpy.random.RandomState(1234)\\n        if theano_rng is None:\\n            theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\\nThis is fairly straightforward stuff; we set the visible and hidden nodes for our RBM \\nand set up two random number generators. The theano_rng  parameter will be used \\nlater in our code to sample from the RBM's hidden units:\\n        if W is None:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 60}),\n",
              " Document(page_content='initial_W = numpy.asarray(                numpy_rng.uniform(                    low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),                    high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),                    size=(n_visible, n_hidden)                ),                dtype=theano.config.floatX            )', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 60}),\n",
              " Document(page_content=\"Chapter 2[ 39 ]This code switches up the data type for W so that it can be run over the GPU. Next, \\nwe set up shared variables using theano.shared , which allows a variable's storage \\nto be shared between functions that it appears in. Within the current example, the \\nshared variables that we create will be the weight vector ( W) and bias variables for \\nhidden and visible units ( hbias  and vbias , respectively). When we move on to \\ncreating deep networks with multiple components, the following code will allow us to share components between parts of our networks:\\n            W = theano.shared(value=initial_W, name='W', borrow=True)\\n        if hbias is None:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 61}),\n",
              " Document(page_content=\"hbias = theano.shared(                value=numpy.zeros(                    n_hidden,                    dtype=theano.config.floatX                ),                name='hbias',                borrow=True            )\\n        if vbias is None:\\n            vbias = theano.shared(                value=numpy.zeros(                    n_visible,                    dtype=theano.config.floatX                ),                name='vbias',                borrow=True            )\\nAt this point, we're ready to initialize the input layer as follows:\\n        self.input = input        if not input:            self.input = T.matrix('input')\\n        self.W = W\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 61}),\n",
              " Document(page_content='self.hbias = hbias        self.vbias = vbias        self.theano_rng = theano_rng        self.params = [self.W, self.hbias, self.vbias]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 61}),\n",
              " Document(page_content='Deep Belief Networks[ 40 ]As we now have an initialized input  layer, our next task is to create the symbolic \\ngraph that we described earlier in the chapter. Achieving this is a matter of creating \\nfunctions to manage the interlayer propagation and activation computation operations of the network:\\ndef propup(self, vis):\\n        pre_sigmoid_activation = T.dot(vis, self.W) + self.hbias        return [pre_sigmoid_activation, T.nnet.sigmoid(pre_sigmoid_\\nactivation)]\\n    def propdown(self, hid):\\n        pre_sigmoid_activation = T.dot(hid, self.W.T) + self.vbias        return [pre_sigmoid_activation, T.nnet.sigmoid(pre_sigmoid_\\nactivation)]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 62}),\n",
              " Document(page_content=\"These two functions pass the activation of one layer's units to the other layer. The first function passes the visible units' activation upward to the hidden units so that the hidden units can compute their activation conditional on a sample of the visible units. The second function does the reverse—propagating the hidden layer's activation downward to the visible units.\\nIt's probably worth asking why we're creating both \\npropup  and propdown . As we \\nreviewed it, PCD only requires that we perform sampling from the hidden units. So \\nwhat's the value of propup ?\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 62}),\n",
              " Document(page_content='In a nutshell, sampling from the visible layer becomes useful when we want to sample from the RBM to review its progress. In most applications where our RBM is processing visual data, it is immediately valuable to periodically take the output of sampling from the visible layer and plot it, as shown in the following example:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 62}),\n",
              " Document(page_content=\"Chapter 2[ 41 ]As we can see here, over the course of iteration, our network begins to change its \\nlabeling; in the first case, 7 morphs into 9, while elsewhere 9 becomes 6 and the \\nnetwork gradually reaches a definition of 3-ness.\\nAs we discussed earlier, it's helpful to have as many views on the operation of your \\nRBM as possible to ensure that it's delivering meaningful results. Sampling from the outputs it generates is one way to improve this visibility.\\nArmed with information about the visible layer's activation, we can deliver a  \\nsample of the unit activations from the hidden layer, given the activation of the \\nhidden nodes:\\n    def sample_h_given_v(self, v0_sample):\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 63}),\n",
              " Document(page_content=\"pre_sigmoid_h1, h1_mean = self.propup(v0_sample)    h1_sample = self.theano_rng.binomial(size=h1_mean.shape,    n=1, p=h1_mean, dtype=theano.config.floatX)\\n    return [pre_sigmoid_h1, h1_mean, h1_sample]\\nLikewise, we can now sample from the visible layer given hidden unit activation \\ninformation:\\n    def sample_v_given_h(self, h0_sample):\\n    pre_sigmoid_v1, v1_mean = self.propdown(h0_sample)      v1_sample = self.theano_rng.binomial(size=v1_mean.shape,      n=1, p=v1_mean, dtype=theano.config.floatX)\\n      return [pre_sigmoid_v1, v1_mean, v1_sample]\\nWe've now achieved the connectivity and update loop required to perform a Gibbs \\nsampling step, as described earlier in this chapter. Next, we should define this sampling step!\\n    def gibbs_hvh(self, h0_sample):\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 63}),\n",
              " Document(page_content='pre_sigmoid_v1, v1_mean, v1_sample =         self.sample_v_given_h(h0_sample)        pre_sigmoid_h1, h1_mean, h1_sample =         self.sample_h_given_v(v1_sample)        return [pre_sigmoid_v1, v1_mean, v1_sample,                pre_sigmoid_h1, h1_mean, h1_sample]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 63}),\n",
              " Document(page_content=\"Deep Belief Networks[ 42 ]As discussed, we need a similar function to sample from the visible layer:\\n    def gibbs_vhv(self, v0_sample):\\n                pre_sigmoid_h1, h1_mean, h1_sample =         self.sample_h_given_v(v0_sample)        pre_sigmoid_v1, v1_mean, v1_sample =         self.sample_v_given_h(h1_sample)        return [pre_sigmoid_h1, h1_mean, h1_sample,                pre_sigmoid_v1, v1_mean, v1_sample]\\nThe code that we've written so far gives us some of our model. It set up the nodes \\nand layers and connections between layers. We've written the code that we need in order to update the network based on Gibbs sampling from the hidden layer.\\nWhat we're still missing is code that allows us to perform the following:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 64}),\n",
              " Document(page_content=\"• Compute the free energy of the model. As we discussed, the model uses \\nenergy as the term to do the following:\\n °Implement PCD using our Gibbs sampling step code, and setting the \\nGibbs step count parameter, k = 1, to compute the parameter gradient \\nfor gradient descent\\n °Create a means to feed the output of PCD (the computed gradient) to our previously defined network update code\\n• Develop the means to track the progress and success of our RBM throughout the training.\\nFirst off, we'll create the means to calculate the free energy of our RBM. Note that this is the inverse log of the probability distribution for the hidden layer, which we discussed earlier:\\n  def free_energy(self, v_sample):\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 64}),\n",
              " Document(page_content=\"wx_b = T.dot(v_sample, self.W) + self.hbias        vbias_term = T.dot(v_sample, self.vbias)        hidden_term = T.sum(T.log(1 + T.exp(wx_b)), axis=1)        return -hidden_term - vbias_term\\nNext, we'll implement PCD. At this point, we'll be setting a couple of interesting \\nparameters. The lr, short for learning rate, is an adjustable parameter used to adjust \\nlearning speed. The k parameter points to the number of steps to be performed by \\nPCD (remember the PCD-k notation from earlier in the chapter?).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 64}),\n",
              " Document(page_content=\"Chapter 2[ 43 ]We discussed the PCD as containing two phases, positive and negative. The \\nfollowing code computes the positive phase of PCD:\\ndef get_cost_updates(self, lr=0.1, persistent = , k=1):\\n        pre_sigmoid_ph, ph_mean, ph_sample =  \\n        self.sample_h_given_v(self.input)\\n        \\n                   chain_start = persistent\\nMeanwhile, the following code implements the negative phase of PCD. To do so, we \\nscan the gibbs_hvh  function k times, using Theano's scan operation, performing one \\nGibbs sampling step with each scan. After completing the negative phase, we acquire the free energy value:\\n        (\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 65}),\n",
              " Document(page_content='[                pre_sigmoid_nvs,                nv_means,                nv_samples,                pre_sigmoid_nhs,                nh_means,                nh_samples            ],            updates        ) = theano.scan(            self.gibbs_hvh,            outputs_info=[None, None, None, None, None, chain_start],            n_steps=k        )\\n        chain_end = nv_samples[-1]\\n        cost = T.mean(self.free_energy(self.input)) - T.mean(\\n            self.free_energy(chain_end))\\n        gparams = T.grad(cost, self.params, \\n        consider_constant=[chain_end])', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 65}),\n",
              " Document(page_content=\"Deep Belief Networks[ 44 ]Having written code that performs the full PCD process, we need a way to feed the \\noutputs to our network. At this point, we're able to connect our PCD learning process to the code to update the network that we reviewed earlier. The preceding updates dictionary points to \\ntheano.scan  of the gibbs_hvh  function. As you may recall, \\ngibbs_hvh  currently contains rules for random states of theano_rng . What we need \\nto do now is add the new parameter values and variable containing the state of the Gibbs chain to the dictionary (the \\nupdates  variable):\\n        for gparam, param in zip(gparams, self.params):\\n            updates[param] = param - gparam * T.cast(\\n                lr,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 66}),\n",
              " Document(page_content=\"dtype=theano.config.floatX            )                    updates = nh_samples[-1]            monitoring_cost =              self.get_pseudo_likelihood_cost(updates)        \\n        return monitoring_cost, updates\\nWe now have almost all the parts that we need to make our RBM work. What's \\nclearly missing is a means to inspect training, either during or after completion,  to ensure that our RBM is learning an appropriate representation of the data.\\nWe talked previously about how to train an RBM, specifically about challenges \\nposed by the partition function. Furthermore, earlier in the code, we implemented \\none means by which we can inspect an RBM during training; we created the  \\ngibbs_vhv  function to perform Gibbs sampling from the model.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 66}),\n",
              " Document(page_content=\"In our previous discussion around how to validate an RBM, we discussed visually plotting the filters that the RBM has created. We'll review how this can be achieved shortly.\\nThe final possibility is to use the inverse log of the PL as a more tractable proxy to \\nthe likelihood itself. Technically, the log-PL is the sum of the log-probabilities of each data point (each \\nx) conditioned on all other data points. As discussed, this becomes \\ntoo expensive with larger-dimensional datasets, so a stochastic approximation to  \\nlog-PL is used.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 66}),\n",
              " Document(page_content=\"Chapter 2[ 45 ]We referenced a function that will enable us to get PL cost during the get_cost_\\nupdates  function, specifically the get_pseudo_likelihood_cost  function. Now it's \\ntime to flesh out this function and obtain the pseudo-likelihood:\\ndef get_pseudo_likelihood_cost(self, updates):\\n        bit_i_idx = theano.shared(value=0, name='bit_i_idx')\\n        xi = T.round(self.input)\\n        fe_xi = self.free_energy(xi)        xi_flip = T.set_subtensor(xi[:, bit_i_idx], 1 - xi[:, \\n        bit_i_idx])\\n        fe_xi_flip = self.free_energy(xi_flip)        cost = T.mean(self.n_visible * \\n        T.log(T.nnet.sigmoid(fe_xi_flip - fe_xi)))\\n        \\n        updates[bit_i_idx] = (bit_i_idx + 1) % self.n_visible\\n        return cost\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 67}),\n",
              " Document(page_content=\"We've now filled out each element on the list of missing components and have \\ncompletely reviewed the RBM class. We've explored how each element ties into the \\ntheory behind the RBM and should now have a thorough understanding of how the RBM algorithm works. We understand what the outputs of our RBM will be and will soon be able to review and assess them. In short, we're ready to train our RBM. Beginning the training of the RBM is a matter of running the following code, which triggers the \\ntrain_set_x  function. We'll discuss this function in greater depth later \\nin this chapter:\\n    train_rbm = theano.function(\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 67}),\n",
              " Document(page_content=\"[index],        cost,        updates=updates,        givens={            x: train_set_x[index * batch_size: (index + 1) *             batch_size]        },        name='train_rbm'    )\\n    plotting_time = 0.\\n    start_time = time.clock()\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 67}),\n",
              " Document(page_content=\"Deep Belief Networks[ 46 ]Having updated the RBM's updates and training set, we run through training \\nepochs. Within each epoch, we train over the training data before plotting the weights as a matrix (as described earlier in the chapter):\\n    for epoch in xrange(training_epochs):\\n        mean_cost = []\\n        for batch_index in xrange(n_train_batches):            mean_cost += [train_rbm(batch_index)]\\n        print 'Training epoch %d, cost is ' % epoch, \\n        numpy.mean(mean_cost)\\n        plotting_start = time.clock()\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 68}),\n",
              " Document(page_content=\"image = Image.fromarray(            tile_raster_images(                X=rbm.W.get_value(borrow=True).T,                img_shape=(28, 28),                tile_shape=(10, 10),                tile_spacing=(1, 1)            )        )        image.save('filters_at_epoch_%i.png' % epoch)        plotting_stop = time.clock()        plotting_time += (plotting_stop - plotting_start)\\n    end_time = time.clock()    pretraining_time = (end_time - start_time) - plotting_time    print ('Training took %f minutes' % (pretraining_time / 60.))\\nThe weights tend to plot fairly recognizably and resemble Gabor filters (linear\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 68}),\n",
              " Document(page_content='filters commonly used for edge detection in images). If your dataset is handwritten characters on a fairly low-noise background, you tend to find that the weights trace the strokes used. For photographs, the filters will approximately trace edges in the image. The following image shows an example output:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 68}),\n",
              " Document(page_content='Chapter 2[ 47 ]\\nFinally, we create the persistent Gibbs chains that we need to derive our samples. \\nThe following function performs a single Gibbs step, as discussed previously, then updates the chain:\\nplot_every = 1000\\n    (\\n        [            presig_hids,            hid_mfs,            hid_samples,            presig_vis,            vis_mfs,            vis_samples        ],        updates    ) = theano.scan(        rbm.gibbs_vhv,        outputs_info=[None, None, None, None, None, persistent_vis_\\nchain],\\n        n_steps=plot_every    )', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 69}),\n",
              " Document(page_content=\"Deep Belief Networks[ 48 ]This code runs the gibbs_vhv  function we described previously, plotting network \\noutput samples for our inspection:\\n    updates.update({persistent_vis_chain: vis_samples[-1]})\\n    sample_fn = theano.function(\\n        [],\\n        [            vis_mfs[-1],            vis_samples[-1]        ],        updates=updates,        name='sample_fn'    )\\n    image_data = numpy.zeros(\\n        (29 * n_samples + 1, 29 * n_chains - 1),        dtype='uint8'    )    for idx in xrange(n_samples):                vis_mf, vis_sample = sample_fn()        print ' ... plotting sample ', idx        image_data[29 * idx:29 * idx + 28, :] = tile_raster_images(            X=vis_mf,            img_shape=(28, 28),            tile_shape=(1, n_chains),            tile_spacing=(1, 1)        )\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 70}),\n",
              " Document(page_content=\"image = Image.fromarray(image_data)\\n    image.save('samples.png')\\nAt this point, we have an entire RBM. We have the PCD algorithm and the ability \\nto update the network using this algorithm and Gibbs sampling. We have several visible output methods so that we can assess how well our RBM has trained.\\nHowever, we're not done yet! Next, we'll begin to see what the most frequent and \\npowerful application of the RBM is.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 70}),\n",
              " Document(page_content=\"Chapter 2[ 49 ]Further applications of the RBM\\nWe can use the RBM as an ML algorithm in and of itself. It functions comparably \\nwell with other algorithms. Advantageously, it can be scaled up to a point where it \\ncan learn high-dimensional datasets. However, this isn't where the real strength of the RBM lies.\\nThe RBM is most commonly used as a pretraining mechanism for a highly effective \\ndeep network architecture called a DBN. DBNs are extremely powerful tools to learn and classify a range of image datasets. They possess a very good ability to generalize to unknown cases and are among the best image-learning tools available. For this reason, DBNs are in use at many of the world's top tech and data science companies, primarily in image search and recognition contexts.\\nDeep belief networks\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 71}),\n",
              " Document(page_content='A DBN is a graphical model, constructed using multiple stacked RBMs. While the first RBM trains a layer of features based on input from the pixels of the training data, subsequent layers treat the activations of preceding layers as if they were pixels and attempt to learn the features in subsequent hidden layers. This is frequently described as learning the representation of data and is a common theme in deep learning.\\nHow many multiple RBMs there should be depends on what is needed for the', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 71}),\n",
              " Document(page_content=\"problem at hand. From a practical perspective, it's a trade-off between increasing accuracy and increasing computational cost. It is the case that each layer of RBMs will improve the lower bound of the log probability of the training data. In other words; the DBN almost inevitably becomes less bad with each additional layer  \\nof features.\\nAs far as layer size is concerned, it is generally advantageous to reduce the number \\nof nodes in the hidden layers of successive RBMs. One should avoid contexts in \\nwhich an RBM has at least as many visible units as the RBM preceding it has hidden \\nunits (which raises the risk of simply learning the identity function of the network).\\nIt can be advantageous (but is by no means necessary) when successive RBMs\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 71}),\n",
              " Document(page_content=\"decrease in layer size until the final RBM has a layer size approximating the dimensionality of variance in the data. Affixing an MLP to the end of a DBN whose layers have too many nodes will harm classification performance; it's like trying to affix a drinking straw to the end of a hosepipe! Even an MLP with many neurons may not successfully  train in such contexts. On a related note, it has been noted that \\neven if the layers don't contain very many nodes, with enough layers, more or less any function can be modeled.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 71}),\n",
              " Document(page_content='Deep Belief Networks[ 50 ]Determining what the dimensionality of variance in the data is, is not a simple task. \\nOne tool that can support this task is PCA; as we saw in the preceding chapter, PCA can enable us to get a reasonable idea as to how many components of meaningful size exist in the input data.\\nTraining a DBN\\nTraining a DBN is typically done greedily, which is to say that it trains to optimize locally at each layer, rather than attempting to reach a global optimum. The learning process is as follows:\\n• The first layer of the DBN is trained using the method that we saw in  our earlier discussion of RBM learning. As such, the first layer converts its data distribution to a posterior distribution using Gibbs sampling over the hidden units.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 72}),\n",
              " Document(page_content=\"• This distribution is far more conducive for RBM training than the input data itself so the next RBM layer learns that distribution!\\n• Successive RBM layers continue to train on the samples output by  preceding layers.\\n• All of the parameters within this architecture are tuned using a  \\nperformance measure.\\nThis performance measure may vary. It may be a log-likelihood proxy used in \\ngradient descent, as discussed earlier in the chapter. In supervised contexts, a classifier (for example, an MLP) can be added as the final layer of the architecture and prediction accuracy can be used as the performance measure to fine-tune the deep architecture.\\nLet's move on to using the DBN in practice.\\nApplying the DBN\\nHaving discussed the DBN and theory surrounding it, it's time to set up our own.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 72}),\n",
              " Document(page_content=\"We'll be working in a similar way to the RBM, by walking through a DBN class and \\nconnecting the code to the theory, discussing what to expect and how to review  \\nthe network's performance, before initializing and training our network to see  \\nit in action.\\nLet's take a look at our DBN class:\\nclass DBN(object):\\n    def __init__(self, numpy_rng, theano_rng=None, n_ins=784,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 72}),\n",
              " Document(page_content=\"Chapter 2[ 51 ]                 hidden_layers_sizes=[500, 500], n_outs=10):\\n               self.sigmoid_layers = []        self.rbm_layers = []        self.params = []        self.n_layers = len(hidden_layers_sizes)\\n        assert self.n_layers > 0        if not theano_rng:\\n            theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\\n       \\n        self.x = T.matrix('x')        self.y = T.ivector('y')\\nThe DBN class contains a number of parameters that bear further explanation. The \\nnumpy_rng  and theano_rng  parameters, used to determine initial weights, are \\nalready familiar from our examination of the RBM class. The n_ins  parameter is a \\npointer to the dimension (in features) of the DBN's input. The hidden_layers_\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 73}),\n",
              " Document(page_content=\"sizes  parameter is a list of hidden layer sizes. Each value in this list will guide \\nthe DBN constructor in creating an RBM layer of the relevant size; as you'll note, \\nthe n_layers  parameter refers to the number of layers in the network and is set by \\nhidden_layers_sizes . Adjustment of values in this list enables us to make DBNs \\nwhose layer sizes taper down from the input layer size, to increasingly succinct \\nrepresentations, as discussed earlier in the chapter.\\nIt's also worth noting that self.sigmoid_layers  will store the MLP component \\n(the final layer of the DBN), while self.rbm_layers  stores the RBM layers used to \\npretrain the MLP.With this done, we do the following to complete our DBN architecture:\\n• We create \\nn_layers  sigmoid layers\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 73}),\n",
              " Document(page_content='• We connect the sigmoid layers to form an MLP\\n• We construct an RBM for each sigmoid layer with a shared weight matrix \\nand hidden bias between each sigmoid layer and RBM\\nThe following code creates n_layers  many layers with sigmoid activations; first \\ncreating the input layer, then creating hidden layers whose size corresponds to the values in our \\nhidden_layers_sizes  list:\\n       for i in xrange(self.n_layers):\\n                   if i == 0:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 73}),\n",
              " Document(page_content='Deep Belief Networks[ 52 ]                input_size = n_ins\\n            else:                       input_size = hidden_layers_sizes[i - 1]\\n            if i == 0:\\n                layer_input = self.x\\n            else:\\n                layer_input = self.sigmoid_layers[-1].output\\n            sigmoid_layer = HiddenLayer(rng=numpy_rng,\\n                                        input=layer_input,\\n                                        n_in=input_size,                                        n_out=hidden_layers_sizes[i],\\n                                        activation=T.nnet.sigmoid)\\n            self.sigmoid_layers.append(sigmoid_layer)\\n            self.params.extend(sigmoid_layer.params)\\nNext up, we create an RBM that shares weights with the sigmoid layers. This directly', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 74}),\n",
              " Document(page_content='leverages the RBM class that we described previously:\\n            rbm_layer = RBM(numpy_rng=numpy_rng,\\n                            theano_rng=theano_rng,                            input=layer_input,                            n_visible=input_size,                            n_hidden=hidden_layers_sizes[i],                            W=sigmoid_layer.W,                            hbias=sigmoid_layer.b)            self.rbm_layers.append(rbm_layer)\\nFinally, we add a logistic regression layer to the end of the DBN so as to form  \\nan MLP:\\n        self.logLayer = LogisticRegression(            input=self.sigmoid_layers[-1].output,            n_in=hidden_layers_sizes[-1],            n_out=n_outs)        self.params.extend(self.logLayer.params)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 74}),\n",
              " Document(page_content='self.finetune_cost = self.logLayer.negative_log_\\nlikelihood(self.y)\\n        self.errors = self.logLayer.errors(self.y)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 74}),\n",
              " Document(page_content=\"Chapter 2[ 53 ]Now that we've put together our MLP class, let's construct DBN. The following code \\nconstructs the network with 28 * 28  inputs (that is, 28*28  pixels in the MNIST \\nimage data), three hidden layers of decreasing size, and 10 output values (for each of \\nthe 10 handwritten number classes in the MNIST dataset):\\n    numpy_rng = numpy.random.RandomState(123)\\n    print '... building the model'    dbn = DBN(numpy_rng=numpy_rng, n_ins=28 * 28,              hidden_layers_sizes=[1000, 800, 720],              n_outs=10)\\nAs discussed earlier in this section, a DBN trains in two stages—a layer-wise\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 75}),\n",
              " Document(page_content=\"pretraining in which each layer takes the output of the preceding layer to train on, which is followed by a fine-tuning step (backpropagation) that allows for weight adjustment across the whole network. The first stage, pretraining, is achieved by performing one step of PCD within each layer's RBM. The following code will perform this pretraining step:\\n    print '... getting the pretraining functions'\\n    pretraining_fns =     dbn.pretraining_functions(train_set_x=train_set_x,    batch_size=batch_size, k=k)\\n    print '... pre-training the model'\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 75}),\n",
              " Document(page_content=\"start_time = time.clock()       for i in xrange(dbn.n_layers):        for epoch in xrange(pretraining_epochs):            c = []            for batch_index in xrange(n_train_batches):                c.append(pretraining_fns[i](index=batch_index,                                            lr=pretrain_lr))            print 'Pre-training layer %i, epoch %d, cost ' % (i, \\nepoch),\\n            print numpy.mean(c)\\n    end_time = time.clock()\\nRunning the pretrained DBN is then achieved by the following command:\\npython code/DBN.py\\nNote that even with GPU acceleration, this code will spend \\nquite a lot of time pretraining, and it is therefore suggested that you run it overnight.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 75}),\n",
              " Document(page_content=\"Deep Belief Networks[ 54 ]Validating the DBN\\nValidation of a DBN as a whole is done in a very familiar way. We can use the \\nminimal validation error from cross-validation as one error measure. However,  \\nthe minimal cross-validation error can underestimate the error expected on  \\ncross-validation data as the meta-parameters may overfit to the new data.\\nAs such, we should use our cross-validation error to adjust our metaparameters \\nuntil the cross-validation error is minimized. Then we should expose our DBN to the held-out test set, using test error as our validation measure. Our \\nDBN class performs \\nexactly this training process.\\nHowever, this doesn't tell us exactly what to do if the network fails to train \\nadequately. What do we do if our DBN is underperforming?\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 76}),\n",
              " Document(page_content=\"The first thing to do is recognize the potential causes and, in this area, there are some \\nusual culprits. We know that the training of underlying RBMs is also quite tricky and any individual layer may fail to train. Thankfully, our \\nRBM class gives us the ability to \\ntap into and view the weights (filters) being generated by each layer, and we can plot these to get a view on what our network is attempting to represent.\\nAdditionally, we want to ask whether our network is overfitting, or else, \\nunderfitting. Either is entirely possible and it's useful to recognize how and why this\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 76}),\n",
              " Document(page_content=\"might be happening. In the case of underfitting, the training process may simply be unable to find good parameters for the model. This is particularly common when you are using a larger network to resolve a large problem space, but can be seen even with some smaller models. If you think that underfitting might be happening with your DBN, you have a couple of options. The first is to simply reduce the size of your hidden layers. This may, or may not, work well. A better alternative is to gradually taper your hidden layers such that each layer learns a refined version of the preceding layer's representation. How to do this, how sharply to taper, and when to stop is a matter of trial and error in the first case and of experience-based learning over the long term.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 76}),\n",
              " Document(page_content=\"Overfitting is a well-known phenomenon where your algorithm trains overly \\nspecifically on the training data provided. This class of problem is typically identified at the point of cross-validation (where your error rate will increase dramatically), but can be quite pernicious. Means of resolving an overfitting issue do exist; one can increase the training dataset size. A more heavy-handed Bayesian approach would be to attach an additional criterion (for example, a prior) that is used to reduce the value of fitting the training data. Some of the most effective methods to improve classification performance are preprocessing methods, which we'll discuss in Chapters 6, Text Feature Engineering  and Chapter 7, Feature Engineering Part II .\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 76}),\n",
              " Document(page_content='Chapter 2[ 55 ]Though this code will initialize from a predefined position (given a seed value), the \\nstochastic nature of the model means that it will quickly diverge and results may vary. When running on my system, this DBN achieved a minimal cross-validation error of 1.19%. More importantly, it achieved a test error of 1.30% after 46 supervised epochs. These are good results; indeed, they are comparable with field-leading examples!\\nFurther reading\\nFor a primer on neural networks, it makes sense to read from a range of sources. There are many concerns to be aware of and different authors emphasize on different material. A solid introduction is provided by Kevin Gurney in An Introduction to Neural Networks.\\nAn excellent piece on the intuitions underlying Markov Chain Monte Carlo is', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 77}),\n",
              " Document(page_content=\"available at \\nhttp://twiecki.github.io/blog/2015/11/10/mcmc-sampling/ .\\nFor readers with a specific interest in the intuitions supporting Gibbs Sampling, \\nPhilip Resnik, and Eric Hardisty's paper, Gibbs Sampling for the Uninitiated , provides \\na technical, but clear description of how Gibbs works. It's particularly notable to \\nhave some really first-rate analogies! Find them at https://www.umiacs.umd.\\nedu/~resnik/pubs/LAMP-TR-153.pdf .\\nThere aren't many good explanations of Contrastive Divergence, one I like is provided by Oliver Woodford at \\nhttp://www.robots.ox.ac.uk/~ojw/files/\\nNotesOnCD.pdf . If you're a little daunted by the heavy use of formal expressions, I \\nwould still recommend that you read it for its articulate description of theory and practical concerns involved.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 77}),\n",
              " Document(page_content='This chapter used the Theano documentation available at \\nhttp://deeplearning.\\nnet/tutorial/contents.html  as a base for discussion and implementation of RBM \\nand DBN classes.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 77}),\n",
              " Document(page_content=\"Deep Belief Networks[ 56 ]Summary\\nWe've covered a lot of ground in this chapter! We began with an overview of Neural \\nNetworks, focusing on the general properties of topology and learning method before taking a deep dive into the RBM algorithm and RBM code itself. We took this solid understanding forward to create a DBN. In doing so, we linked the DBN theory and code together, before firing up our DBN to work over the MNIST dataset. We performed image classification in a 10-class problem and achieved an extremely competitive result, with classification error below 2%!\\nIn the next chapter, we'll continue to build on your mastery of deep learning \\nby introducing you to another deep learning architecture— Stacked Denoising \\nAutoencoders  (SDA).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 78}),\n",
              " Document(page_content=\"[ 57 ]Stacked Denoising \\nAutoencoders\\nIn this chapter, we'll continue building our skill with deep architectures by  \\napplying Stacked Denoising Autoencoders  (SdA ) to learn feature representations \\nfor high-dimensional input data.\\nWe'll start, as before, by gaining a solid understanding of the theory and concepts \\nthat underpin autoencoders. We'll identify related techniques and call out the strengths of autoencoders as part of your data science toolkit. We'll discuss the use of Denoising Autoencoders  (dA), a variation of the algorithm that introduces \\nstochastic corruption to the input data, obliging the autoencoder to decorrupt the input and, in so doing, build a more effective feature representation.\\nWe'll follow up on theory, as before, by walking through the code for a dA class,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 79}),\n",
              " Document(page_content=\"linking theory and implementation details to build a strong understanding of  \\nthe technique.\\nAt this point, we'll take a journey very similar to that taken in the preceding \\nchapter—by stacking dA, we'll create a deep architecture that can be used to pretrain an MLP network, which offers substantial performance improvements in a range of unsupervised learning applications including speech data processing.\\nAutoencoders\\nThe autoencoder (also called the Diabolo network) is another crucial component of \\ndeep architectures. The autoencoder is related to the RBM, with autoencoder training resembling RBM training; however, autoencoders can be easier to train than RBMs with contrastive divergence and are thus preferred in contexts where RBMs train  less effectively.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 79}),\n",
              " Document(page_content='Stacked Denoising Autoencoders[ 58 ]Introducing the autoencoder\\nAn autoencoder is a simple three-layer neural network whose output units are \\ndirectly connected back to the input units. The objective of the autoencoder is to \\nencode the i-dimensional input into an h-dimensional representation, where h < i, before reconstructing (decoding) the input at the output layer. The training process involves iteration over this process until the reconstruction error is minimized—at which point one should have arrived at the most efficient representation of input data (should, barring the possibility of arriving at local minima!).\\nIn a preceding chapter, we discussed PCA as being a powerful dimensionality', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 80}),\n",
              " Document(page_content=\"reduction technique. This description of autoencoders as finding the most efficient reduced-dimensional representation of input data will no doubt be familiar and you may be asking why we're exploring another technique that fulfils the same role.\\nThe simple answer is that like the SOM, autoencoders can provide nonlinear \\nreductions, which enables them to process high-dimensional input data more \\neffectively than PCA. This revives a form of our earlier question—why discuss autoencoders if they deliver what an SOM does, without even providing the illuminating visual presentation?\\nSimply put, autoencoders are a more developed and sophisticated set of techniques;\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 80}),\n",
              " Document(page_content=\"the use of denoising and stacking techniques enable reductions of high-dimensional, multimodal data that can be trained with relative ease to greater accuracy, at greater scale, than the techniques that we discussed in Chapter 1, Unsupervised Machine Learning.\\nHaving discussed the capabilities of autoencoders at a high level, let's dig in a  \\nlittle further to understand the topology of autoencoders as well as what their training involves.\\nTopology\\nAs described earlier in this chapter, an autoencoder has a relatively simple \\nstructure. It is a three-layer neural network, with input , hidden , and output layers. \\nThe input feeds forward into the hidden  layer, then the output layer, as with\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 80}),\n",
              " Document(page_content='most neural network architectures. One topological feature worth mentioning is that the hidden  layer is typically of fewer nodes than the input  or output layers. \\n(However, as intimated previously, the required number of hidden  nodes is really \\na function of the complexity of the input  data; the goal of the hidden  layer is to \\nbottleneck the information content from the input  and force the network to identify \\na representation that captures underlying statistical properties. Representing very complex input accurately might require a large quantity of hidden nodes.)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 80}),\n",
              " Document(page_content='Chapter 3[ 59 ]The key feature of an autoencoder is that the output is typically set to be the input ; \\nthe performance measure for an autoencoder is its accuracy in reconstructing the \\ninput  after encoding it within the hidden  layer. Autoencoder topology tends to take \\nthe following form:\\noutput\\nhidden\\ninputdecode\\nencode\\nThe encoding function that occurs between the input  and hidden  layers is a \\nmapping of an input (x) to a new form (y). A simple example mapping function \\nmight be a nonlinear (in this case sigmoid, s) function of the input as follows:\\n( ) y s Wx b = +\\nHowever, more sophisticated encodings may exist or be developed to accommodate specific subject domains. In this case, of course, W represents the weight values', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 81}),\n",
              " Document(page_content=\"assigned to x and b is an adjustable variable that can be tuned to enable the minimization of reconstruction error.\\nThe autoencoder then decodes to deliver its output. This reconstruction is intended \\nto take the same shape as x and will occur through a similar transformation as follows:\\n( ) z s W y b′ ′ = +\\nHere, b' and W' are typically also configurable to allow network optimization.\\nTraining\\nThe network trains, as discussed, by minimizing the reconstruction error.  \\nOne popular method to measure this error is a simple squared error measure,  \\nas shown in the following formula:\\n2 1\\n2E z x = −\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 81}),\n",
              " Document(page_content='Stacked Denoising Autoencoders[ 60 ]However, different and more appropriate error measures exist for cases where the \\ninput is in a less generic format (such as a set of bit probabilities).\\nWhile the intention  is that autoencoders capture the main axes of variation in the \\ninput dataset, it is possible for an autoencoder to learn something far less useful—the \\nidentity function of the input.\\nDenoising autoencoders\\nWhile autoencoders can work well in some applications, they can be challenging to apply to problems where the input data contains a complex distribution that must be modeled in high dimensionality. The major challenge is that, with autoencoders that have n-dimensional  input and an encoding of at least n, there is a real likelihood that', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 82}),\n",
              " Document(page_content='the autoencoder will just learn the identity function of the input. In such cases, the encoding is a literal copy of the input. Such autoencoders are called overcomplete.\\nOne of the most important properties when training a machine learning technique is to understand how the dimensionality of hidden layers affects the quality of the resulting model. In cases where the input data is complex and the hidden layer has too few nodes to capture that complexity effectively, the result is obvious—the network fails to train as well as it might with more nodes.\\nTo capture complex distributions in input data, then, you may wish to', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 82}),\n",
              " Document(page_content='use a large number of hidden nodes. In cases where the hidden layer has at least as many nodes as the input, there is a strong possibility that the network will learn the identity of the input; in such cases, each element of the input is learned as a specific unique case. Naturally, a model that has been trained to do this will work very well over training data, but as it has learned a trivial pattern that cannot be generalized to unfamiliar data, it is liable to fail catastrophically when validated.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 82}),\n",
              " Document(page_content='This is particularly relevant when modeling complex data, such as speech data. Such data is frequently complex in distribution, so the classification of speech signals requires multimodal encoding and a high-dimensional hidden layer. Of course, this brings an increased risk of the autoencoder (or any of a large number of models as this is not an autoencoder-specific problem) learning the identity function.\\nWhile (rather surprisingly) overcomplete autoencoders can and do learn  \\nerror-minimizing representations under certain configurations (namely, ones in', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 82}),\n",
              " Document(page_content='which the first hidden layer needs very small weights so as to force the hidden units into a linear orientation and subsequent weights have large values), such configurations are difficult to optimize for, and it has been desirable to find another way to prevent overcomplete autoencoders from learning the identity function.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 82}),\n",
              " Document(page_content=\"Chapter 3[ 61 ]There are several different ways that an overcomplete autoencoder can be prevented \\nfrom learning the identity function while still capturing something useful within its representation. By far, the most popular approach is to introduce noise to the input data and force the autoencoder to train on the noisy data by learning distributions and statistical regularities rather than identity. This can be effectively achieved by multiple methods, including using sparseness constraints or dropout techniques (wherein input values are randomly set to zero).\\nThe process that we'll be using to introduce noise to the input in this chapter is \\ndropout. Via this method, up to half of the inputs are randomly set to zero. To achieve\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 83}),\n",
              " Document(page_content='this, we create a stochastic corruption process that operates on our input data:\\ndef get_corrupted_input(self, input, corruption_level):\\n   return self.theano_rng.binomial(size=input.shape, n=1, p=1 -   \\n   corruption_level, dtype=theano.config.floatX) * input\\nIn order to accurately model the input data, the autoencoder has to predict the \\ncorrupted values from the uncorrupted values, thus learning meaningful statistical properties (that is, distribution).\\nIn addition to preventing an autoencoder from learning the identity values of data,', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 83}),\n",
              " Document(page_content='adding a denoising process also tends to produce models that are substantially more robust to input variations or distortion. This proves to be particularly useful for input data that is inherently noisy, such as speech or image data. One commonly recognized advantage of deep learning techniques, mentioned in the preface to this book, is that deep learning algorithms minimize the need for feature engineering. Where many learning algorithms require lengthy and complicated preprocessing of input data (filtering of images or manipulation of audio signals) to reconstruct the denoised input and enable the model to train, a dA can work effectively with minimal preprocessing. This can dramatically decrease the time it takes to train a model over your input data to practical levels of accuracy.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 83}),\n",
              " Document(page_content=\"Finally, it's worth observing that an autoencoder that learns the identity function \\nof the input dataset is probably misconfigured in a fundamental way. As the main added value of the autoencoder is to find a lower-dimensional representation of the \\nfeature set, an autoencoder that has learned the identity function of the input data \\nmay simply have too many nodes. If in doubt, consider reducing the number of \\nnodes in your hidden layer.\\nNow that we've discussed the topology of an autoencoder—the means by which \\none might be effectively trained and the role of denoising in improving autoencoder performance—let's review Theano code for a dA so as to carry the preceding theory into practice.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 83}),\n",
              " Document(page_content=\"Stacked Denoising Autoencoders[ 62 ]Applying a dA\\nAt this point, we're ready to step through the implementation of a dA. Once again, \\nwe're leveraging the Theano library to apply a dA class.\\nUnlike the RBM class that we explored in the previous chapter, the \\nDenoisingAutoencoder is relatively simple and tying the functionality of the dA to the theory and math that we examined earlier in this chapter is relatively simple.\\nIn Chapter 2, Deep Belief Networks, we applied an \\nRBM class that had a number of \\nelements that, while not necessary for the correct functioning of the RBM in itself, \\nenabled shared parameters within multilayer, deep architectures. The dA class we'll\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 84}),\n",
              " Document(page_content='be using possesses similar shared elements that will provide us with the means to build a multilayer autoencoder architecture later in the chapter.\\nWe begin by initializing a \\ndA class. We specify the number of visible units,  \\nn_visible , as well as the number of hidden units, n_hidden . We additionally \\nspecify variables for the configuration of the input ( input ) as well as the weights \\n(W) and the hidden and visible bias values ( bhid  and bvis  respectively). The four \\nadditional variables enable autoencoders to receive configuration parameters from \\nother elements of a deep architecture:\\nclass dA(object):\\n    def __init__(', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 84}),\n",
              " Document(page_content='self,        numpy_rng,        theano_rng=None,        input=None,        n_visible=784,        n_hidden=500,        W=None,        bhid=None,        bvis=None):\\n        self.n_visible = n_visible\\n        self.n_hidden = n_hidden', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 84}),\n",
              " Document(page_content=\"Chapter 3[ 63 ]We follow up by initialising the weight and bias variables. We set the weight vector, \\nW to an initial value, initial_W , which we obtain using random, uniform sampling \\nfrom the range:\\n( ) ( )6. 6.4 4_ _hidde n v isibleton hidde n n visibl e n n− ∗ ∗+ +i\\nWe then set the visible and hidden bias variables to arrays of zeroes using  \\nnumpy.zeros :\\n   if not theano_rng:\\n      theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\\n   if not W:\\n      initial_W = numpy.asarray(         numpy_rng.uniform(            low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),            high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),            size=(n_visible, n_hidden)         ),         dtype=theano.config.floatX      )      W = theano.shared(value=initial_W, name='W', borrow=True)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 85}),\n",
              " Document(page_content=\"if not bvis:\\n      bvis = theano.shared(         value=numpy.zeros(            n_visible,            dtype=theano.config.floatX         ),         borrow=True      )\\n   if not bhid:\\n      bhid = theano.shared(         value=numpy.zeros(            n_hidden,            dtype=theano.config.floatX         ),         name='b',         borrow=True      )\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 85}),\n",
              " Document(page_content=\"Stacked Denoising Autoencoders[ 64 ]Earlier in the chapter, we described how the autoencoder translates between visible \\nand hidden layers via mappings such as ( ) y s Wx b = + . To enable such translation, \\nit is necessary to define W, b, W', and b' in relation to the previously described \\nautoencoder parameters, bhid , bvis , and W. W' and b' are referred to as W_prime  and \\nb_prime  in the following code:\\nself.W = W\\nself.b = bhidself.b_prime = bvisself.W_prime = self.W.Tself.theano_rng = theano_rng\\nif input is None:\\n   self.x = T.dmatrix(name='input')\\nelse:\\n   self.x = input\\nself.params = [self.W, self.b, self.b_prime]\\nThe preceding code sets b and b_prime  to bhid  and bvis  respectively, while  \\nW_prime  is set as the transpose of W; in other words, the weights are tied. Tied\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 86}),\n",
              " Document(page_content='weights are sometimes, but not always, used in autoencoders for several reasons:\\n• Tying weights improves the quality of results in several contexts (albeit  \\noften in contexts where the optimal solution is PCA, which is the solution  \\nan autoencoder with tied weights will tend to reach)\\n• Tying weights improves the memory consumption of the autoencoder by \\nreducing the number of parameters that need be stored\\n• Most importantly, tied weights provide a regularization effect; they require one less parameter to be optimized (thus one less thing that can go wrong!)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 86}),\n",
              " Document(page_content=\"However, in other contexts, it's both common and appropriate to use untied weights. This is true, for instance, in cases where the input data is multimodal and the optimal decoder models a nonlinear set of statistical regularities. In such cases, a linear model, such as PCA, will not effectively model the nonlinear trends and you will tend to obtain better results using untied weights.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 86}),\n",
              " Document(page_content='Chapter 3[ 65 ]Having configured the parameters to our autoencoder, the next step is to define \\nthe functions that enable it to learn. Earlier in this chapter, we determined that autoencoders learn effectively by adding noise to input data, then attempting to learn an encoded representation of that input that can in turn be reconstructed into the input. What we need next, then, are functions that deliver this functionality. We begin by corrupting  the input data:\\ndef get_corrupted_input(self, input, corruption_level):\\n   return self.theano_rng.binomial(size=input.shape, n=1, p=1 – \\n   corruption_level, dtype=theano.config.floatX) * input\\nThe degree of corruption is configurable using a corruption_level  parameter; as', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 87}),\n",
              " Document(page_content=\"we recognized earlier, the corruption of the input through dropout typically does \\nnot exceed 50% of cases, or 0.5. The function takes a random set of cases, where the number of cases is that proportion of the \\ninput  whose size  is equal to corruption_\\nlevel . The function produces a corruption vector of 0's and 1's equal in length \\nto the input, where a corruption_level  sized proportion of the vector is 0. The \\ncorrupted input vector is then simply a multiple of the autoencoder's input vector and corruption vector:\\ndef get_hidden_values(self, input):\\n   return T.nnet.sigmoid(T.dot(input, self.W) + self.b)\\nNext, we obtain the hidden values. This is done via code that performs the equation \\n( ) y s Wx b = +  to obtain y (the hidden values). To get the autoencoder's output (z),\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 87}),\n",
              " Document(page_content=\"we reconstruct the hidden layer via code that uses the previously defined b_prime  \\nand W_prime  to perform ( ) z s W y b′ ′ = + :\\ndefget_reconstructed_input(self, hidden):   returnT.nnet.sigmoid(T.dot(hidden, self.W_prime) +      self.b_prime)\\nThe final missing piece is the calculation of cost updates. We reviewed one cost \\nfunction previously, a simple squared error measure: 2 1\\n2E z x = − . Let's use  \\nthis cost function to calculate our cost updates, based on the input ( x) and \\nreconstruction ( z):\\ndef get_cost_updates(self, corruption_level, learning_rate):\\n   tilde_x = self.get_corrupted_input(self.x, corruption_level)\\n   y = self.get_hidden_values(tilde_x)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 87}),\n",
              " Document(page_content='Stacked Denoising Autoencoders[ 66 ]   z = self.get_reconstructed_input(y)\\n   E = (0.5 * (T.z – T.self.x)) ^ 2   cost = T.mean(E)\\n   gparams = T.grad(cost, self.params)\\n   updates = [\\n      (param, param - learning_rate * gparam)      for param, gparam in zip(self.params, gparams)   ]\\nreturn (cost, updates)\\nAt this point, we have a functional dA! It may be used to model nonlinear properties \\nof input data and can work as an effective tool to learn valid and lower-dimensional representations of input data. However, the real power of autoencoders comes from the properties that they display when stacked together, as the building blocks of a deep architecture.\\nStacked Denoising Autoencoders', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 88}),\n",
              " Document(page_content=\"While autoencoders are valuable tools in themselves, significant accuracy can be obtained by stacking autoencoders to form a deep network. This is achieved by feeding the representation created by the encoder on one layer into the next layer's encoder as the input to that layer.\\nStacked denoising autoencoders  (SdAs ) are currently in use in many leading data \\nscience teams for sophisticated natural language analyses as well as a hugely broad \\nrange of signals, image, and text analysis.\\nThe implementation of a SdA will be very familiar after the previous chapter's \\ndiscussion of deep belief networks. The SdA is used in much the same way as the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 88}),\n",
              " Document(page_content='RBMs in our deep belief networks were used. Each layer of the deep architecture will have a dA and sigmoid component, with the autoencoder component being used to pretrain the sigmoid network. The performance measure used by a stacked \\ndenoising autoencoder is the training set error, with an intensive period of layer-to-\\nlayer (layer-wise) pretraining used to gradually align network parameters before \\na final period of fine-tuning. During fine-tuning, the network is trained using validation and test data, over fewer epochs but with larger update steps. The goal is to have the network converge at the end of the fine-tuning in order to deliver an \\naccurate result.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 88}),\n",
              " Document(page_content='Chapter 3[ 67 ]In addition to delivering on the typical advantages of deep networks (the ability \\nto learn feature representations for complex or high-dimensional datasets, and the ability to train a model without extensive feature engineering), stacked autoencoders have an additional, interesting property.\\nCorrectly configured stacked autoencoders can capture a hierarchical grouping \\nof their input data. Successive layers of a stacked denoised autoencoder may learn \\nincreasingly high-level features. Where the first layer might learn some first-order \\nfeatures from input data (such as learning edges in a photo image), a second layer \\nmay learn some grouping of first-order features (for instance, by learning given', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 89}),\n",
              " Document(page_content=\"configurations of edges that correspond to contours or structural elements in the input image).\\nThere's no golden rule to determine how many layers or how large layers should \\nbe for a given problem. The best solution is usually to experiment with these model \\nparameters until you find an optimal point. This experimentation is best done with a \\nhyperparameter optimization technique or genetic algorithm (subjects we'll discuss \\nin later chapters of this book).\\nHigher layers may learn increasingly high-order configurations, enabling a\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 89}),\n",
              " Document(page_content=\"stacked denoised autoencoder to learn to recognize facial features, alphanumerical characters, or generalized forms of objects (such as a bird). This is what gives SdAs their unique capability to learn very sophisticated, high-level abstractions of their input data.\\nAutoencoders can be stacked indefinitely, and it has been demonstrated that \\ncontinuing to stack autoencoders can improve the effectiveness of the deep architecture (with the main constraint becoming compute cost in time). In this chapter, we'll look at stacking three autoencoders to solve a natural language processing challenge.\\nApplying the SdA\\nNow that we've had a chance to understand the advantages and power of the SdA as a deep learning architecture, let's test our skills on a real-world dataset.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 89}),\n",
              " Document(page_content=\"For this chapter, let's step away from image datasets and work with the OpinRank \\nReview dataset, a text dataset of around 259,000 hotel reviews from TripAdvisor—accessible via the UCI machine learning dataset repository. This freely-available dataset provides review scores (as floating point numbers from 1 to 5) and review text for a broad range of hotels; we'll be applying our stacked dA to attempt to identify the scoring of each hotel from its review text.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 89}),\n",
              " Document(page_content=\"Stacked Denoising Autoencoders[ 68 ]We'll be applying our autoencoder to analyze a preprocessed version of \\nthis data, which is accessible from the GitHub share accompanying this chapter. We'll be discussing the techniques by which we prepare text data in an upcoming chapter. For the interested reader, the source data is available at https://archive.ics.uci.edu/ml/datasets/OpinRank+Review+Dataset.\\nIn order to get started, we're going to need a stacked denoising autoencoder (hereafter \\nSdA) class:\\nclass SdA(object):\\n    def __init__(\\n        self,        numpy_rng,        theano_rng=None,        n_ins=280,        hidden_layers_sizes=[500, 500],        n_outs=5,        corruption_levels=[0.1, 0.1]):\\nAs we previously discussed, the SdA is created by feeding the encoding from\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 90}),\n",
              " Document(page_content=\"one layer's autoencoder as the input to the subsequent layer. This class supports \\nthe configuration of the layer count (reflected in, but not set by, the length of the \\nhidden_layers_sizes  and corruption_levels  vectors). It also supports \\ndifferentiated layer sizes (in nodes) at each layer, which can be set using hidden_\\nlayers_sizes . As we discussed, the ability to configure successive layers of the \\nautoencoder is critical to developing successful representations.\\nNext, we need parameters to store the MLP ( self.sigmoid_layers ) and dA ( self.\\ndA_layers ) elements of the SdA. In order to specify the depth of our architecture,  \\nwe use the self.n_layers  parameter to specify the number of sigmoid and dA \\nlayers required:\\nself.sigmoid_layers = []\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 90}),\n",
              " Document(page_content='self.dA_layers = []self.params = []self.n_layers = len(hidden_layers_sizes)\\nassertself.n_layers> 0', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 90}),\n",
              " Document(page_content='Chapter 3[ 69 ]Next, we need to construct our sigmoid and dA layers. We begin by setting the \\nhidden layer size to be set either from the input vector size or by the activation of the preceding layer. Following this, \\nsigmoid_layer  and dA_layer  components are \\ncreated, with the dA layer drawing from the dA class that we discussed earlier in  \\nthis chapter:\\nfor i in xrange(self.n_layers):\\n   if i == 0:      input_size = n_ins\\n   else:\\n      input_size = hidden_layers_sizes[i - 1]\\nif i == 0:\\n   layer_input = self.x\\nelse:\\n   layer_input = self.sigmoid_layers[-1].output\\nsigmoid_layer = HiddenLayer(rng=numpy_rng, \\ninput=layer_input, n_in=input_size, \\nn_out=hidden_layers_sizes[i], \\nactivation=T.nnet.sigmoid)\\nself.sigmoid_layers.append(sigmoid_layer)\\nself.params.extend(sigmoid_layer.params)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 91}),\n",
              " Document(page_content=\"dA_layer = dA(numpy_rng=numpy_rng, \\ntheano_rng=theano_rng, input=layer_input, n_visible=input_size, n_hidden=hidden_layers_sizes[i], W=sigmoid_layer.W, bhid=sigmoid_layer.b)\\nself.dA_layers.append(dA_layer)\\nHaving implemented the layers of our stacked dA, we'll need a final, logistic \\nregression layer to complete the MLP component of the network:\\nself.logLayer = LogisticRegression(\\n   input=self.sigmoid_layers[-1].output,   n_in=hidden_layers_sizes[-1],   n_out=n_outs)\\nself.params.extend(self.logLayer.params)\\nself.finetune_cost = self.logLayer.negative_log_likelihood(self.y)self.errors = self.logLayer.errors(self.y)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 91}),\n",
              " Document(page_content='Stacked Denoising Autoencoders[ 70 ]This completes the architecture of our SdA. Next up, we need to generate the \\ntraining functions used by the SdA class. Each function will the minibatch index \\n(index ) as an argument, together with several other elements—the corruption_\\nlevel  and learning_rate  are enabled here so that we can adjust them (for example, \\ngradually increase or decrease them) during training. Additionally, we identify variables that help identify where the batch starts and ends—\\nbatch_begin  and \\nbatch_end , respectively:\\nThe ability to dynamically adjust the learning rate is particularly very helpful and may be applied in one of two ways. Once a technique has begun to converge on an appropriate solution, it is very helpful to be', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 92}),\n",
              " Document(page_content=\"able to reduce the learning rate. If you do not do this, you risk creating \\na situation in which the network oscillates between values located \\naround the optimum without ever hitting it. In some contexts, it can be helpful to tie the learning rate to the network's performance measure. If the error rate is high, it makes sense to make larger adjustments until the error rate begins to decrease!\\ndef pretraining_functions(self, train_set_x, batch_size):\\n    index = T.lscalar('index')      corruption_level = T.scalar('corruption')      learning_rate = T.scalar('lr')      batch_begin = index * batch_size    batch_end = batch_begin + batch_size\\n    pretrain_fns = []\\n    for dA in self.dA_layers:        cost, updates = dA.get_cost_updates(corruption_level, \\n          learning_rate)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 92}),\n",
              " Document(page_content='fn = theano.function(            inputs=[                index,                theano.Param(corruption_level, default=0.2),                theano.Param(learning_rate, default=0.1)            ],            outputs=cost,            updates=updates,            givens={                self.x: train_set_x[batch_begin: batch_end]            }         )         pretrain_fns.append(fn)\\n    return pretrain_fns', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 92}),\n",
              " Document(page_content=\"Chapter 3[ 71 ]The pretraining functions that we've created takes the minibatch index  and \\ncan optionally take the corruption level or learning rate. It performs one step of \\npretraining and outputs the cost value and vector of weight updates.\\nIn addition to pretraining, we need to build functions to support the fine-tuning \\nstage, wherein the network is run iteratively over the validation and test data to optimize network parameters. The training function (\\ntrain_fn ) seen in the code \\nbelow implements a single step of fine-tuning. The valid_score  is a Python function \\nthat computes a validation score using the error measure produced by the SdA over \\nvalidation data. Similarly, test_score  computes the error score over test data.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 93}),\n",
              " Document(page_content='To get this process off the ground, we first need to set up training, validation, and test datasets. Each stage requires two datasets (set \\nx and set y) containing the \\nfeatures and class labels, respectively. The required number of minibatches for validation and test is determined, and an index is created to track the batch size (and provide a means of identifying at which entries a batch starts and ends). Training, validation, and testing occurs for each batch and afterward, both \\nvalid_score  and \\ntest_score  are calculated across all batches:\\ndef build_finetune_functions(self, datasets, batch_size,   learning_rate):\\n   (train_set_x, train_set_y) = datasets[0]\\n   (valid_set_x, valid_set_y) = datasets[1]   (test_set_x, test_set_y) = datasets[2]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 93}),\n",
              " Document(page_content=\"n_valid_batches = valid_set_x.get_value(borrow=True).shape[0]\\n   n_valid_batches /= batch_size   n_test_batches = test_set_x.get_value(borrow=True).shape[0]   n_test_batches /= batch_size\\n   index = T.lscalar('index')  \\n   gparams = T.grad(self.finetune_cost, self.params)   updates = [\\n       (param, param - gparam * learning_rate)       For param, gparam in zip(self.params, gparams)]\\ntrain_fn = theano.function(\\n   inputs=[index],\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 93}),\n",
              " Document(page_content=\"Stacked Denoising Autoencoders[ 72 ]   outputs=self.finetune_cost,\\n   updates=updates,   givens={\\n      self.x: train_set_x[\\n         index * batch_size: (index + 1) * batch_size\\n      ],\\n      self.y: train_set_y[         index * batch_size: (index + 1) * batch_size      ]\\n   },\\n   name='train')\\ntest_score_i = theano.function(\\n    [index],\\n   self.errors,\\n   givens={\\n      self.x: test_set_x[\\n      index * batch_size: (index + 1) * batch_size   ],      self.y: test_set_y[      index * batch_size: (index + 1) * batch_size   ]},   name='test')\\nvalid_score_i = theano.function(\\n   [index],\\n   self.errors,\\n   givens={\\n      self.x: valid_set_x[\\n         index * batch_size: (index + 1) * batch_size\\n      ],\\n      self.y: valid_set_y[\\n         index * batch_size: (index + 1) * batch_size\\n      ]\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 94}),\n",
              " Document(page_content=\"},\\n   name='valid'\\n)\\ndef valid_score():\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 94}),\n",
              " Document(page_content=\"Chapter 3[ 73 ]   return [valid_score_i(i) for i inxrange(n_valid_batches)]\\ndef test_score():\\n   return [test_score_i(i) for i inxrange(n_test_batches)]\\nreturn train_fn, valid_score, test_score\\nWith the training functionality in place, the following code initiates our stacked dA:\\nnumpy_rng = numpy.random.RandomState(89677)\\nprint '... building the model'   sda = SdA(      numpy_rng=numpy_rng,      n_ins=280,      hidden_layers_sizes=[240, 170, 100],      n_outs=5   )\\nIt should be noted that, at this point, we should be trying an initial configuration \\nof layer sizes to see how we do. In this case, the layer sizes used are the product of some initial testing. As we discussed, training the \\nSdA occurs in two stages. The first\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 95}),\n",
              " Document(page_content=\"is a layer-wise pretraining process that loops over all of the SdA's  layers. The second \\nis a process of fine-tuning over validation and test data.\\nTo pretrain the SdA, we provide the required corruption levels to train each layer and \\niterate over the layers using our previously defined pretraining_fns :\\nprint '... getting the pretraining functions'\\npretraining_fns = sda.pretraining_functions(train_set_x=train_set_x,batch_size=batch_size)\\nprint '... pre-training the model'\\nstart_time = time.clock()corruption_levels = [.1, .2, .2]for i in xrange(sda.n_layers):\\n   for epoch in xrange(pretraining_epochs):\\n      c = []      for batch_index in xrange(n_train_batches):         c.append(pretraining_fns[i](index=batch_index,         corruption=corruption_levels[i],         lr=pretrain_lr))\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 95}),\n",
              " Document(page_content=\"Stacked Denoising Autoencoders[ 74 ]print 'Pre-training layer %i, epoch %d, cost ' % (i, epoch),\\nprint numpy.mean(c)\\nend_time = time.clock()\\nprint(('The pretraining code for file ' +\\nos.path.split(__file__)[1] + ' ran for %.2fm' % ((end_time - start_\\ntime) / 60.)), file = sys.stderr)\\nAt this point, we're able to initialize our SdA class via calling the preceding code \\nstored within this book's GitHub repository: MasteringMLWithPython/Chapter3/\\nSdA.py\\nAssessing SdA performance\\nThe SdA will take a significant length of time to run. With 15 epochs per layer  \\nand each layer typically taking an average of 11 minutes, the network will run for around 500 minutes on a modern desktop system with GPU acceleration and a single-threaded GotoBLAS.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 96}),\n",
              " Document(page_content='On a system without GPU acceleration, the network will take substantially longer \\nto train, and it is recommended that you use the alternative, which runs over a significantly smaller input dataset: \\nMasteringMLWithPython/Chapter3/SdA_no_\\nblas.py\\nThe results are of high quality, with a validation error score of 3.22% and test error score of 3.14%. These results are particularly impressive given the ambiguous and sometimes challenging nature of natural language processing applications.\\nIt was noticeable that the network classified more correctly for the 1-star and 5-star \\nrating cases than for the intermediate levels. This is largely due to the ambiguous nature of unpolarized or unemotional language.\\nPart of the reason that this input data was classifiable was via significant feature', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 96}),\n",
              " Document(page_content=\"engineering. While time-consuming and sometimes problematic, we've seen that \\nwell-executed feature engineering combined with an optimized model can deliver  \\nan excellent level of accuracy. In Chapter 6, Text Feature Engineering , we'll be applying \\nthe techniques used to prepare this dataset ourselves.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 96}),\n",
              " Document(page_content='Chapter 3[ 75 ]Further reading\\nA well-informed overview of autoencoders (amongst other subjects) is provided by \\nQuoc V. Le from the Google Brain team. Read about it at https://cs.stanford.\\nedu/~quocle/tutorial2.pdf . \\nThis chapter used the Theano documentation available at http://deeplearning.\\nnet/tutorial/contents.html  as a base for discussion as Theano was the main \\nlibrary used in this chapter.\\nSummary', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 97}),\n",
              " Document(page_content='In this chapter, we introduced the autoencoder, an effective dimensionality reduction technique with some unique applications. We focused on the theory behind the stacked denoised autoencoder, an extension of autoencoders whereby any number of autoencoders are stacked in a deep architecture. We were able to apply the stacked denoised autoencoder to a challenging natural language processing problem and met with great success, delivering highly accurate sentiment analysis of hotel reviews.\\nIn the next chapter, we will discuss supervised deep learning methods, including \\nConvolutional Neural Networks (CNN).', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 97}),\n",
              " Document(page_content=\"[ 77 ]Convolutional Neural \\nNetworks\\nIn this chapter, you'll be learning how to apply the convolutional neural network \\n(also referred to as the CNN or convnet), perhaps the best-known deep architecture, via the following steps:\\n• Taking a look at the convnet's topology and learning processes, including convolutional and pooling layers\\n• Understanding how we can combine convnet components into successful network architectures\\n• Using Python code to apply a convnet architecture so as to solve a  \\nwell-known image classification task\\nIntroducing the CNN\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 99}),\n",
              " Document(page_content='In the field of machine learning, there is an enduring preference for developing structures in code that parallel biological structures. One of the most obvious examples is that of the MLP neural network, whose topology and learning  processes are inspired by the neurons of the human brain.\\nThis preference has turned out to be highly efficient; the availability of specialized, \\noptimized biological structures that excel at specific sets of tasks gives us a wealth of templates and clues from which to design and create effective learning models.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 99}),\n",
              " Document(page_content=\"Convolutional Neural Networks[ 78 ]The design of convolutional neural networks takes inspiration from the visual \\ncortex—the area of the brain that processes visual input. The visual cortex has several specializations that enable it to effectively process visual data; it contains many receptor cells that detect light in overlapping regions of the visual field. All receptor cells are subject to the same convolution operation, which is to say that they all process their input in the same way. These specializations were incorporated into the design of convnets, making their topology noticeably distinct from that of other neural networks.\\nIt's safe to say that CNN (convnets for short) are underpinning many of the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 100}),\n",
              " Document(page_content=\"most impactful current advances in artificial intelligence and machine learning. Variants of CNN are applied to some of the most sophisticated visual, linguistic,  \\nand problem-solving applications in existence. Some examples include the following:\\n• Google has developed a range of specialized convnet architectures, \\nincluding GoogLeNet, a 22-layer convnet architecture. In addition, Google's \\nDeepDream program, which became well-known for its overtrained, \\nhallucinogenic imagery, also uses a convolutional neural network.\\n• Convolutional nets have been taught to play the game Go (a long-standing \\nAI challenge), achieving win-rates ranging between 85% and 91% against highly-ranked players.\\n• Facebook uses convolutional nets in face verification (DeepFace).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 100}),\n",
              " Document(page_content=\"• Baidu, Microsoft research, IBM, and Twitter are among the many other  \\nteams using convnets to tackle the challenges around trying to deliver  next-generation intelligent applications.\\nIn recent years, object recognition challenges, such as the 2014 ImageNet challenge, have been dominated by winners employing specialized convnet implementations or multiple-model ensembles that combine convnets with other architectures.\\nWhile we'll cover how to create and effectively apply ensembles in Chapter 8, \\nEnsemble Methods, this chapter focuses on the successful application of convolutional neural networks to large-scale visual classification contexts.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 100}),\n",
              " Document(page_content=\"Chapter 4[ 79 ]Understanding the convnet topology\\nThe convolutional neural network's architecture should be fairly familiar; the \\nnetwork is an acyclic graph composed of layers of increasingly few nodes, where each layer feeds into the next. This will be very familiar from many well-known network topologies such as the MLP.\\nPerhaps the most immediate difference between a convolutional neural network and\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 101}),\n",
              " Document(page_content=\"most other networks is that all of the neurons in a convnet are identical! All neurons possess the same parameters and weight values. As you can see, this will immediately reduce the number of parameter values controlled by the network, bringing substantial efficiency savings. It also typically improves network learning rate as there are fewer free parameters to be managed and computed over. As we'll see later in this chapter, shared weights also enable a convnet to learn features irrespective of their position in the input (for example, the input image or audio signal).\\nAnother big difference between convolutional networks and other architectures is\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 101}),\n",
              " Document(page_content=\"that the connectivity between nodes is limited such as to develop a spatially local connectivity pattern. In other words, the inputs to a given node will be limited to only those nodes whose receptor fields are contiguous. This may be spatially \\ncontiguous, as in the case of image data; in such cases, each neuron's inputs will \\nultimately draw from a continuous subset of the image. In the case of audio signal \\ndata, the input might instead be a continuous window of time.\\nTo illustrate this more clearly, let's take an example input image and discuss how\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 101}),\n",
              " Document(page_content=\"a convolutional network might process parts of that image across specific nodes. Nodes in the first layer of a convolutional neural network will be assigned subsets of the input image. In this case, let's say that they take a 3 x 3 pixel subset of the image each. Our coverage covers the entire image without any overlap between the areas taken as input by nodes and without any gaps. (Note that none of these conditions are automatically true for convnet implementations.) Each node is assigned a 3 x 3 pixel subset of the image (the receptive field of the node) and outputs a transformed version of that input. We'll disregard the specifics of that transformation for now.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 101}),\n",
              " Document(page_content=\"Convolutional Neural Networks[ 80 ]This output is usually then picked up by a second layer of nodes. In this case, let's \\nsay that our second layer is taking a subset of all of the outputs from nodes in the first layer. For example, it might be taking a contiguous 6 x 6 pixel subset of the original image; that is, it has a receptive field that covers the outputs of exactly  \\nfour nodes from the preceding layer. This becomes a little more intuitive when \\nexplained visually:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 102}),\n",
              " Document(page_content='Chapter 4[ 81 ]Each layer is composable; the output of one convolutional layer may be fed  \\ninto the next layer as an input. This provides the same effect that we saw in the Chapter 3, Stacked Denoising Autoencoders ; successive layers develop representations \\nof increasingly high-level, abstract features. Furthermore, as we build downward—adding layers—the representation becomes responsive to a larger region of pixel space. Ultimately, by stacking layers, we can work our way toward global representations of the entire input.\\nUnderstanding convolution layers\\nAs described, in order to prevent each node from learning an unpredictable (and', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 103}),\n",
              " Document(page_content='difficult to tune!) set of very local, free parameters, weights in a layer are shared across the entire layer. To be completely precise, the filters applied in a convolutional layer are a single set of filters, which are slid (convolved) across the input dataset. This produces a two-dimensional activation map of the input, which is referred to as the feature map.\\nThe filter itself is subject to four hyperparameters: size, depth, stride, and zero-', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 103}),\n",
              " Document(page_content=\"padding. The size of the filter is fairly self-explanatory, being the area of the filter (obviously, found by multiplying height and width; a filter need not be square!). Larger filters will tend to overlap more, and as we'll see, this can improve the accuracy of classification. Crucially, however, increasing the filter size will create increasingly large outputs. As we'll see, managing the size of outputs from convolutional layers is a huge factor in controlling the efficiency of a network.\\nDepth defines the number of nodes in the layer that connect to the same region of \\nthe input. The trick to understanding depth is to recognize that looking at an image\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 103}),\n",
              " Document(page_content=\"(for people or networks) involves processing multiple different types of property. Anyone who has ever looked at all the image adjustment sliders in Photoshop has an \\nidea of what this might entail. Depth is sometimes referred to as a dimension in its \\nown right; it almost relates to the complexity of an image, not in terms of its contents \\nbut in terms of the number of channels needed to accurately describe it.\\nIt's possible that the depth might describe color channels, with nodes mapped to \\nrecognize green, blue, or red in the input. This, incidentally, leads to a common convention where depth is set to three (particularly at the first convolution layer).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 103}),\n",
              " Document(page_content=\"It's very important to recognize that some nodes commonly learn to express less easily-described properties of input images that happen to enable a convnet to learn that image more accurately. Increasing the depth hyperparameter tends to enable nodes to encode more information about inputs, with the attendant problems and benefits that you might expect.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 103}),\n",
              " Document(page_content=\"Convolutional Neural Networks[ 82 ]As a result, setting the depth parameter to too small a value tends to lead to poor \\nresults because the network doesn't have the expressive depth (in terms of channel count) required to accurately characterize input data. This is a problem analogous to not having enough features, except that it's more easily fixed; one can tune the depth of the network upward to improve the expressive depth of the convnet.\\nEqually, setting the depth parameter to too small a value can be redundant or \\nharmful to performance, thereafter. If in doubt, consider testing the appropriate \\ndepth value during network configuration via hyperparameter optimization, the \\nelbow method, or another technique.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 104}),\n",
              " Document(page_content=\"Stride is a measure of spacing between neurons. A stride value of one will lead every \\nelement of the input (for an image, potentially every pixel) to be the center of a filter \\ninstance. This naturally leads to a high degree of overlap and very large outputs. \\nIncreasing the stride causes less of an overlap in the receptive fields and the output's \\nsize is reduced. While tuning the stride of a convnet is a question of weighing accuracy \\nagainst output size, it can generally be a good idea to use smaller strides, which tend \\nto work better. In addition, a stride value of one enables us to manage down-sampling and scale reduction at pooling layers (as we'll discuss later in the chapter).\\nThe following diagram graphically displays both Depth and Stride:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 104}),\n",
              " Document(page_content=\"Chapter 4[ 83 ]The final hyperparameter, zero-padding, offers an interesting convenience. Zero-\\npadding is the process of setting the outer values (the border) of each receptive field to zero, which has the effect of reducing the output size for that layer. It's possible to set one, or multiple, pixels around the border of the field to zero, which reduces the output size accordingly. There are, of course, limits; obviously, it's not a good idea to set zero-padding and stride such that areas of the input are not touched by a filter! More generally, increasing the degree of zero-padding can cause a decrease in effectiveness, which is tied to the increased difficulty of learning features via coarse coding. (Refer to the Understanding pooling layers section in this chapter.)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 105}),\n",
              " Document(page_content='However, zero-padding is very helpful because it enables us to adjust the input and \\noutput sizes to be the same. This is a very common practice; using zero-padding to ensure that the size of the input layer and output layer are equal, we are able to easily manage the stride and depth values. Without using zero-padding in this way, we would need to do a lot of work tracking input sizes and managing network parameters simply to make the network function correctly. In addition, zero-padding also improves performance as, without it, a convnet will tend to gradually degrade content at the edges of the filter.\\nIn order to calibrate the number of nodes, appropriate stride, and padding for \\nsuccessive layers when we define our convnet, we need to know the size of the', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 105}),\n",
              " Document(page_content=\"output from the preceding layer. We can calculate the spatial size of a layer's output \\n(O) as a function of the input image size (W), filter size (F), stride (S), and the amount of zero-padding applied (P), as follows:\\n2\\n1W F POS− +=+\\nIf O is not an integer, the filters do not tile across the input neatly and instead extend over the edge of the input. This can cause some problematic issues when training (normally involving thrown exceptions)! By adjusting the stride value, one can find a whole-number solution for O and train effectively. It is normal for the stride to be constrained to what is possible given the other hyperparameter values and size of the input.\\nWe've discussed the hyperparameters involved in correctly configuring the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 105}),\n",
              " Document(page_content=\"convolutional layer, but we haven't yet discussed the convolution process itself. Convolution is a mathematical operator, like addition or derivation, which is heavily used in signal processing applications and in many other contexts where its application helps simplify complex equations.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 105}),\n",
              " Document(page_content=\"Convolutional Neural Networks[ 84 ]Loosely speaking, convolution is an operation over two functions, such as to produce \\na third function that is a modified version of one of the two original functions. In the case of convolution within a convnet, the first component is the network's input. In the case of convolution applied to images, convolution is applied in two dimensions (the width and height of the image). The input image is typically three matrices of pixels—one for each of the red, blue, and green color channels, with values ranging between 0 and 255 in each channel.\\nAt this point, it's worth introducing the concept of a tensor. Tensor is a term commonly used to refer to an n-dimensional array or matrix of input data, commonly applied in deep learning contexts. It's effectively\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 106}),\n",
              " Document(page_content=\"analogous to a matrix or array. We'll be discussing tensors in more detail, \\nboth in this chapter and in Chapter 9, Additional Python Machine Learning \\nTools  (where we review the TensorFlow library). It's worth noting that \\nthe term tensor is noticing a resurgence of use in the machine learning community, largely through the influence of Google machine intelligence research teams.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 106}),\n",
              " Document(page_content='The second input to the convolution operation is the convolution kernel, a single matrix of floating point numbers that acts as a filter on the input matrices. The output of this convolution operation is the feature map. The convolution operation works by sliding the filter across the input, computing the dot product of the two arguments at each instance, which is written to the feature map. In cases where the stride of the convolutional layer is one, this operation will be performed across each pixel of the input image.\\nThe main advantage of convolution is that it reduces the need for feature', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 106}),\n",
              " Document(page_content=\"engineering. Creating and managing complex kernels and performing the highly specialized feature engineering processes needed is a demanding task, made more challenging by the fact that feature engineering processes that work well in one context can work poorly in most others. While we discuss feature engineering  in detail in Chapter 7, Feature Engineering Part II , convolutional nets offer a powerful \\nalternative.\\nCNN, however, incrementally improve their kernel's ability to filter a given input,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 106}),\n",
              " Document(page_content=\"thus automatically optimizing their kernel. This process is accelerated by learning multiple kernels in parallel at once. This is feature learning, which we've encountered in previous chapters. Feature learning can offer tremendous advantages in time and in increasing the accessibility of many problems. As with our earlier SDA and DBN implementations, we would look to pass our learned features to a much simpler, shallow neural network, which uses these features to classify the input image.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 106}),\n",
              " Document(page_content=\"Chapter 4[ 85 ]Understanding pooling layers\\nStacking convolutional layers allows us to create a topology that effectively  \\ncreates features as feature maps for complex, noisy input data. However, convolutional layers are not the only component of a deep network. It is common  \\nto weave convolutional layers in with pooling layers. Pooling is an operation  over feature maps, where multiple feature values are aggregated into a single value—mostly using a max (max-pooling), mean (mean-pooling), or summation (sum-pooling) operation.\\nPooling is a fairly natural approach that offers substantial advantages. If we do not \\naggregate feature maps, we tend to find ourselves with a huge amount of features. The CIFAR-10 dataset that we'll be classifying later in this chapter contains 60,000\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 107}),\n",
              " Document(page_content=\"32 x 32 pixel images. If we hypothetically learned 200 features for each image—over \\n8 x 8 inputs—then at each convolution, we'd find ourselves with an output vector of size (32 – 8+1) * (32 – 8+1) * 200, or 125,000 features per image. Convolution produces a huge amount of features that tend to make computation very expensive and can also introduce significant overfitting problems.\\nThe other major advantage provided by a pooling operation is that it provides a \\nlevel of robustness against the many, small deviations and variances that occur in \\nmodeling noisy, high-dimensional data. Specifically, pooling prevents the network\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 107}),\n",
              " Document(page_content='learning the position of features too specifically (overfitting), which is obviously a critical requirement in image processing and recognition settings. With pooling, the network no longer fixates on the precise location of features in the input and gains a \\ngreater ability to generalize. This is called translation-invariance.\\nMax-pooling is the most commonly applied pooling operation. This is because it \\nfocuses on the most responsive features in question that should, in theory, make it the best candidate for image recognition and classification purposes. By a similar logic, min-pooling tends to be applied in cases where it is necessary to take additional steps to prevent an overly sensitive classification or overfitting from occurring.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 107}),\n",
              " Document(page_content=\"For obvious reasons, it's prudent to begin modeling using a quickly applied and \\nstraightforward pooling method such as max-pooling. However, when seeking additional gains in network performance during later iterations, it's important to look at whether your pooling operations can be improved on. There isn't any real restriction in terms of defining your own pooling operation. Indeed, finding a more effective subsampling method or alternative aggregation can substantially improve the performance of your model.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 107}),\n",
              " Document(page_content=\"Convolutional Neural Networks[ 86 ]In terms of theano  code, a max-pooling implementation is pretty straightforward \\nand may look like this:\\nfrom theano.tensor.signal import downsample\\ninput = T.dtensor4('input')\\nmaxpool_shape = (2, 2)pool_out = downsample.max_pool_2d(input, maxpool_shape, ignore_\\nborder=True)\\nf = theano.function([input],pool_out)\\nThe max_pool_2d  function takes an n-dimensional tensor  and downscaling  \\nfactor, in this case, input  and maxpool_shape , with the latter being a tuple of  \\nlength 2, containing width and height downscaling factors for the input image.  \\nThe max_pool_2d  operation then performs max-pooling over the two trailing \\ndimensions of the vector:\\ninvals = numpy.random.RandomState(1).rand(3, 2, 5, 5)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 108}),\n",
              " Document(page_content='pool_out = downsample.max_pool_2d(input, maxpool_shape, ignore_\\nborder=False)\\nf = theano.function([input],pool_out)\\nThe ignore_border  determines whether the border values are considered  \\nor discarded. This max-pooling operation produces the following, given that \\nignore_border = True :\\n[[ 0.72032449  0.39676747]\\n[ 0.6852195   0.87811744]]\\nAs you can see, pooling is a straightforward operation that can provide dramatic \\nresults (in this case, the input was a 5 x 5 matrix, reduced to 2 x 2). However, pooling is not without critics. In particular, Geoffrey Hinton offered this pretty delightful soundbite:\\n\"The pooling operation used in convolutional neural networks is a big mistake and the fact that it works so well is a disaster.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 108}),\n",
              " Document(page_content='If the pools do not overlap, pooling loses valuable information about where things \\nare. We need this information to detect precise relationships between the parts \\nof an object. Its true that if the pools overlap enough, the positions of features \\nwill be accurately preserved by \"coarse coding\" (see my paper on \"distributed \\nrepresentations\" in 1986 for an explanation of this effect). But I no longer believe that coarse coding is the best way to represent the poses of objects relative to the viewer (by pose I mean position, orientation, and scale).\"', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 108}),\n",
              " Document(page_content=\"Chapter 4[ 87 ]This is a bold statement, but it makes sense. Hinton's telling us that the pooling \\noperation, as an aggregation, does what any aggregation necessarily does—it reduces the data to a simpler and less informationally-rich format. This wouldn't  \\nbe too damaging, except that Hinton goes further.\\nEven if we'd reduced the data down to single values for each pool, we could still \\nhope that the fact that multiple pools overlap spatially would still present feature \\nencodings. (This is the coarse coding referred to by Hinton.) This is also quite \\nan intuitive concept. Imagine that you're listening in to a signal on a noisy radio \\nfrequency. Even if you only caught one word in three, it's probable that you'd be able \\nto distinguish a distress signal from the shipping forecast!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 109}),\n",
              " Document(page_content=\"However, Hinton follows up by observing that coarse coding is not as effective in \\nlearning pose (position, orientation, and scale). There are so many permutations in \\nviewpoint relative to an object that it's unlikely two images would be alike and the \\nsheer variety of possible poses becomes a challenge for a convolutional network \\nusing pooling. This suggests that an architecture that does not overcome this \\nchallenge may not be able to break past an upper limit for image classification.\\nHowever, the general consensus, at least for now, is that even after acknowledging \\nall of this, it is still highly advantageous in terms of efficiency and translation-invariance to continue using pooling operations in convnets. Right now, the argument goes that it's the best we have!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 109}),\n",
              " Document(page_content=\"Meanwhile, Hinton proposed an alternative to convnets in the form of the \\ntransforming autoencoder. The transforming autoencoder offers accuracy improvements on learning tasks that require a high level of precision (such as facial recognition), where pooling operations would cause a reduction in precision. The Further reading  section of this chapter contains recommendations if you are interested \\nin learning more about the transforming autoencoder.\\nSo, we've spent quite a bit of time digging into the convolutional neural network—its \\ncomponents, how they work, and their hyperparameters. Before we move on to put\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 109}),\n",
              " Document(page_content=\"the theory into action, it's worth discussing how all of these theoretical components fit together into a working architecture. To do this, let's discuss what training a convnet looks like.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 109}),\n",
              " Document(page_content='Convolutional Neural Networks[ 88 ]Training a convnet\\nThe means of training a convolutional network will be familiar to readers of the \\npreceding chapters. The convolutional architecture itself is used to pretrain a simpler \\nnetwork structure (for example, an MLP). The backpropagation algorithm is the standard method to compute the gradient when pretraining. During this process, every layer undertakes three tasks:\\n• Forward pass: Each feature map is computed as a sum of all feature maps convolved with the corresponding weight kernel\\n• Backward pass : The gradients respective to inputs are calculated by \\nconvolving the transposed weight kernel with the gradients, with respect to \\nthe outputs', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 110}),\n",
              " Document(page_content='• The loss for each kernel is calculated, enabling the individual weight adjustment of every kernel as needed\\nRepetition of this process allows us to achieve increasing kernel performance until \\nwe reach a point of convergence. At this point, we will hope to have developed a  set of features sufficient that the capping network is able to effectively classify over these features.\\nThis process can execute slowly, even on a fairly advanced GPU. Some recent \\ndevelopments have helped accelerate the training process, including the use of the Fast Fourier Transform  to accelerate the convolution process (for cases where the \\nconvolution kernel is of roughly equal size to the input image).\\nPutting it all together', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 110}),\n",
              " Document(page_content=\"So far, we've discussed some of the elements required to create a CNN. The next subject of discussion  should be how we go about combining these components to \\ncreate capable convolutional nets as well as which combinations of components can work well. We'll draw guidance from a number of forerunning convnet implementations as we build an understanding of what is commonly done  \\nas well as what is possible.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 110}),\n",
              " Document(page_content=\"Chapter 4[ 89 ]Probably the best-known convolutional network implementation is Yann LeCun's \\nLeNet. LeNet has gone through several iterations since LeNet-1 in late 1980, but has been increasingly effective at performing tasks including handwritten digit and image classification. LeNet is structured using alternating convolution and pooling layers capped by an MLP, as follows:\\nEach layer is partially-connected, as we discussed earlier, with the MLP being a fully connected layer. At each layer, multiple feature maps (channels) are employed; this gives us the advantage of being able to create more complex sets of filters. As we'll see, using multiple channels within a layer is a powerful technique employed in advanced use cases.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 111}),\n",
              " Document(page_content=\"It's common to use max-pooling layers to reduce the dimensionality of the output \\nto match the input as well as generally manage output volumes. How pooling is implemented, particularly in regard to the relative position of convolutional and pooling layers, is an element that tends to vary between implementations. It's generally common to develop a layer as a set of operations that feed into, and are fed into, a single Fully Connected layer, as shown in the following example:\\nFully Connected\\nPrevious Layer1x1 Convolutions\\n3x3 Convolutions 5x5 Convolutions 3x3 Max P ooling\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 111}),\n",
              " Document(page_content=\"Convolutional Neural Networks[ 90 ]While this network structure wouldn't work in practice, it's a helpful illustration of \\nthe fact that a network can be constructed from the components you've learned about in a number of ways. How this network is structured and how complex it becomes should be motivated by the challenge the network is intended to solve. Different problems can call for very different solutions.\\nIn the case of the LeNet implementation that we'll be working with later in  \\nthis chapter, each layer contains multiple convolutional layers in parallel with a \\nmax-pooling layer following each. Diagrammatically, a LeNet layer looks like the \\nfollowing image:\\nFully Connected\\nPrevious Layer4x4 Convolutions2x2 Max P ooling 2x2 Max P ooling 2x2 Max P ooling\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 112}),\n",
              " Document(page_content=\"4x4 Convolutions 4x4 Convolutions\\nThis architecture will enable us to start looking at some initial use cases quickly and \\neasily, but in general won't perform well for some of the state-of-the-art applications we'll run into later in this book. Given this fact, there are some more extensive deep learning architectures designed to tackle the most challenging problems, whose topologies are worth discussing. One of the best-known convnet architectures is Google's Inception network, now more commonly known as GoogLeNet.\\nGoogLeNet was designed to tackle computer vision challenges involving  \\nInternet-quality image data, that is, images that have been captured in real  \\ncontexts where the pose, lighting, occlusion, and clutter of images vary significantly.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 112}),\n",
              " Document(page_content='GoogLeNet was applied to the 2014 ImageNet challenge with noteworthy success, achieving only 6.7% error rate on the test dataset. ImageNet images are small,  high-granularity images taken from many, varied classes. Multiple classes may appear very similar (such as varieties of tree) and the network architecture must  be able to find increasingly challenging class distinctions to succeed. For a concrete example, consider the following ImageNet image:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 112}),\n",
              " Document(page_content=\"Chapter 4[ 91 ]\\nGiven the demands of this problem, the GoogLeNet architecture used to win ImageNet \\n14 departs from the LeNet model in several key ways. GoogLeNet's basic layer design is known as the Inception module and is made up of the following components:\\nDepth Concat\\n1x1 Convolutions 1x1 Convolutions 1x1 Convolutions1x1 Convolutions 5x5 Convolutions 3x3 Convolutions\\n3x3 Max P ooling\\nPrevious Layer\\nThe 1 x 1 convolutional layers used here are followed by Rectified Linear Units\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 113}),\n",
              " Document(page_content='(ReLU). This approach is heavily used in speech and audio modeling contexts as ReLU can be used to effectively train deep models without pretraining and without facing some of the gradient vanishing problems that challenge other activation types. More information on ReLU is provided in the Further reading  section of this chapter. \\nThe DepthConcat element provides a concatenation function, which consolidates the outputs of multiple units and substantially improves training time.\\nGoogLeNet chains layers of this type to create a full network. Indeed, the repetition \\nof inception modules through GoogLeNet (nine times!) suggests that Network In Network ( NIN) (deep architectures created from chained network modules)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 113}),\n",
              " Document(page_content='approaches are going to continue to be a serious contender in deep learning circles. The paper describing GoogLeNet and demonstrating how inception models were integrated into the network is provided in the Further reading section of this chapter.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 113}),\n",
              " Document(page_content='Convolutional Neural Networks[ 92 ]Beyond the regularity of Inception module stacking, GoogLeNet has a few further \\nsurprises to throw at us. The first few layers are typically more straightforward with single-channel convolutional and max-pooling layers used at first. Additionally, at several points, GoogLeNet introduced a branch off the main structure using an average-pool layer, feeding into auxiliary softmax classifiers. The purpose of these classifiers was to improve the gradient signal that gets propagated back in lower layers of the network, enabling stronger performance at the early and middle network layers. Instead of one huge and potentially vague backpropagation process stemming from the final layer of the network, GoogLeNet instead has several intermediary update sources.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 114}),\n",
              " Document(page_content=\"What's really important to take from this implementation is that GoogLeNet and \\nother top convnet architectures are mainly successful because they are able to find effective configurations using the highly available components that we've discussed in this chapter. Now that we've had a chance to discuss the architecture and components of a convolutional net and the opportunity to discuss how these components are used to construct some highly advanced networks, it's time to apply the techniques to solve a problem of our own!\\nApplying a CNN\\nWe'll be working with image data to try out our convnet. The image data that we\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 114}),\n",
              " Document(page_content=\"worked with in earlier chapters, including the MNIST digit dataset, was a useful training dataset (with many valuable real-world applications such as automated check reading!). However, it differs from almost all photographic or video data in an important way; most visual data is highly noisy.\\nProblem variables can include pose, lighting, occlusion, and clutter, which may \\nbe expressed independently or in conjunction in huge variety. This means that the task of creating a function that is invariant to all properties of noise in the dataset is challenging; the function is typically very complex and nonlinear. In Chapter 7, Feature Engineering Part II , we'll discuss how techniques such as whitening can\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 114}),\n",
              " Document(page_content=\"help mitigate some of these challenges, but as we'll see, even such techniques by themselves are insufficient to yield good classification (at least, without a very large investment of time!). By far, the most efficient solution to the problem of noise in image data, as we've already seen in multiple contexts, is to use a deep architecture rather than a broad one (that is, a neural network with few, high-dimensional layers, which is vulnerable to problematic overfitting and generalizability problems).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 114}),\n",
              " Document(page_content=\"Chapter 4[ 93 ]From discussions in previous chapters, the reasons for a deep architecture may \\nalready be clear; successive layers of a deep architecture reuse the reasoning and computation performed in preceding layers. Deep architectures can thus build a representation that is sequentially improved by successive layers of the network without performing extensive recalculation on any individual layer. This makes the challenging task of classifying large datasets of noisy photograph data achievable to a high level of accuracy in a relatively short time, without extensive feature engineering.\\nNow that we've discussed the challenges of modeling image data and advantages \\nof a deep architecture in such contexts, let's apply a convnet to a real-world classification problem.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 115}),\n",
              " Document(page_content=\"As in preceding chapters, we're going to start out with a toy example, which we'll \\nuse to familiarize ourselves with the architecture of our deep network. This time, \\nwe're going to take on a classic image processing challenge, CIFAR-10. CIFAR-10 is \\na dataset of 60,000 32 x 32 color images in 10 classes, with each class containing 6,000 \\nimages. The data is already split into five training batches, with one test batch. The classes and some images from each dataset are as follows:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 115}),\n",
              " Document(page_content=\"Convolutional Neural Networks[ 94 ]While the industry has—to an extent—moved on to tackle other datasets such \\nas ImageNet, CIFAR-10 was long regarded as the bar to reach in terms of image classification, with a great many data scientists attempting to create architectures that classify the dataset to human levels of accuracy, where human error rate is estimated at around 6%.\\nIn November 2014, Kaggle ran a contest whose objective was to classify CIFAR-10 \\nas accurately as possible. This contest's highest-scoring entry produced 95.55% \\nclassification accuracy, with the result using convolutional networks and a  \\nNetwork-in-Network approach. We'll discuss the challenge of classifying this \\ndataset, as well as some of the more advanced techniques we can bring to bear,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 116}),\n",
              " Document(page_content=\"in Chapter 8, Ensemble Methods; for now, let's begin by having a go at classification with a convolutional network.\\nFor our first attempt, we'll apply a fairly simple convolutional network with the \\nfollowing objectives:\\n• Applying a filter to the image and view the output\\n• Seeing the weights that our convnet created\\n• Understanding the difference between the outputs of effective and  \\nineffective networks\\nIn this chapter, we're going to take an approach that we haven't taken before, which will be of huge importance to you when you come to use these techniques in the wild. We saw earlier in this chapter how the deep architectures developed to solve \\ndifferent problems may differ structurally in many ways.\\nIt's important to be able to create problem-specific network architectures so that\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 116}),\n",
              " Document(page_content=\"we can adapt our implementation to fit a range of real-world problems. To do this, we'll be constructing our network using components that are modular and can be recombined in almost any way necessary, without too much additional effort. We saw the impact of modularity earlier in this chapter, and it's worth exploring how to apply this effect to our own networks.\\nAs we discussed earlier in the chapter, convnets become particularly powerful \\nwhen tasked to classify very large and varied datasets of up to tens or hundreds of thousands of images. As such, let's be a little ambitious and see whether we can apply a convnet to classify CIFAR-10.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 116}),\n",
              " Document(page_content=\"Chapter 4[ 95 ]In setting up our convolutional network, we'll begin by defining a useable class and \\ninitializing the relevant network parameters, particularly weights and biases. This approach will be familiar to readers of the preceding chapters.\\nclass LeNetConvPoolLayer(object):\\n    def __init__(self, rng, input, filter_shape, image_shape,   \\n    poolsize=(2, 2)):\\n        assert image_shape[1] == filter_shape[1]\\n        self.input = input\\n        fan_in = numpy.prod(filter_shape[1:])\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 117}),\n",
              " Document(page_content=\"fan_out = (filter_shape[0] * numpy.prod(filter_shape[2:])                                                 numpy.prod(poolsize))            W_bound = numpy.sqrt(6. / (fan_in + fan_out))        self.W = theano.shared(            numpy.asarray(                rng.uniform(low=-W_bound, high=W_bound,                 size=filter_shape),                dtype=theano.config.floatX            ),            borrow=True        )\\nBefore moving on to create the biases, it's worth reviewing what we have thus far. \\nThe LeNetConvPoolLayer  class is intended to implement one full convolutional \\nand pooling layer as per the LeNet layer structure. This class contains several useful initial parameters.\\nFrom previous chapters, we're familiar with the \\nrng parameter used to initialize\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 117}),\n",
              " Document(page_content='weights to random values. We can also recognize the input  parameter. As in most \\ncases, image input tends to take the form of a symbolic image tensor. This image \\ninput is shaped by the image_shape  parameter; this is a tuple or list of length 4 \\ndescribing the dimensions of the input. As we move through successive layers, \\nimage_shape  will reduce increasingly. As a tuple, the dimensions of image_shape  \\nsimply specify the height and width of the input. As a list of length 4, the parameters, in order, are as follows:\\n• The batch size\\n• The number of input feature maps\\n• The height of the input image\\n• The width of the input image', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 117}),\n",
              " Document(page_content='Convolutional Neural Networks[ 96 ]While image_shape  specifies the size of the input, filter_shape  specifies the \\ndimensions of the filter. As a list of length 4, the parameters, in order, are as follows:\\n• The number of filters (channels) to be applied\\n• The number of input feature maps\\n• The height of the filter\\n• The width of the filter\\nHowever, the height and width may be entered without any additional parameters. \\nThe final parameter here, poolsize , describes the downsizing factor. This is \\nexpressed as a list of length 2, the first element being the number of rows and the second—the number of columns.\\nHaving defined these values, we immediately apply them to define the \\nLeNetConvPoolLayer  class better. In defining fan_in , we set the inputs to each', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 118}),\n",
              " Document(page_content=\"hidden unit to be a multiple of the number of input feature maps—the filter height \\nand width. Simply enough, we also define fan_out , a gradient that's calculated as \\na multiple of the number of output feature maps—the feature height and width—divided by the pooling size.\\nNext, we move on to defining the bias as a set of one-dimensional tensors, one for \\neach output feature map:\\n        b_values = numpy.zeros((filter_shape[0],),  \\n        dtype=theano.config.floatX)        self.b = theano.shared(value=b_values, borrow=True)\\n        conv_out = conv.conv2d(\\n            input=input,            filters=self.W,            filter_shape=filter_shape,            image_shape=image_shape        )\\nWith this single function call, we've defined a convolution operation that uses the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 118}),\n",
              " Document(page_content='filters we previously defined. At times, it can be a little staggering to see how much theory needs to be known to effectively apply a single function! The next step is to create a similar pooling operation using \\nmax_pool_2d :\\n        pooled_out = downsample.max_pool_2d(\\n            input=conv_out,            ds=poolsize,', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 118}),\n",
              " Document(page_content=\"Chapter 4[ 97 ]            ignore_border=True\\n        )\\n        self.output = T.tanh(pooled_out + self.b.dimshuffle('x', \\n                      0, 'x', 'x'))\\n        self.params = [self.W, self.b]        self.input = input\\nFinally, we add the bias term, first reshaping it to be a tensor of shape ( 1, n_filters , \\n1, 1). This has the simple effect of causing the bias to affect every feature map and \\nminibatch. At this point, we have all of the components we need to build a basic \\nconvnet. Let's move on to create our own network:\\n    x = T.matrix('x')   \\n    y = T.ivector('y') \\nThis process is fairly simple. We build the layers in order, passing parameters to the \\nclass that we previously specified. Let's start by building our first layer:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 119}),\n",
              " Document(page_content=\"layer0_input = x.reshape((batch_size, 1, 32, 32))\\n    layer0 = LeNetConvPoolLayer(\\n        rng,        input=layer0_input,        image_shape=(batch_size, 1, 32, 32),        filter_shape=(nkerns[0], 1, 5, 5),        poolsize=(2, 2)    )\\nWe begin by reshaping the input to spread it across all of the intended minibatches. \\nAs the CIFAR-10 images are of a 32 x 32 dimension, we've used this input size for the height and width dimensions. The filtering process reduces the size of this input to 32- 5+1 in each dimension, or 28. Pooling reduces this by half in each dimension to create an output layer of shape \\n(batch_size, nkerns[0], 14, 14) .\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 119}),\n",
              " Document(page_content=\"Convolutional Neural Networks[ 98 ]This is a completed first layer. Next, we can attach a second layer to this using the \\nsame code:\\n    layer1 = LeNetConvPoolLayer(\\n        rng,\\n        input=layer0.output,\\n        image_shape=(batch_size, nkerns[0], 14, 14),        filter_shape=(nkerns[1], nkerns[0], 5, 5),        poolsize=(2, 2)    )\\nAs per the previous layer, the output shape for this layer is ( batch_size, \\nnkerns[1], 5, 5) . So far, so good! Let's feed this output to the next, fully-connected \\nsigmoid layer. To begin with, we need to flatten the input shape to two dimensions. \\nWith the values that we've fed to the network so far, the input will be a matrix of shape (500, 1250). As such, we'll set up an appropriate \\nlayer2 :\\n    layer2_input = layer1.output.flatten(2)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 120}),\n",
              " Document(page_content=\"layer2 = HiddenLayer(\\n        rng,        input=layer2_input,        n_in=nkerns[1] * 5 * 5        n_out=500,        activation=T.tanh    )\\nThis leaves us in a good place to finish this network's architecture, by adding a final, \\nlogistic regression layer that calculates the values of the fully-connected sigmoid layer.\\nLet's try out this code:\\n    x = T.matrix(CIFAR-10_train)   \\n    y = T.ivector(CIFAR-10_test)\\nChapter_4/convolutional_mlp.py\\nThe results that we obtained were as follows:\\nOptimization complete.\\nBest validation score of 0.885725 % obtained at iteration 17400, with \\ntest performance 0.902508 %\\nThe code for file convolutional_mlp.py ran for 26.50m\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 120}),\n",
              " Document(page_content=\"Chapter 4[ 99 ]This accuracy score, at validation, is reasonably good. It's not at a human level of \\naccuracy, which, as we established, is roughly 94%. Equally, it is not the best score that we could achieve with a convnet.\\nFor instance, the Further Reading section of this chapter refers to a convnet \\nimplemented in Torch using a combination of dropout (which we studied in  \\nChapter 3, Stacked Denoising Autoencoders ) and Batch Normalization (a normalization \\ntechnique intended to reduce covariate drift during the training process; refer to the \\nFurther Reading section for further technical notes and papers on this technique), \\nwhich scored 92.45% validation accuracy.\\nA score of 88.57% is, however, in the same ballpark and can give us confidence that\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 121}),\n",
              " Document(page_content=\"we're within striking distance of an effective network architecture for the CIFAR-10 \\nproblem. More importantly, you've learned a lot about how to configure and train a \\nconvolutional neural network effectively.\\nFurther Reading\\nThe glut of recent interest in Convolutional Networks means that we're spoiled for choice for further reading. One good option for an unfamiliar reader is the course notes from Andrej Karpathy's course: \\nhttp://cs231n.github.io/convolutional-\\nnetworks/ .\\nFor readers with an interest in the deeper details of specific best-in-class implementations, some of the networks referenced in this chapter were the following:\\nGoogle's GoogLeNet (\\nhttp://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf )\\nGoogle Deepmind's Go-playing program AlphaGo ( https://gogameguru.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 121}),\n",
              " Document(page_content=\"com/i/2016/03/deepmind-mastering-go.pdf )\\nFacebook's DeepFace architecture for facial recognition ( https://www.cs.toronto.\\nedu/~ranzato/publications/taigman_cvpr14.pdf ) \\nThe ImageNet LSVRC-2010 contest winning network, described here by Krizhevsky, \\nSutskever and Hinton ( http://www.cs.toronto.edu/~fritz/absps/imagenet.\\npdf) \\nFinally, Sergey Zagoruyko's Torch implementation of a ConvNet with Batch normalization is available here: \\nhttp://torch.ch/blog/2015/07/30/cifar.html .\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 121}),\n",
              " Document(page_content='Convolutional Neural Networks[ 100 ]Summary\\nIn this chapter, we covered a lot of ground. We began by introducing a new kind of \\nneural network, the convnet. We explored the theory and architecture of a convnet in the most ubiquitous form and also by discussing some state-of the-art network design principles that have been developing as recently as mid-2015 in organizations such as Google and Baidu. We built an understanding of the topology and also of how the network operates.\\nFollowing this, we began to work with the convnet itself, applying it to the CIFAR-10', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 122}),\n",
              " Document(page_content=\"dataset. We used modular convnet code to create a functional architecture that reached a reasonable level of accuracy in classifying 10-class image data. While we're definitely still at some distance from human levels of accuracy, we're gradually closing the gap! Chapter 8, Ensemble Methods will pick up from what you learned here, taking these techniques and their application to the next level.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 122}),\n",
              " Document(page_content=\"[ 101 ]Semi-Supervised Learning\\nIntroduction\\nIn previous chapters, we've tackled a range of data challenges using advanced \\ntechniques. In each case, we've applied our techniques to datasets with reasonable success.\\nIn many regards, though, we've had it pretty easy. Our data has been largely derived\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 123}),\n",
              " Document(page_content=\"from canonical and well-prepared sources so we haven't had to do a great deal of preparation. In the real world, though, there are few datasets like this (except, perhaps, the ones that we're able to specify ourselves!). In particular, it is rare and improbable to come across a dataset in the wild, which has class labels available. Without labels on a sufficient portion of the dataset, we find ourselves unable to build a classifier that can accurately predict labels on validation or test data. So, what do we do?\\nThe common solution is attempt to tag our data manually; not only is this  \\ntime-consuming, but it also suffers from certain types of human error (which are\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 123}),\n",
              " Document(page_content='especially common with high-dimensional datasets, where a human observer is unable to identify class boundaries as well as a computational approach might).\\nA fairly new and quite exciting alternative approach is to use semi-supervised \\nlearning to apply labels to unlabeled data via capturing the shape of underlying \\ndistributions. Semi-supervised learning has been growing in popularity over the last decade for its ability to save large amounts of annotation time, where annotation, if possible, may potentially require human expertise or specialist equipment. Contexts where this has proven to be particularly valuable have been natural language parsing and speech signal analysis; in both areas, manual annotation has proven to be complex and time-consuming.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 123}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 102 ]In this chapter, you're going to learn how to apply several semi-supervised learning \\ntechniques, including, Contrastive Pessimistic Likelihood Estimation  (CPLE), \\nself learning, and S3VM. These techniques will enable us to label training data in \\na range of otherwise problematic contexts. You'll learn to identify the capabilities and limitations of semi-supervised techniques. We'll use a number of recent Python libraries developed on top of scikit-learn to apply semi-supervised techniques to several use cases, including audio signal data.\\nLet's get started!\\nUnderstanding semi-supervised learning\\nThe most persistent cost in performing machine learning is the creation of tagged\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 124}),\n",
              " Document(page_content='data for training purposes. Datasets tend not to come with class labels provided due to the circularity of the situation; one needs a trained classification technique to generate class labels, but cannot train the technique without labeled training and test data. As mentioned, tagging data manually or via test processes is one option, but this can be prohibitively time-consuming, costly (particularly for medical tests), challenging to organize, and prone to error (with large or complex datasets). Semi-supervised techniques suggest a better way to break this deadlock.\\nSemi-supervised learning techniques use both unlabeled and labeled data to create', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 124}),\n",
              " Document(page_content='better learning techniques than can be created with either unlabeled or labeled data individually. There is a family of techniques that exists in a space between supervised (with labeled data) and unsupervised (with unlabeled data) learning.\\nThe main types of technique that exist in this group are semi-supervised techniques, \\ntransductive techniques, and active learning techniques, as well as a broad set of other methods.\\nSemi-supervised techniques leave a set of test data out of the training process so as \\nto perform testing at a later stage. Transductive techniques, meanwhile, are purely intended to develop labels for unlabeled data. There may not be a test process embedded in a transductive technique and there may not be labeled data available for use.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 124}),\n",
              " Document(page_content=\"Chapter 5[ 103 ]In this chapter, we'll focus on a set of semi-supervised techniques that deliver powerful \\ndataset labeling capability in very familiar formats. A lot of the techniques that we'll be discussing are useable as wrappers around familiar, pre-existing classifiers, from linear regression classifiers to SVMs. As such, many of them can be run using estimators from Scikit-learn. We'll begin by applying a linear regression classifier to test cases before moving on to apply an SVM with semi-supervised extensions.\\nSemi-supervised algorithms in action\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 125}),\n",
              " Document(page_content=\"We've discussed what semi-supervised learning is, why we want to engage in it, and what some of the general realities of employing semi-supervised algorithms are. We've gone about as far as we can with general descriptions. Over the next few pages, we'll move from this general understanding to develop an ability to use a semi-supervised application effectively.\\nSelf-training\\nSelf-training is the simplest semi-supervised learning method and can also be the fastest. Self-training algorithms see an application in multiple contexts, including NLP and computer vision; as we'll see, they can present both substantial value and significant risks.\\nThe objective of self-training is to combine information from unlabeled cases\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 125}),\n",
              " Document(page_content=\"with that of labeled cases to iteratively identify labels for the dataset's unlabeled \\nexamples. On each iteration, the labeled training set is enlarged until the entire dataset is labeled.\\nThe self-training algorithm is typically applied as a wrapper to a base model. In  \\nthis chapter, we'll be using an SVM as the base for our self-training model. The  \\nself-training algorithm is quite simple and contains very few steps, as follows:\\n1. A set of labeled data is used to predict labels for a set of unlabeled data.  \\n(This may be all unlabeled data or part of it.)\\n2. Confidence is calculated for all newly labeled cases.\\n3. Cases are selected from the newly labeled data to be kept for the next iteration.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 125}),\n",
              " Document(page_content='Semi-Supervised Learning[ 104 ]4. The model trains on all labeled cases, including cases selected in  \\nprevious iterations.\\n5. The model iterates through steps 1 to 4 until it successfully converges.\\nPresented graphically, this process looks as follows:\\nUnlabelled Cases Labelled Cases\\nBase Model\\nModel trained\\nusing labelled\\ndata\\nUnlabelled Cases Labelled Cases\\nConfidence\\nthreshold =0.80.46\\n0.74\\n0.4\\n0.560.820.90Base Model\\nUnlabelled Cases Labelled Cases\\nBase Model\\nModel trained\\nusing labelled\\ndata\\nUnlabelled Cases Labelled Cases\\nConfidence\\nthreshold =0.8Base Model\\n0.810.73\\n0.68\\n0.76', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 126}),\n",
              " Document(page_content=\"Chapter 5[ 105 ]Upon completing training, the self-trained model would be tested and validated. \\nThis may be done via cross-validation or even using held-out, labeled data, should this exist.\\nSelf-training provides real power and time saving, but is also a risky process. In \\norder to understand what to look out for and how to apply self-training to your own classification algorithms, let's look in more detail at how the algorithm works.\\nTo support this discussion, we're going to work with code from the semisup-learn \\nGitHub repository. In order to use this code, we'll need to clone the relevant GitHub \\nrepository. Instructions for this are located in Appendix A.\\nImplementing self-training\\nThe first step in each iteration of self-training is one in which class labels\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 127}),\n",
              " Document(page_content=\"are generated for unlabeled cases. This is achieved by first creating a \\nSelfLearningModel  class, which takes a base supervised model ( basemodel ) and \\nan iteration limit as arguments. As we'll see later in this chapter, an iteration limit can be explicitly specified or provided as a function of classification accuracy (that is, convergence). The \\nprob_threshold  parameter provides a minimum quality bar \\nfor label acceptance; any projected label that scores at less than this level will be rejected. Again, we'll see in later examples that there are alternatives to providing a hardcoded threshold value.\\nclass SelfLearningModel(BaseEstimator): \\n \\n       \\ndef __init__(self, basemodel, max_iter = 200, prob_threshold = 0.8):\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 127}),\n",
              " Document(page_content='self.model = basemodel    self.max_iter = max_iter    self.prob_threshold = prob_threshold  \\nHaving defined the shell of the SelfLearningModel  class, the next step is to define \\nfunctions for the process of semi-supervised model fitting:\\ndef fit(self, X, y):    unlabeledX = X[y==-1, :]    labeledX = X[y!=-1, :]    labeledy = y[y!=-1]       self.model.fit(labeledX, labeledy)    unlabeledy = self.predict(unlabeledX)    unlabeledprob = self.predict_proba(unlabeledX)   unlabeledy_old = [] \\n   i = 0', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 127}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 106 ]The X parameter is a matrix of input data, whose shape is equivalent to [n_samples, \\nn_features] . X is used to create a matrix of [n_samples, n_samples]  size. The y \\nparameter, meanwhile, is an array of labels. Unlabeled points are marked as -1 in \\ny. From X, the unlabeledX  and labeledX  parameters are created quite simply by \\noperations over X that select elements in X whose position corresponds to a -1 label \\nin y. The labeledy  parameter performs a similar selection over y. (Naturally, we're \\nnot that interested in the unlabeled samples of y as a variable, but we need the labels \\nthat do exist for classification attempts!)\\nThe actual process of label prediction is achieved, first, using sklearn's predict\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 128}),\n",
              " Document(page_content=\"operation. The unlabeledy  parameter is generated using sklearn's predict  method, \\nwhile the predict_proba  method is used to calculate probabilities for each projected \\nlabel. These probabilities are stored in unlabeledprob .\\nScikit-learn's predict and predict_proba methods work to predict class labels and the probability of class labeling being correct, respectively. As we'll be applying both of these methods within several of our semi-supervised algorithms, it's informative to understand how they actually work.\\nThe predict method produces class predictions for input data. It \\ndoes so via a set of binary classifiers (that is, classifiers that attempt to differentiate only two classes). A full model with n-many classes contains a set of binary classifiers as follows:\\n( )1\\n2n n∗ −\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 128}),\n",
              " Document(page_content=\"Chapter 5[ 107 ]In order to make a prediction for a given case, all classifiers whose scores \\nexceed zero, vote for a class label to apply to that case. The class with the most votes (and not, say, the highest sum classifier score) is identified. This is referred to as a one-versus-one prediction method and is a fairly common approach.\\nMeanwhile, predict_proba works by invoking Platt calibration, \\na technique that allows the outputs of a classification model to be \\ntransformed into a probability distribution over the classes. This involves \\nfirst training the base model in question, fitting a regression model to the \\nclassifier's scores:\\n( )( ) ( ) ( )1|\\n1 e xpP y X\\nA f X B=\\n+ ∗ +\\nThis model can then be optimized (through scalar parameters A and\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 129}),\n",
              " Document(page_content=\"B) using a maximum likelihood method. In the case of our self-training \\nmodel, predict_proba allows us to fit a regression model to the classifier's scores and thus calculate probabilities for each class label. This is extremely helpful!\\nNext, we need a loop for iteration. The following code describes a while  loop that \\nexecutes until there are no cases left in unlabeledy_old  (a copy of unlabeledy ) or \\nuntil the max iteration count is reached. On each iteration, a labeling attempt is made for each case that does not have a label whose probability exceeds the probability threshold (\\nprob_threshold ):\\n   while (len(unlabeledy_old) == 0 or\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 129}),\n",
              " Document(page_content='numpy.any(unlabeledy!=unlabeledy_old)) and i < self.max_iter:       unlabeledy_old = numpy.copy(unlabeledy)       uidx = numpy.where((unlabeledprob[:, 0] > self.prob_threshold)          | (unlabeledprob[:, 1] > self.prob_threshold))[0] \\nThe self.model.fit  method then attempts to fit a model to the unlabeled data. \\nThis unlabeled data is presented in a matrix of size [n_samples, n_samples]  (as \\nreferred to earlier in this chapter). This matrix is created by appending (with vstack  \\nand hstack ) the unlabeled cases:\\n      self.model.fit(numpy.vstack((labeledX, unlabeledX[uidx, :])),           numpy.hstack((labeledy, unlabeledy_old[uidx])))', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 129}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 108 ]Finally, the iteration performs label predictions, followed by probability predictions \\nfor those labels.\\n      unlabeledy = self.predict(unlabeledX) \\n      unlabeledprob = self.predict_proba(unlabeledX) \\n      i += 1 \\nOn the next iteration, the model will perform the same process, this time taking the \\nnewly labeled data whose probability predictions exceeded the threshold as part of the dataset used in the \\nmodel.fit  step.\\nIf one's model does not already include a classification method that can generate \\nlabel predictions (like the predict_proba  method available in sklearn's SVM \\nimplementation), it is possible to introduce one. The following code checks for the \\npredict_proba  method and introduces Platt scaling  of generated labels if this\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 130}),\n",
              " Document(page_content='method is not found:\\nif not getattr(self.model, \"predict_proba\", None): \\n   self.plattlr = LR()    preds = self.model.predict(labeledX)    self.plattlr.fit( preds.reshape( -1, 1 ), labeledy ) \\nreturn self\\ndef predict_proba(self, X): \\n         if getattr(self.model, \"predict_proba\", None):          return self.model.predict_proba(X)          else:             preds = self.model.predict(X)             return self.plattlr.predict_proba(preds.reshape( -1, 1 ))\\nOnce we have this much in place, we can begin applying our self-training \\narchitecture. To do so, let\\'s grab a dataset and start working!\\nFor this example, we\\'ll use a simple linear regression classifier, with Stochastic \\nGradient Descent  (SGD) as our learning component as our base model ( basemodel ).', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 130}),\n",
              " Document(page_content='The input dataset will be the statlog heart  dataset, obtained from www.mldata.org . \\nThis dataset is provided in the GitHub repository accompanying this chapter.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 130}),\n",
              " Document(page_content='Chapter 5[ 109 ]The heart  dataset is a two-class dataset, where the classes are the absence or \\npresence of a heart disease. There are no missing values across the 270 cases for \\nany of its 13 features. This data is unlabeled and many of the variables needed are usually captured via expensive and sometimes inconvenient tests. The variables are as follows:\\n• \\nage\\n• sex\\n• chest pain type (4 values)\\n• resting blood pressure\\n• serum cholestoral in mg/dl\\n• fasting blood sugar > 120 mg/dl\\n• resting electrocardiographic results (values 0,1,2)\\n• maximum heart rate achieved\\n• exercise induced angina\\n• 10. oldpeak = ST depression induced by exercise relative to \\nrest\\n• the slope of the peak exercise ST segment\\n• number of major vessels (0-3) colored by flourosopy', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 131}),\n",
              " Document(page_content='• thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\\nLets get started with the Heart  dataset by loading in the data, then fitting a model  \\nto it:\\nheart = fetch_mldata(\"heart\")\\nX = heart.dataytrue = np.copy(heart.target)ytrue[ytrue==-1]=0\\nlabeled_N = 2\\nys = np.array([-1]*len(ytrue)) # -1 denotes unlabeled point\\nrandom_labeled_points = random.sample(np.where(ytrue == 0)[0], \\nlabeled_N/2)+\\\\random.sample(np.where(ytrue == 1)[0], labeled_N/2)\\nys[random_labeled_points] = ytrue[random_labeled_points]\\nbasemodel = SGDClassifier(loss=\\'log\\', penalty=\\'l1\\') \\nbasemodel.fit(X[random_labeled_points, :], ys[random_labeled_points])\\nprint \"supervised log.reg. score\", basemodel.score(X, ytrue)\\nssmodel = SelfLearningModel(basemodel)\\nssmodel.fit(X, ys)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 131}),\n",
              " Document(page_content='print \"self-learning log.reg. score\", ssmodel.score(X, ytrue)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 131}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 110 ]Attempting this yields moderate, but not excellent, results:\\nself-learning log.reg. score 0.470347\\nHowever, over 1,000 trials, we find that the quality of our outputs is quite variant:\\nGiven that we're looking at classification accuracy scores for sets of real-world and \\nunlabeled data, this isn't a terrible result, but I don't think we should be satisfied \\nwith it. We're still labeling more than half of our cases incorrectly!\\nWe need to understand the problem a little better; right now, it isn't clear what's \\ngoing wrong or how we can improve on our results. Let's figure this out by returning to the theory around self-training to understand how we can diagnose and improve our implementation.\\nFinessing your self-training implementation\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 132}),\n",
              " Document(page_content='In the previous section, we discussed the creation of self-training algorithms and tried out an implementation. However, what we saw during our first trial was that our results, while demonstrating the potential of self-training, left room for growth. Both the accuracy and variance of our results were questionable.\\nSelf-training can be a fragile process. If an element of the algorithm is ill-configured \\nor the input data contains peculiarities, it is very likely that the iterative process will fail once and continue to compound that error by reintroducing incorrectly labeled data to future labeling steps. As the self-training algorithm iteratively feeds itself, \\ngarbage in, garbage out is a very real concern.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 132}),\n",
              " Document(page_content=\"Chapter 5[ 111 ]There are several quite common flavors of risk that should be called out. In some \\ncases, labeled data may not add more useful information. This is particularly common in the first few iterations, and understandably so! In general, unlabeled cases that are most easily labeled are the ones that are most similar to existing labeled cases. However, while it's easy to generate high-probability labels for these cases, there's no guarantee that their addition to the labeled set will make it easier to label during subsequent iterations.\\nUnfortunately, this can sometimes lead to a situation in which cases are being added \\nthat have no real effect on classification while classification accuracy in general\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 133}),\n",
              " Document(page_content=\"deteriorates. Even worse, adding cases that are similar to pre-existing cases in enough respects to make them easy to label, but that actually misguide the classifier's decision boundary, can introduce misclassification increases.\\nDiagnosing what went wrong with a self-training model can sometimes be difficult, \\nbut as always, a few well-chosen plots add a lot of clarity to the situation. As this \\ntype of error occurs particularly often within the first few iterations, simply adding \\nan element to the label prediction loop that writes the current classification accuracy allows us to understand how accuracy trended during early iterations.\\nOnce the issue has been identified, there are a few possible solutions. If enough\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 133}),\n",
              " Document(page_content=\"labeled data exists, a simple solution is to attempt to use a more diverse set of labeled data to kick-start the process.\\nWhile the impulse might be to use all of the labeled data, we'll see later in this \\nchapter that self-training models are vulnerable to overfitting—a risk that forces us to hold on to some data for validation purposes. A promising option is to use multiple subsets of our dataset to train multiple self-training model instances. Doing so, particularly over several trials, can help us understand the impact of our input data on our self-training models performance.\\nIn Chapter 8, Ensemble Methods, we'll explore some options around ensembles that \\nwill enable us to use multiple self-training models together to yield predictions.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 133}),\n",
              " Document(page_content=\"When ensembling is accessible to us, we can even consider applying multiple sampling techniques in parallel.\\nIf we don't want to solve this problem with quantity, though, perhaps we can \\nsolve it by improving quality. One solution is to create an appropriately diverse subset of the labeled data through selection. There isn't a hard limit on the number of labeled cases that works well as a minimum amount to start up a self-training implementation. While you could hypothetically start working with even one labeled case per class (as we did in our preceding training example), it'll quickly become obvious that training against a more diverse and overlapping set of classes benefits from more labeled data.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 133}),\n",
              " Document(page_content='Semi-Supervised Learning[ 112 ]Another class of error that a self-training model is particularly vulnerable to is \\nbiased selection. Our naïve assumption is that the selection of data during each iteration is, at worst, only slightly biased (favoring one class only slightly more than others). The reality is that this is not a safe assumption. There are several factors that can influence the likelihood of biased selection, with the most likely culprit being disproportionate sampling from one class.\\nIf the dataset as a whole, or the labeled subsets used, are biased toward one class, \\nthen the risk increases that your self-training classifier will overfit. This only \\ncompounds the problem as the cases provided for the next iteration are liable to be', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 134}),\n",
              " Document(page_content=\"insufficiently diverse to solve the problem; whatever incorrect decision boundary was set up by the self-training algorithm will be set where it is—overfit to a subset of the data. Numerical disparity between each class' count of cases is the main symptom here, but the more usual methods to spot overfitting can also be helpful in diagnosing problems around selection bias.\\nThis reference to the usual methods of spotting overfitting is worth expanding on because techniques to identify overfitting are highly valuable! These techniques are typically referred to as validation techniques. The fundamental concept underpinning validation techniques is that one has two sets of data—one that is used to build a model, and the other is used to test it.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 134}),\n",
              " Document(page_content=\"The most effective validation technique is independent validation, the \\nsimplest form of which involves waiting to determine whether predictions are accurate. This obviously isn't always (or even, often) possible!\\nGiven that it may not be possible to perform independent validation, the \\nbest bet is to hold out a subset of your sample. This is referred to as sample \\nsplitting and is the foundation of modern validation techniques. Most \\nmachine learning implementations refer to training, test, and validation \\ndatasets; this is a case of multilayered validation in action.\\nA third and critical validation tool is resampling, where subsets of the \\ndata are iteratively used to repeatedly validate the dataset. In Chapter 1,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 134}),\n",
              " Document(page_content=\"Unsupervised Machine Learning , we saw the use of v-fold cross-validation; \\ncross-validation techniques are perhaps the best examples of resampling in action.\\nBeyond applicable techniques, it's a good idea to be mindful of the needed \\nsample size required for the effective modeling of your data. There are no universal principles here, but I always rather liked the following rule of thumb:\\nIf m points are required to determine a univariate regression line with \\nsufficient precision, then it will take at least mn observations and perhaps \\nn!mn observations to appropriately characterize and evaluate a regression model with n variables.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 134}),\n",
              " Document(page_content='Chapter 5[ 113 ]Note that there is some tension between the suggested solutions to this problem \\n(resampling, sample splitting, and validation techniques including cross-validation) and the preceding one. Namely, overfitting requires a more restrained use of subsets of the labeled training data, while bad starts are less likely to occur using more training data. For each specific problem, depending on the complexity of the data under analysis, there will be an appropriate balance to strike. By monitoring for signs of either type of problem, the appropriate action (whether that is an increase or decrease in the amount of labeled data used simultaneously in an iteration) can be taken at the right  time.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 135}),\n",
              " Document(page_content=\"A further class of risk introduced by self-training is that the introduction of unlabeled data almost always introduces noise. If dealing with datasets where part or all of the unlabeled cases are highly noisy, the amount of noise introduced may be sufficient to degrade classification accuracy.\\nThe idea of using data complexity and noise measures to understand the degree of noise in one's dataset is not new. Fortunately for us, quite a lot of good estimators already exist that we can take advantage of.\\nThere are two main groups of relative complexity measures. Some\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 135}),\n",
              " Document(page_content=\"attempt to measure the overlap of values of different classes, or separability; measures in this group attempt to describe the degree of ambiguity of each class relative to the other classes. One good measure for such cases is the maximum Fisher's discriminant ratio, though maximum \\nindividual feature efficiency is also effective.\\nAlternatively (and sometimes more simply), one can use the error\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 135}),\n",
              " Document(page_content=\"function of a linear classifier to understand how separable the dataset's classes are from one another. By attempting to train a simple linear classifier on your dataset and observing the training error, one can immediately get a good understanding as to how linearly separable the classes are. Furthermore, measures related to this classifier (such as the fraction of points in the class boundary or the ratio of average intra/inter class nearest neighbor distance) can also be extremely helpful.\\nThere are other data complexity measures that specifically measure the \\ndensity or geometry of the dataset. One good example is the fraction of maximum covering spheres. Again, helpful measures can be accessed by applying a linear classifier and including the nonlinearity of that classifier.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 135}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 114 ]Improving the selection process\\nThe key to the self-training algorithm working correctly is the accurate calculation of \\nconfidence for each label projection. Confidence calculation is the key to successful \\nself-training.\\nDuring our first explanation of self-training, we used some simplistic values for \\ncertain parameters, including a parameter closely tied to confidence calculation.  \\nIn selecting our labeled cases, we used a fixed confidence level for comparison against predicted probabilities, where we could've adopted any one of several different strategies:\\n• Adding all of the projected labels to the set of labeled data\\n• Using a confidence threshold to select only the few most confident labels to \\nthe set\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 136}),\n",
              " Document(page_content=\"• Adding all the projected labels to the labeled dataset and weighing each label \\nby confidence\\nAll in all, we've seen that self-training implementations present quite a lot of risk. They're prone to a number of training failures and are also subject to overfitting. To make matters worse, as the amount of unlabeled data increases, the accuracy of a self-training classifier becomes increasingly at risk.\\nOur next step will be to look at a very different self-training implementation. While \\nconceptually similar to the algorithm that we worked with earlier in this chapter, the next technique we'll be looking at operates under different assumptions to yield very different results.\\nContrastive Pessimistic Likelihood Estimation\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 136}),\n",
              " Document(page_content='In our preceding discovery and application of self-training techniques, we found self-training to be a powerful technique with significant risks. Particularly, we found \\na need for multiple diagnostic tools and some quite restrictive dataset conditions. While we can work around these problems by subsetting, identifying optimal labeled data, and attentively tracking performance for some datasets, some of these actions continue to be impossible for the very data that self-training would bring the most benefit to—data where labeling requires expensive tests, be those medical or scientific, with specialist knowledge and equipment.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 136}),\n",
              " Document(page_content='Chapter 5[ 115 ]In some cases, we end up with some self-training classifiers that are outperformed by \\ntheir supervised counterparts, which is a pretty terrible state of affairs. Even worse, while a supervised classifier with labeled data will tend to improve in accuracy with additional cases, semi-supervised classifier performance can degrade as the dataset size increases. What we need, then, is a less naïve approach to semi-supervised learning. Our goal should be to find an approach that harnesses the benefits of semi-supervised learning while maintaining performance at least comparable with that of the same classifier under a supervised approach.\\nA very recent (May 2015) approach to self-supervised learning, CPLE, provides', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 137}),\n",
              " Document(page_content=\"a more general way to perform semi-supervised parameter estimation. CPLE provides a rather remarkable advantage: it produces label predictions that have been demonstrated to consistently outperform those created by equivalent semi-supervised classifiers or by supervised classifiers working from the labeled data! In other words, when performing a linear discriminant analysis, for instance, it is advised that you perform a CPLE-based, semi-supervised analysis instead of a supervised one, as you will always obtain at least equivalent performance.\\nThis is a pretty big claim and it needs substantiating. Let's start by building an \\nunderstanding of how CPLE works before moving on to demonstrate its superior \\nperformance in real cases.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 137}),\n",
              " Document(page_content=\"CPLE uses the familiar measure of maximized log-likelihood for parameter \\noptimization. This can be thought of as the success condition; the model we'll develop is intended to optimize the  maximized log-likelihood of our model's parameters. It is the specific guarantees and assumptions that CPLE incorporates that make the technique effective.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 137}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 116 ]In order to create a better semi-supervised learner—one that improves on it's \\nsupervised alternative—CPLE takes the supervised estimates into account explicitly, using the loss incurred between the semi-supervised and supervised models as a training performance measure:\\nCPLE calculates the relative improvement of any semi-supervised estimate  \\nover the supervised solution. Where the supervised solution outperforms the  \\nsemi-supervised estimate, the loss function shows this and the model can train to adjust the semi-supervised model to reduce this loss. Where the semi-supervised solution outperforms the supervised solution, the model can learn from the  \\nsemi-supervised model by adjusting model parameters.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 138}),\n",
              " Document(page_content=\"Chapter 5[ 117 ]However, while this sounds excellent so far, there is a flaw in the theory that has \\nto be addressed. The fact that data labels don't exist for a semi-supervised solution means that the posterior distribution (that CPLE would use to calculate loss) is inaccessible. CPLE's solution to this is to be pessimistic. The CPLE algorithm takes the Cartesian product of all label/prediction combinations and then selects the posterior distribution that minimizes the gain in likelihood.\\nIn real-world machine learning contexts, this is a very safe approach. It delivers the \\nclassification accuracy of a supervised approach with semi-supervised performance \\nimprovement derived via conservative assumptions. In real applications, these\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 139}),\n",
              " Document(page_content=\"conservative assumptions enable high performance under testing. Even better, CPLE can deliver particular performance improvements on some of the most challenging unsupervised learning cases, where the labeled data is a poor representation of the unlabeled data (by virtue of poor sampling from one or more classes or just because of a shortage of unlabeled cases).\\nIn order to understand how much more effective CPLE can be than semi-supervised \\nor supervised approaches, let's apply the technique to a practical problem. We'll once again work with the semisup-learn library, a specialist Python library, focused on semi-supervised learning, which extends scikit-learn to provide CPLE across any \\nscikit-learn-provided classifier. We begin with a CPLE class:\\nclass CPLELearningModel(BaseEstimator):\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 139}),\n",
              " Document(page_content=\"def __init__(self, basemodel, pessimistic=True, predict_from_\\nprobabilities = False, use_sample_weighting = True, max_iter=3000, verbose = 1):\\n        self.model = basemodel        self.pessimistic = pessimistic        self.predict_from_probabilities = predict_from_probabilities        self.use_sample_weighting = use_sample_weighting        self.max_iter = max_iter        self.verbose = verbose\\nWe're already familiar with the concept of basemodel . Earlier in this chapter, we \\nemployed S3VMs and semi-supervised LDE's. In this situation, we'll again use an \\nLDE; the goal of this first assay will be to try and exceed the results obtained by the semi-supervised LDE from earlier in this chapter. In fact, we're going to blow those results out of the water!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 139}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 118 ]Before we do so, however, let's review the other parameter options. The \\npessimistic  argument gives us an opportunity to use a non-pessimistic (optimistic) \\nmodel. Instead of following the pessimistic  method of minimizing the loss \\nbetween unlabeled and labeled discriminative likelihood, an optimistic model aims \\nto maximize likelihood. This can yield better results (mostly during training), but is significantly more risky. Here, we'll be working with pessimistic models.\\nThe \\npredict_from_probabilities  parameter enables optimization by allowing \\na prediction to be generated from the probabilities of multiple data points at once. \\nIf we set this as true, our CPLE will set the prediction as 1 if the probability we're\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 140}),\n",
              " Document(page_content=\"using for prediction is greater than the mean, or 0 otherwise. The alternative is to use \\nthe base model probabilities, which is generally preferable for performance reasons, unless we'll be calling \\npredict  across a number of cases.\\nWe also have the option to use_sample_weighting , otherwise known as soft labels \\n(but most familiar to us as posterior probabilities). We would normally take this opportunity, as soft labels enable greater flexibility than hard labels and are generally preferred (unless the model only supports hard class labels).\\nThe first few parameters provide a means of stopping CPLE training, either at \\nmaximum iterations or after log-likelihood stops improving (typically because of convergence). The \\nbestdl  provides the best discriminative likelihood value and\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 140}),\n",
              " Document(page_content='corresponding soft labels; these values are updated on each training iteration:\\n        self.it = 0 \\n        self.noimprovementsince = 0         self.maxnoimprovementsince = 3                 self.buffersize = 200        self.lastdls = [0]*self.buffersize\\n        self.bestdl = numpy.infty\\n        self.bestlbls = []                        self.id = str(unichr(numpy.random.randint(26)+97))+str(unichr(\\nnumpy.random.randint(26)+97))\\nThe discriminative_likelihood  function calculates the likelihood (for \\ndiscriminative models—that is, models that aim to maximize the probability of a target—y = 1, conditional on the input, X) of an input.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 140}),\n",
              " Document(page_content=\"Chapter 5[ 119 ]In this case, it's worth drawing your attention to the distinction \\nbetween generative and discriminative models. While this isn't a basic concept, it can be fundamental in understanding why many classifiers have the goals that they do.\\nA classification model takes input data and attempts to classify cases, \\nassigning each case a label. There is more than one way to do this.\\nOne approach is to take the cases and attempt to draw a decision \\nboundary between them. Then we can take each new case as it \\nappears and identify which side of the boundary it falls on. This is a \\ndiscriminative learning approach.\\nAnother approach is to attempt to model the distribution of each class\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 141}),\n",
              " Document(page_content=\"individually. Once a model has been generated, the algorithm can use Bayes' rule to calculate the posterior distribution on the labels given input data. This approach is generative and is a very powerful approach with significant weaknesses (most of which tie into the question of how well we can model our classes). Generative approaches include Gaussian discriminant models (yes, that is a slightly confusing name) and a broad range of Bayesian models. More information, including some excellent recommended reading, is provided in the Further reading  section of this chapter.\\nIn this case, the function will be used on each iteration to calculate the likelihood of the predicted labels:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 141}),\n",
              " Document(page_content='def discriminative_likelihood(self, model, labeledData, labeledy = None, unlabeledData = None, unlabeledWeights = None, unlabeledlambda = 1, gradient=[], alpha = 0.01):\\n        unlabeledy = (unlabeledWeights[:, 0]<0.5)*1        uweights = numpy.copy(unlabeledWeights[:, 0]) \\n        uweights[unlabeledy==1] = 1-uweights[unlabeledy==1]         weights = numpy.hstack((numpy.ones(len(labeledy)), uweights))\\n        labels = numpy.hstack((labeledy, unlabeledy))\\nHaving defined this much of our CPLE, we also need to define the fitting process \\nfor our supervised model. This uses familiar components, namely, model.fit  and \\nmodel.predict_proba , for probability prediction:\\n        if self.use_sample_weighting:\\n            model.fit(numpy.vstack((labeledData, unlabeledData)),', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 141}),\n",
              " Document(page_content='labels, sample_weight=weights)\\n        else:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 141}),\n",
              " Document(page_content='Semi-Supervised Learning[ 120 ]            model.fit(numpy.vstack((labeledData, unlabeledData)), \\nlabels)\\n        \\n        P = model.predict_proba(labeledData)\\nIn order to perform pessimistic CPLE, we need to derive both the labeled and \\nunlabeled discriminative log likelihood. In order, we then perform predict_proba  \\non both the labeled and unlabeled data:\\n        try:\\n                        labeledDL = -sklearn.metrics.log_loss(labeledy, P)        except Exception, e:            print e            P = model.predict_proba(labeledData)\\n        \\n        unlabeledP = model.predict_proba(unlabeledData)             \\n        try: \\n            eps = 1e-15            unlabeledP = numpy.clip(unlabeledP, eps, 1 - eps)            unlabeledDL = numpy.average((unlabeledWeights*numpy.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 142}),\n",
              " Document(page_content=\"vstack((1-unlabeledy, unlabeledy)).T*numpy.log(unlabeledP)).sum(axis=1))\\n        except Exception, e:            print e            unlabeledP = model.predict_proba(unlabeledData)\\nOnce we're able to calculate the discriminative log likelihood for both the labeled and \\nunlabeled classification attempts, we can set an objective via the discriminative_\\nlikelihood_objective  function. The goal here is to use the pessimistic (or \\noptimistic, by choice) methodology to calculate dl on each iteration until the model \\nconverges or the maximum iteration count is hit.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 142}),\n",
              " Document(page_content='Chapter 5[ 121 ]On each iteration, a t-test is performed to determine whether the likelihoods have \\nchanged. Likelihoods should continue to change on each iteration preconvergence. Sharp-eyed readers may have noticed earlier in the chapter that three consecutive t-tests showing no change will cause the iteration to stop (this is configurable via the \\nmaxnoimprovementsince  parameter):\\n        if self.pessimistic:\\n            dl = unlabeledlambda * unlabeledDL - labeledDL        else: \\n            dl = - unlabeledlambda * unlabeledDL - labeledDL\\n        \\n        return dl\\n    def discriminative_likelihood_objective(self, model, labeledData, \\nlabeledy = None, unlabeledData = None, unlabeledWeights = None, unlabeledlambda = 1, gradient=[], alpha = 0.01):\\n        if self.it == 0:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 143}),\n",
              " Document(page_content='self.lastdls = [0]*self.buffersize\\n        \\n        dl = self.discriminative_likelihood(model, labeledData, \\nlabeledy, unlabeledData, unlabeledWeights, unlabeledlambda, gradient, alpha)\\n                self.it += 1        self.lastdls[numpy.mod(self.it, len(self.lastdls))] = dl                if numpy.mod(self.it, self.buffersize) == 0: # or True:            improvement = numpy.mean((self.lastdls[(len(self.\\nlastdls)/2):])) - numpy.mean((self.lastdls[:(len(self.lastdls)/2)]))\\n            _, prob = scipy.stats.ttest_ind(self.lastdls[(len(self.\\nlastdls)/2):], self.lastdls[:(len(self.lastdls)/2)])\\n                        noimprovement = prob > 0.1 and numpy.mean(self.\\nlastdls[(len(self.lastdls)/2):]) < numpy.mean(self.lastdls[:(len(self.lastdls)/2)])\\n            if noimprovement:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 143}),\n",
              " Document(page_content='self.noimprovementsince += 1\\n                if self.noimprovementsince >= self.\\nmaxnoimprovementsince:\\n                                        self.noimprovementsince = 0                    raise Exception(\" converged.\")             else:\\n                self.noimprovementsince = 0', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 143}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 122 ]On each iteration, the algorithm saves the best discriminative likelihood and the best \\nweight set for use in the next iteration:\\n        if dl < self.bestdl:\\n            self.bestdl = dl\\n            self.bestlbls = numpy.copy(unlabeledWeights[:, 0])\\n                                return dl\\nOne more element worth discussing is how the soft labels are created. We've \\ndiscussed these earlier in the chapter. This is how they look in code:\\nf = lambda softlabels, grad=[]: self.discriminative_likelihood_objective(self.model, labeledX, labeledy=labeledy, unlabeledData=unlabeledX, unlabeledWeights=numpy.vstack((softlabels, 1-softlabels)).T, gradient=grad) \\nlblinit = numpy.random.random(len(unlabeledy))\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 144}),\n",
              " Document(page_content='In a nutshell, softlabels  provide a probabilistic version of the discriminative \\nlikelihood calculation. In other words, they act as weights rather than hard, binary \\nclass labels. Soft labels are calculable using the optimize  method:\\n        try:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 144}),\n",
              " Document(page_content='self.it = 0            opt = nlopt.opt(nlopt.GN_DIRECT_L_RAND, M)            opt.set_lower_bounds(numpy.zeros(M))            opt.set_upper_bounds(numpy.ones(M))            opt.set_min_objective(f)            opt.set_maxeval(self.max_iter)            self.bestsoftlbl = opt.optimize(lblinit)            print \" max_iter exceeded.\"        except Exception, e:            print e            self.bestsoftlbl = self.bestlbls                    if numpy.any(self.bestsoftlbl != self.bestlbls):            self.bestsoftlbl = self.bestlbls        ll = f(self.bestsoftlbl)\\n        unlabeledy = (self.bestsoftlbl<0.5)*1\\n        uweights = numpy.copy(self.bestsoftlbl)         uweights[unlabeledy==1] = 1-uweights[unlabeledy==1]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 144}),\n",
              " Document(page_content='weights = numpy.hstack((numpy.ones(len(labeledy)), uweights))\\n        labels = numpy.hstack((labeledy, unlabeledy))', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 144}),\n",
              " Document(page_content='Chapter 5[ 123 ]For interested readers, optimize uses the Newton conjugate gradient \\nmethod of calculating gradient descent to find optimal weight values. A reference to Newton conjugate gradient is provided in the Further \\nreading section at the end of this chapter.\\nOnce we understand how this works, the rest of the calculation is a straightforward \\ncomparison of the best supervised labels and soft labels, setting the bestsoftlabel  \\nparameter as the best label set. Following this, the discriminative likelihood is computed against the best label set and a \\nfit function is calculated:\\n        if self.use_sample_weighting:\\n            self.model.fit(numpy.vstack((labeledX, unlabeledX)), \\nlabels, sample_weight=weights)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 145}),\n",
              " Document(page_content='else:            self.model.fit(numpy.vstack((labeledX, unlabeledX)), \\nlabels)\\n        \\n        if self.verbose > 1:\\n            print \"number of non-one soft labels: \", numpy.sum(self.\\nbestsoftlbl != 1), \", balance:\", numpy.sum(self.bestsoftlbl<0.5), \" / \", len(self.bestsoftlbl)\\n            print \"current likelihood: \", ll\\nNow that we\\'ve had a chance to understand the implementation of CPLE, let\\'s get \\nhands-on with an interesting dataset of our own! This time, we\\'ll change things up by working with the University of Columbia\\'s Million Song Dataset.\\nThe central feature of this algorithm is feature analysis and metadata for one million', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 145}),\n",
              " Document(page_content=\"songs. The data is preprepared and made up of natural and derived features. Available features include things such as the artist's name and ID, duration, loudness, time signature, and tempo of each song, as well as other measures including a crowd-rated danceability score and tags associated with the audio.\\nThis dataset is generally labeled (via tags), but our objective in this case will be to \\ngenerate genre labels for different songs based on the data provided. As the full \\nmillion song dataset is a rather forbidding 300 GB, let's work with a 1% (1.8 GB) \\nsubset of 10,000 records. Furthermore, we don't particularly need this data as it \\ncurrently exists; it's in an unhelpful format and a lot of the fields are going to be of \\nlittle use to us.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 145}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 124 ]The 10000_songs  dataset residing in the Chapter 6, Text Feature Engineering  folder \\nof our Mastering Python Machine Learning  repository is a cleaned, prepared (and \\nalso rather large) subset of music data from multiple genres. In this analysis, we'll \\nbe attempting to predict genre from the genre tags provided as targets. We'll take a subset of tags as the labeled data used to kick-start our learning and will attempt  \\nto generate tags for unlabelled data.\\nIn this iteration, we're going to raise our game as follows:\\n• Using more labeled data. This time, we'll use 1% of the total dataset size (100 \\nsongs), taken at random, as labeled data.\\n• Using an SVM with a linear kernel as our classifier, rather than the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 146}),\n",
              " Document(page_content='simple linear discriminant analysis we used with our naïve self-training implementation earlier in this chapter.\\nSo, let\\'s get started:\\nimport sklearn.svm\\nimport numpy as npimport random\\nfrom frameworks.CPLELearning import CPLELearningModel\\nfrom methods import scikitTSVMfrom examples.plotutils import evaluate_and_plot\\nkernel = \"linear\"songs = fetch_mldata(\"10000_songs\")\\nX = songs.dataytrue = np.copy(songs.target)ytrue[ytrue==-1]=0\\nlabeled_N = 20\\nys = np.array([-1]*len(ytrue))random_labeled_points = random.sample(np.where(ytrue == 0)[0], \\nlabeled_N/2)+\\\\\\n                        random.sample(np.where(ytrue == 1)[0], \\nlabeled_N/2)\\nys[random_labeled_points] = ytrue[random_labeled_points]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 146}),\n",
              " Document(page_content='Chapter 5[ 125 ]For comparison, we\\'ll run a supervised SVM alongside our CPLE implementation. \\nWe\\'ll also run the naïve self-supervised implementation, which we saw earlier in this chapter, for comparison:\\nbasemodel = SGDClassifier(loss=\\'log\\', penalty=\\'l1\\') # scikit logistic regression\\nbasemodel.fit(X[random_labeled_points, :], ys[random_labeled_points])print \"supervised log.reg. score\", basemodel.score(X, ytrue)\\nssmodel = SelfLearningModel(basemodel)\\nssmodel.fit(X, ys)print \"self-learning log.reg. score\", ssmodel.score(X, ytrue)\\nssmodel = CPLELearningModel(basemodel)\\nssmodel.fit(X, ys)print \"CPLE semi-supervised log.reg. score\", ssmodel.score(X, ytrue)\\nThe results that we obtain on this iteration are very strong:\\n# supervised log.reg. score 0.698', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 147}),\n",
              " Document(page_content='# self-learning log.reg. score 0.825# CPLE semi-supervised log.reg. score 0.833', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 147}),\n",
              " Document(page_content=\"Semi-Supervised Learning[ 126 ]The CPLE semi-supervised model succeeds in classifying with 84% accuracy,  \\na score comparable to human estimation and over 10% higher than the naïve  \\nsemi-supervised implementation. Notably, it also outperforms the supervised SVM.\\nFurther reading\\nA solid place to start understanding Semi-supervised learning methods is Xiaojin Zhu's very thorough literature survey, available at \\nhttp://pages.cs.wisc.\\nedu/~jerryzhu/pub/ssl_survey.pdf . \\nI also recommend a tutorial by the same author, available in the slide format at \\nhttp://pages.cs.wisc.edu/~jerryzhu/pub/sslicml07.pdf .\\nThe key paper on Contastive Pessimistic Likelihood Estimation is Loog's 2015 paper \\nhttp://arxiv.org/abs/1503.00269 .\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 148}),\n",
              " Document(page_content=\"This chapter made a reference to the distinction between generative and discriminative models. A couple of relatively clear explanations of the distinction between generative and discriminative algorithms are provided by Andrew Ng (\\nhttp://cs229.stanford.edu/notes/cs229-notes2.pdf ) and Michael \\nJordan (http://www.ics.uci.edu/~smyth/courses/cs274/readings/jordan_\\nlogistic.pdf ). \\nFor readers interested in Bayesian statistics, Allen Downey's book, Think Bayes,  is a marvelous introduction (and one of my all-time favorite statistics books): \\nhttps://www.google.co.uk/#q=think+bayes .\\nFor readers interested in learning more about gradient descent, I recommend Sebastian Ruder's blog at \\nhttp://sebastianruder.com/optimizing-gradient-\\ndescent/.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 148}),\n",
              " Document(page_content=\"For readers interested in going a little deeper into the internals of conjugate descent, Jonathan Shewchuk's introduction provides clear and enjoyable definitions for a number of key concepts at \\nhttps://www.cs.cmu.edu/~quake-papers/painless-\\nconjugate-gradient.pdf .\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 148}),\n",
              " Document(page_content='Chapter 5[ 127 ]Summary\\nIn this chapter, we tapped into a very powerful but lesser known paradigm in \\nmachine learning—semi-supervised learning. We began by exploring the underlying concepts of transductive learning and self-training, and improved our understanding of the latter class of techniques by working with a naïve self-training implementation.\\nWe quickly began to see weaknesses in self-training and looked for an effective \\nsolution, which we found in the form of CPLE. CPLE is a very elegant and highly applicable framework for semi-supervised learning that makes no assumptions beyond those of the classifier that it uses as a base model. In return, we found', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 149}),\n",
              " Document(page_content=\"CPLE to consistently offer performance in excess of naïve semi-supervised and supervised implementations, at minimal risk. We've gained a significant amount  \\nof understanding regarding one of the most useful recent developments in  \\nmachine learning.\\nIn the next chapter, we'll begin discussing data preparation skills that significantly \\nincrease the effectiveness of all of the models that we've previously discussed.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 149}),\n",
              " Document(page_content=\"[ 129 ]Text Feature Engineering\\nIntroduction\\nIn preceding chapters, we've spent time assessing powerful techniques that enable \\nthe analysis of complex or challenging data. However, for the most difficult problems, the right technique will only get you so far.\\nThe persistent challenge that deep learning and supervised learning try to solve for \\nis that finding solutions often requires multiple big investments from the team in question. Under the old paradigm, one often has to perform specific preparation tasks, requiring time, specialist skills, and knowledge. Often, even the techniques used were domain-specific and/or data type-specific. This process, via which features are derived, is referred to as feature engineering.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 151}),\n",
              " Document(page_content='Most of the deep learning algorithms which we\\'ve studied so far are intended to \\nhelp find ways around needing to perform extensive feature engineering. However, \\nat the same time, feature engineering continues to be seen as a hugely important \\nskill for top-level ML practitioners. The following quotes come from leading Kaggle \\ncompetitors, via David Kofoed Wind\\'s contribution to the Kaggle blog:\\n\"The features you use influence more than everything else the result. No algorithm alone, to my knowledge, can supplement the information gain given by correct feature engineering.\"\\n                                                                                                 – (Luca Massaron)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 151}),\n",
              " Document(page_content='Text Feature Engineering[ 130 ]\"Feature engineering is certainly one of the most important aspects in Kaggle', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 152}),\n",
              " Document(page_content=\"competitions and it is the part where one should spend the most time on. There are often some hidden features in the data which can improve your performance by a lot and if you want to get a good place on the leaderboard you have to find them. If you screw up here you mostly can't win anymore; there is always one guy who finds all the secrets. However, there are also other important parts, like how you formulate the problem. Will you use a regression model or classification model or even combine both or is some kind of ranking needed. This, and feature engineering, are crucial to achieve a good result in those competitions. There are also some competitions where (manual) feature engineering is not needed anymore; like in image processing competitions. Current state of the art deep\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 152}),\n",
              " Document(page_content='learning algorithms can do that for you.\"', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 152}),\n",
              " Document(page_content='– (Josef Feigl)\\nThere are a few key themes here; feature engineering  is powerful and even a very \\nsmall amount of feature engineering can have a big impact on one\\'s classifiers. It is \\nalso frequently necessary to employ feature engineering techniques if one wishes to deliver the best possible results. Maximising the effectiveness of your machine learning algorithms requires a certain amount of both domain-specific and data  \\ntype-specific knowledge (secrets).\\nOne more quote:\\n\"For most Kaggle competitions the most important part is feature engineering, \\nwhich is pretty easy to learn how to do.\"', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 152}),\n",
              " Document(page_content=\"– (Tim Salimans)\\nTim's not wrong; most of what you'll learn in this chapter is intuitive, effective tricks, \\nand transformations. This chapter will introduce you to a few of the most effective and commonly-used preparation techniques applied to text and time series data, drawing from NLP and financial time series applications. We'll walk through how the techniques work, what one should expect to see, and how one can diagnose whether they're working as desired.\\nText feature engineering\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 152}),\n",
              " Document(page_content=\"In preceding sections, we've discussed some of the methods by which we might take a dataset and extract a subset of valuable features. These methods have broad applicability but are less helpful when dealing with non-numerical/non-categorical data, or data that cannot be easily translated into numerical or categorical data. In particular, we need to apply different techniques when working with text data.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 152}),\n",
              " Document(page_content=\"Chapter 6[ 131 ]The techniques that we'll study in this section fall into two main categories—cleaning \\ntechniques and feature preparation techniques. These are typically implemented in roughly that order and we'll study them accordingly.\\nCleaning text data\\nWhen we work with natural text data, a different set of approaches apply. This is because in real-world contexts, the idea of a naturally clean text dataset is pretty unsafe; text data is rife with misspellings, non-dictionary constructs like emoticons, and in some cases, HTML tagging. As such, we need to be very thorough with  \\nour cleaning.\\nIn this section, we'll work with a number of effective text-cleaning techniques, using\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 153}),\n",
              " Document(page_content='a pretty gnarly real-world dataset. Specifically, we\\'ll be using the Impermium dataset from a 2012 Kaggle competition, where the competition\\'s goal was to create a model which accurately detects insults in social commentary.\\nYes, I do mean Internet troll detection.\\nLet\\'s get started!\\nText cleaning with BeautifulSoup\\nOur first step should be manually checking the input data. This is pretty critical; with \\ntext data, one needs to try and understand what issues exist in the data initially so as to identify the cleaning needed.\\nIt\\'s kind of painful to read through a dataset full of hateful Internet commentary, so \\nhere\\'s an example entry:\\nID Date Comment\\n132 20120531031917Z \"\"\"\\\\xa0@Flip\\\\xa0how are you not ded\"\"\"', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 153}),\n",
              " Document(page_content=\"We have an ID field and date field which don't seem to need much work. The text fields, however, are quite challenging. From this one case, we can already see misspelling and HTML inclusion. Furthermore, many entries in the dataset contain attempts to bypass swear filtering, usually by including a space or punctuation element mid-word. Other data quality issues include multiple vowels (to extend a word), non-ascii characters, hyperlinks... the list goes on.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 153}),\n",
              " Document(page_content=\"Text Feature Engineering[ 132 ]One option for cleaning this dataset is to use regular expressions, which run over  \\nthe input data to scrub out data quality issues. However, the quantity and variety  \\nof problem formats make it impractical to use a regex-based approach, at least to begin with. We're likely both to miss a lot of cases and also to misjudge the amount of preparation needed, leading us to clean too aggressively, or not aggressively enough; in specific terms we risk cutting into real text content or leaving parts of tags in place. What we need is a solution that will wash out the majority of common data quality problems to begin with so  that we can focus on the remaining issues with a \\nscript-based approach.\\nEnter\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 154}),\n",
              " Document(page_content='BeautifulSoup . BeautifulSoup  is a very powerful text cleaning library which \\ncan, among other things, remove HTML markup. Let\\'s take a look at this library in \\naction on our troll data:\\nfrom bs4 import BeautifulSoup\\nimport csv\\ntrolls = []\\nwith open(\\'trolls.csv\\',  \\'rt\\') as f:    reader = csv.DictReader(f)    for line in reader:        trolls.append(BeautifulSoup(str(line[\"Comment\"]), \"html.\\nparser\"))\\nprint(trolls[0])eg = BeautifulSoup(str(trolls), \"html.parser\")print(eg.get_text())\\nID Date Comments\\n132 20120531031917Z @Flip how are you not ded\\nAs we can see, we\\'ve already made headway on improving the quality of our text', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 154}),\n",
              " Document(page_content=\"data. Yet, it's also clear from these examples that there's a lot of work left to do! As discussed, let's move on to using regular expressions to help further clean and tokenize our data.\\nManaging punctuation and tokenizing\\nTokenisation is the process of creating a set of tokens from a stream of text. Many \\ntokens are words, while others might be character sets (such as smilies or other punctuation strings, for example, \\n???????? ).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 154}),\n",
              " Document(page_content=\"Chapter 6[ 133 ]Now that we've removed a lot of the HTML ugliness from our initial dataset, we \\ncan take steps to further improve the cleanliness of our text data. To do this, we'll leverage the \\nre module, which allows us to use operations over regular expressions, \\nsuch as substring replacement. We'll perform a series of operations over our input text on this pass, which mostly focus on replacing variable or problematic text elements with tokens. Let's begin with a simple example, replacing e-mail addresses with an \\n_EM token:\\ntext = re.sub(r'[\\\\w\\\\-][\\\\w\\\\-\\\\.]+@[\\\\w\\\\-][\\\\w\\\\-\\\\.]+[a-zA-Z]{1,4}', '_EM', text)\\nSimilarly, we can remove URLs, replacing them with the _U token:\\ntext = re.sub(r'\\\\w+:\\\\/\\\\/\\\\S+', r'_U', text)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 155}),\n",
              " Document(page_content=\"We can automatically remove extra or problematic whitespace and newline characters, hyphens, and underscores. In addition, we'll begin managing the problem of multiple characters, often used for emphasis in informal conversation. Extended series of punctuation characters are encoded here using codes such as \\n_BQ and BX; these longer tags are used as a means of differentiating from the more \\nstraightforward _Q and _X tags (which refer to the use of a question mark and \\nexclamation mark, respectively).\\nWe can also use regular expressions to manage extra letters; by cutting down such \\nstrings to two characters at most, we're able to reduce the number of combinations to a manageable amount and tokenize that reduced group using the \\n_EL token:\\n# Format whitespaces\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 155}),\n",
              " Document(page_content='text = text.replace(\\'\"\\', \\' \\')text = text.replace(\\'\\\\\\'\\', \\' \\')text = text.replace(\\'_\\', \\' \\')text = text.replace(\\'-\\', \\' \\')text = text.replace(\\'\\\\n\\', \\' \\')text = text.replace(\\'\\\\\\\\n\\', \\' \\')text = text.replace(\\'\\\\\\'\\', \\' \\')text = re.sub(\\' +\\',\\' \\', text) text = text.replace(\\'\\\\\\'\\', \\' \\')        \\n#manage punctuation\\ntext = re.sub(r\\'([^!\\\\?])(\\\\?{2,})(\\\\Z|[^!\\\\?])\\', r\\'\\\\1 _BQ\\\\n\\\\3\\', text)text = re.sub(r\\'([^\\\\.])(\\\\.{2,})\\', r\\'\\\\1 _SS\\\\n\\', text) text = re.sub(r\\'([^!\\\\?])(\\\\?|!){2,}(\\\\Z|[^!\\\\?])\\', r\\'\\\\1 _BX\\\\n\\\\3\\', text) text = re.sub(r\\'([^!\\\\?])\\\\?(\\\\Z|[^!\\\\?])\\', r\\'\\\\1 _Q\\\\n\\\\2\\', text) text = re.sub(r\\'([^!\\\\?])!(\\\\Z|[^!\\\\?])\\', r\\'\\\\1 _X\\\\n\\\\2\\', text)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 155}),\n",
              " Document(page_content=\"Text Feature Engineering[ 134 ]text = re.sub(r'([a-zA-Z])\\\\1\\\\1+(\\\\w*)', r'\\\\1\\\\1\\\\2 _EL', text) \\ntext = re.sub(r'([a-zA-Z])\\\\1\\\\1+(\\\\w*)', r'\\\\1\\\\1\\\\2 _EL', text)text = re.sub(r'(\\\\w+)\\\\.(\\\\w+)', r'\\\\1\\\\2', text)\\ntext = re.sub(r'[^a-zA-Z]','', text)\\nNext, we want to begin creating other tokens of interest. One of the more helpful \\nindicators available is the _SW token for swearing. We'll also use regular expressions \\nto help identify and tokenize smileys into one of four buckets; big and happy smileys (\\n_BS), small and happy ones ( _S), big and sad ones ( _BF), and small and sad ones ( _F):\\ntext = re.sub(r'([#%&\\\\*\\\\$]{2,})(\\\\w*)', r'\\\\1\\\\2 _SW', text)\\n        \\ntext = re.sub(r' [8x;:=]-?(?:\\\\)|\\\\}|\\\\]|>){2,}', r' _BS', text) text = re.sub(r' (?:[;:=]-?[\\\\)\\\\}\\\\]d>])|(?:<3)', r' _S', text)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 156}),\n",
              " Document(page_content=\"text = re.sub(r' [x:=]-?(?:\\\\(|\\\\[|\\\\||\\\\\\\\|/|\\\\{|<){2,}', r' _BF', text) \\ntext = re.sub(r' [x:=]-?[\\\\(\\\\[\\\\|\\\\\\\\/\\\\{<]', r' _F', text)\\nSmileys are complicated by the fact that their uses change frequently; \\nwhile this series of characters is reasonably current, it's by no means complete; for example, see emojis for a range of non-ascii representations. For several reasons, we'll be removing non-ascii text from this example (a similar approach is to use a dictionary to force compliance), but both approaches have the obvious drawback that they remove cases from the dataset, meaning that any solution will be imperfect. In some cases, this approach may lead to the removal of a substantial amount of data. In \\ngeneral, then, it's prudent to be aware of the general challenge around\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 156}),\n",
              " Document(page_content=\"character-based images in text content.\\nFollowing this, we want to begin splitting text into phrases. This is a simple application of \\nstr.split , which enables the input to be treated as a vector of words \\n(words) rather than as long strings ( re):\\nphrases = re.split(r'[;:\\\\.()\\\\n]', text) \\nphrases = [re.findall(r'[\\\\w%\\\\*&#]+', ph) for ph in phrases] phrases = [ph for ph in phrases if ph]         words = []        for ph in phrases:      words.extend(ph)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 156}),\n",
              " Document(page_content=\"Chapter 6[ 135 ]This gives us the following:\\nID Date Comments\\n132 20120531031917Z [['Flip', 'how', 'are', 'you', 'not', \\n'ded']]\\nNext, we perform a search for single-letter sequences. Sometimes, for emphasis, Internet communication involves the use of spaced single-letter chains. This may be attempted as a method of avoiding curse word detection:\\ntmp = words\\nwords = []new_word = ''for word in tmp:   if len(word) == 1:      new_word = new_word + word   else:      if new_word:         words.append(new_word)         new_word = ''      words.append(word)\\nSo far, then, we've gone a long way toward cleaning and improving the quality \\nof our input data. There are still outstanding issues, however. Let's reconsider the example we began with, which now looks like the following:\\nID Date Words\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 157}),\n",
              " Document(page_content=\"132 20120531031917Z ['_F', 'how', 'are', 'you', 'not', 'ded']\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 157}),\n",
              " Document(page_content='Text Feature Engineering[ 136 ]Much of our early cleaning has passed this example by, but we can see the effect of \\nvectorising the sentence content as well as the now-cleaned HTML tags. We can also see that the emote used has been captured via the \\n_F tag. When we look at a more \\ncomplex test case, we see even more substantial change results:\\nRaw Cleaned and split\\nGALLUP DAILY\\\\nMay 24-26, 2012 \\\\u2013 Updates daily at 1 p.m. ET; reflects one-day change\\\\nNo updates Monday, May 28; next update will be Tuesday, May \\n29.\\\\nObama Approval48%-\\\\nObama', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 158}),\n",
              " Document(page_content=\"Disapproval45%-1\\\\nPRESIDENTIAL ELECTION\\\\nObama47%-\\\\nRomney45%-\\\\n7-day rolling average\\\\n\\\\n It seems the bump Romney got is over and the president is on his game.['GALLUP', 'DAILY', 'May', 'u', 'Updates', 'daily', 'pm', 'ET', 'reflects', 'one', 'day', 'change', 'No', 'updates', \\n'Monday', 'May', 'next', \\n'update', 'Tuesday', 'May', \\n'Obama', 'Approval', 'Obama', 'Disapproval', 'PRESIDENTIAL', 'ELECTION', 'Obama', 'Romney', 'day', 'rolling', 'average', 'It', 'seems', 'bump', 'Romney', 'got', 'president', 'game']\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 158}),\n",
              " Document(page_content=\"However, there are two significant problems still obvious in both examples. In the first case, we have a misspelled word; we need to find a way to eliminate this. Secondly, a lot of the words in both examples (for example. are, pm) aren't terribly informative in and of themselves. The problem we find, particularly for shorter text samples, is that what's left after cleaning may contain only one or two meaningful terms. If these terms are not terribly common in the corpus as a whole, it can prove to be very difficult to train a classifier to recognise these terms' significance.\\nTagging and categorising words\\nI expect that we all know that English language words come in several types—nouns, verbs, adverbs, and so on. These are commonly referred to as parts of speech . If we\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 158}),\n",
              " Document(page_content=\"know that a certain word is an adjective, as opposed to a verb or stop word (such as a, the, or of), we can treat it differently or more importantly, our algorithm can!\\nIf we can perform part of speech tagging by identifying and encoding word classes \\nas categorical variables, we're able to improve the quality of our data by retaining only the valuable content. The full range of text tagging options and techniques is too broad to be effectively covered in one section of this chapter, so we'll look at a subset of the applicable tagging techniques. Specifically, we'll focus on n-gram tagging and backoff taggers, a pair of complimentary techniques that allow us to create powerful recursive tagging algorithms.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 158}),\n",
              " Document(page_content=\"Chapter 6[ 137 ]We'll be using a Python library called the Natural Language Toolkit (NLTK). NLTK \\noffers a wide array of functionality and we'll be relying on it at several points in this \\nchapter. For now, we'll be using NLTK to perform tagging and removal of certain word types. Specifically, we'll be filtering out stop words.\\nTo answer the obvious first question (why eliminate stop words?), it tends to be true \\nthat stop words add little to nothing to most text analysis and can be responsible for a degree of noise and training variance. Fortunately, filtering stop words is pretty \\nstraightforward. We'll simply import NLTK, download and import the dictionaries, \\nthen perform a scan over all words in our pre-existing word vector, removing any \\nstop words found:\\nimport nltk\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 159}),\n",
              " Document(page_content='nltk.download()from nltk.corpus import stopwords \\nwords = [w for w in words if not w in stopwords.words(\"english\")]\\nI\\'m sure you\\'ll agree that this was pretty straightforward! Let\\'s move on to discuss \\nmore NLTK functionality, specifically, tagging.\\nTagging with NLTK\\nTagging is the process  of identifying parts of speech, as we described previously, and \\napplying tags to each term.\\nIn its simplest form, tagging can be as straightforward as applying a dictionary over \\nour input data, just as we did previously with stopwords:\\ntagged = ntlk.word_tokenize(words)\\nHowever, even brief consideration will make it obvious that our use of language is a', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 159}),\n",
              " Document(page_content='lot more complicated than this allows. We may use a word (such as ferry) as one of several parts of speech and it may not be straightforward to decide how to treat each word in every utterance. A lot of the time, the correct tag can only be understood contextually given the other words and their positioning within the phrase.\\nThankfully, we have a number of useful techniques available to help us solve \\nlinguistic challenges.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 159}),\n",
              " Document(page_content=\"Text Feature Engineering[ 138 ]Sequential tagging\\nA sequential tagging algorithm is one that works by running through the input \\ndataset, left-to-right and token-by-token (hence sequential!), tagging each token in \\nsuccession. The decision over which token to assign is made based on that token, the tokens that preceded it, and the predicted tags for those preceding tokens.\\nIn this section, we'll be using an n-gram tagger . An n-gram tagger is a type of \\nsequential tagger, which is pretrained to identify appropriate tags. The n-gram \\ntagger takes (n-1)-many preceding POS tags and the current token into consideration \\nin producing a tag.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 160}),\n",
              " Document(page_content='For clarity, an n-gram is the term used for a contiguous sequence of n-many elements from a given set of elements. This may be a contiguous sequence of letters, words, numerical codes (for example, for state changes), or other elements. N-grams are widely used as a means of capturing the conjunct meaning of sets of elements—be those phrases or encoded state transitions—using n-many elements.\\nThe simplest form of n-gram tagger is one where n = 1, referred to as a unigram tagger. A unigram tagger operates quite simply, by maintaining a conditional frequency distribution for each token. This conditional frequency distribution is built up from a training corpus of terms; we can implement training using a helpful train method belonging to the', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 160}),\n",
              " Document(page_content=\"NgramTagger  class in NLTK. The tagger assumes that the \\ntag which occurs most frequently for a given token in a given sequence is likely to be the correct tag for that token. If the term carp is in the training corpus as a noun four \\ntimes and as a verb twice, a unigram tagger will assign the noun tag to any token whose type is carp.\\nThis might suffice for a first-pass tagging attempt but clearly, a solution that only \\never serves up one tag for each set of homonyms isn't always going to be ideal. The solution we can tap into is using n-grams with a larger value of n. With n = 3 (a trigram tagger ), for instance, we can see how the tagger might more easily \\ndistinguish the input He tends to carp on a lot from He caught a magnificent carp!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 160}),\n",
              " Document(page_content=\"However, once again there is a trade-off here between accuracy of tagging and ability \\nto tag. As we increase n, we're creating increasingly long n-grams which become increasingly rare. In a very short time, we end up in a situation where our n-grams are not occurring in the training data, causing our tagger to be unable to find any appropriate tag for the current token!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 160}),\n",
              " Document(page_content=\"Chapter 6[ 139 ]In practice, we find that what we need is a set of taggers. We want our most reliably \\naccurate tagger to have the first shot at trying to tag a given dataset and, for any case that fails, we're comfortable with having a more reliable but potentially less accurate tagger have a try.\\nHappily, what we want already exists in the form of backoff tagging. Let's find  \\nout more!\\nBackoff tagging\\nSometimes, a given tagger may not perform reliably. This is particularly common when the tagger has high accuracy demands and limited training data. At such times, we usually want to build an ensemble structure that lets us use several taggers simultaneously.\\nTo do this, we create a distinction between two types of taggers: subtaggers and\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 161}),\n",
              " Document(page_content='backoff taggers. Subtaggers are taggers like the ones we saw previously, sequential  \\nand Brill taggers. Tagging structures may contain one or multiple of each kind of \\ntagger.\\nIf a subtagger is unable to determine a tag for a given token, then a backoff tagger \\nmay be referred to instead. A backoff tagger is specifically used to combine the \\nresults of an ensemble of (one or more) subtaggers, as shown in the following example diagram:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 161}),\n",
              " Document(page_content='Text Feature Engineering[ 140 ]In simple implementations, the backoff tagger will simply poll the subtaggers in \\norder, accepting the first none-null tag provided. If all subtaggers return null for a given token, the backoff tagger will assign a none tag to that token. The order can be determined.\\nBackoffs are typically used with multiple subtaggers of different types; this enables \\na data scientist to harness the benefits of multiple types of tagger simultaneously. Backoffs may refer to other backoffs as needed, potentially creating highly redundant \\nor sophisticated tagging structures:\\nIn general terms, backoff taggers provide redundancy and enable you to use multiple', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 162}),\n",
              " Document(page_content=\"taggers in a composite solution. To solve our immediate problem, let's implement a nested series of n-gram taggers. We'll start with a trigram tagger, which will use a bigram tagger as its backoff tagger. If neither of these taggers has a solution, we'll have a unigram tagger as an additional backoff. This can be done very simply,  as follows:\\nbrown_a = nltk.corpus.brown.tagged_sents(categories= 'a')\\ntagger = None\\nfor n in range(1,4):  tagger = NgramTagger(n, brown_a, backoff = tagger)\\nwords  = tagger.tag(words)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 162}),\n",
              " Document(page_content=\"Chapter 6[ 141 ]Creating features from text data\\nOnce we've engaged in well-thought-out text cleaning practices, we need to take \\nadditional steps to ensure that our text becomes useful features. In order to do this, we'll look at another set of staple techniques in NLP:\\n• Stemming\\n• Lemmatising\\n• Bagging using random forests\\nStemming\\nAnother challenge when working with linguistic datasets is that multiple word forms exist for many word stems. For example, the root dance is the stem of multiple other words—dancing, dancer, dances, and so on. By finding a way to reduce this plurality of forms into stems, we find ourselves able to improve our n-gram tagging and apply new techniques such as lemmatisation.\\nThe techniques that enable us to reduce words to their stems are called stemmers.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 163}),\n",
              " Document(page_content=\"Stemmers work by parsing words as consonant/vowel strings and applying a series of rules. The most popular stemmer is the porter stemmer , which works by \\nperforming the following steps;\\n1. Simplifying the range of suffixes by reducing (for example, ies becomes i) to a \\nsmaller set.\\n2. Removing suffixes in several passes, with each pass removing a set of suffix types (for example, past particple or plural suffixes such as ousness or alism).\\n3. Once all suffixes are removed, cleaning up word endings by adding 'e's \\nwhere needed (for example, ceas becomes cease).\\n4. Removing double 'l's.\\nThe porter stemmer works very effectively. In order to understand exactly how well \\nit works, let's see it in action!\\nfrom nltk.stem import PorterStemmer\\n stemmer = PorterStemmer() stemmer.stem(words)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 163}),\n",
              " Document(page_content=\"The output of this stemmer , as demonstrated on our pre-existing example, is the \\nroot form of the word. This may be a real word, or it may not; dancing, for instance, \\nbecomes danci. This is okay, but it's not really ideal. We can do better than this!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 163}),\n",
              " Document(page_content=\"Text Feature Engineering[ 142 ]To consistently reach a real word form, let's apply a slightly different technique, \\nlemmatisation. Lemmatisation is a more complex process to determine word stems; unlike porter stemming, it uses a different normalisation process for different parts of speech. Unlike Porter Stemming it also seeks to find actual roots for words. Where a stem does not have to be a real word, a lemma does. Lemmatization also takes on the challenge of reducing synonyms down to their roots. For example, where a stemmer might turn the term books into the term book, it isn't equipped to handle \\nthe term tome. A lemmatizer can process both books and tome, reducing both terms to book.\\nAs a necessary prerequisite, we need the POS for each input token. Thankfully, we've\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 164}),\n",
              " Document(page_content=\"already applied a POS tagger and can work straight from the results of  that process!\\nfrom nltk.stem import PorterStemmer, WordNetLemmatizer\\nlemmatizer = WordNetLemmatizer()words = lemmatizer.lemmatize(words, pos = 'pos')\\nThe output is now what we'd expect to see:\\nSource Text Post-lemmatisation\\nThe laughs you two heard were \\ntriggered by memories of his own high-flying exits off moving beasts['The', 'laugh', 'two', 'hear', 'trigger', 'memory', 'high', 'fly', 'exit', 'move', 'beast']\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 164}),\n",
              " Document(page_content=\"We've now successfully stemmed our input text data, massively improving the effectiveness of lookup algorithms (such as many dictionary-based approaches) in handling this data. We've removed stop words and tokenized a range of other noise elements with regex methods. We've also removed any HTML tagging. Our text data has reached a reasonably processed state. There's one more linchpin technique that we need to learn, which will let us generate features from our text data. Specifically, we can use bagging to help quantify the use of terms.\\nLet's find out more!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 164}),\n",
              " Document(page_content=\"Chapter 6[ 143 ]Bagging and random forests\\nBagging is part of a family of techniques that may collectively be referred to as \\nsubspace methods. There are several forms of method, with each having a separate name. If we draw random subsets from the sample cases, then we're performing pasting. If we're sampling from cases with replacement, it's referred to as bagging. If instead of drawing from cases, we work with a subset of features, then we're performing attribute bagging. Finally, if we choose to draw from both sample cases and features, we're employing what's known as a random patches  technique.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 165}),\n",
              " Document(page_content=\"The feature-based techniques, attribute bagging, and Random Patch methods are very valuable in certain contexts, particularly very high-dimensional ones. Medical and genetics contexts both tend to see a lot of extremely high-dimensional data, so feature-based methods are highly effective within those contexts.\\nIn NLP contexts, it's common to work with bagging specifically. In the context of \\nlinguistic data, what we'll be dealing with is properly called a bag of words. A bag \\nof words is an approach to text data preparation that works by identifying all of the distinct words (or tokens) in a dataset and then counting their occurrence in each sample. Let's begin with a demonstration, performed over a couple of example cases \\nfrom our dataset:\\nID Date Words\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 165}),\n",
              " Document(page_content='132 20120531031917Z [\\'_F\\', \\'how\\', \\'are\\', \\'you\\', \\'not\\', \\n\\'ded\\']\\n69 20120531173030Z [\\'you\\', \\'are\\', \\'living\\', \\'proof\\', \\'that\\', \\'bath\\', \\'salts\\', \\'effect\\', \\'thinking\\']\\nThis gives us the following 12-part list of terms:\\n[\\n  \"_F\"  \"how\"  \"are\"  \"you\"  \"not\"  \"ded\"  \"living\"  \"proof\"  \"that\"  \"bath\"', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 165}),\n",
              " Document(page_content='Text Feature Engineering[ 144 ]  \"salts\"\\n  \"effect\"  \"thinking\"]\\nUsing the indices of this list, we can create a 12-part vector for each of the preceding \\nsentences. This vector\\'s values are filled by traversing the preceding list and counting \\nthe number of times each term occurs for each sentence in the dataset. Given our  \\npre-existing example sentences and the list we created from them, we end up creating the following bags:\\nID Date Comment Bag of words\\n13220120531031917Z _F how are you not ded[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\\n6920120531173030Z you are living proof that bath salts effect thinking[0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1]', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 166}),\n",
              " Document(page_content=\"This is the core of a bag of words implementation. Naturally, once we've translated the linguistic content of text into numerical vectors, we're able to start using techniques that add sophistication to how we use this text in classification.\\nOne option is to use weighted terms. We can use a term weighting scheme to \\nmodify the values within each vector so that terms that are indicative or helpful for classification are emphasized. Weighting schemes may be straightforward masks, such as a binary mask that indicates presence versus absence.\\nBinary masking can be useful if certain terms are used much more frequently than\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 166}),\n",
              " Document(page_content='normal; in such cases, specific scaling (for example, log-scaling) may be needed if a binary mask is not used. At the same time, though, frequency of term use can be informative (it may indicate emphasis, for instance) and the decision over whether to apply a binary mask is not always made simply.\\nAnother weighting option is term frequency-inverse document frequency, or tf-idf. \\nThis scheme compares frequency of usage within a specific sentence and the dataset as a whole and uses values that increase if a term is used more frequently within a given sample than within the whole corpus.\\nVariations on tf-idf are frequently used in text mining contexts, including search \\nengines. Scikit-learn provides a tf-idf implementation, \\nTfidfVectoriser , which', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 166}),\n",
              " Document(page_content=\"we'll shortly use to employ tf-idf for ourselves.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 166}),\n",
              " Document(page_content=\"Chapter 6[ 145 ]Now that we have an understanding of the theory behind bag of words and can \\nsee the range of technical options available to us once we develop vectors of word use, we should discuss how a bag of words implementation can be undertaken. Bag of words can be easily applied as a wrapper to a familiar model. While in general, subspace methods may use any of a range of base models (SVMs and linear regression models are common), it is very common to use random forests in a bag of \\nwords implementation, wrapping up preparation and learning into a concise script. In this case, we'll employ bag of words independently for now, saving classification via a random forest implementation for the next section!\\nWhile we'll discuss random forests in greater detail in Chapter 8,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 167}),\n",
              " Document(page_content=\"Ensemble Methods, (which describes the various types of ensemble that we can create), it is helpful for now to note that a random forest is a set of decision trees. They are powerful ensemble models that are created either to run in parallel (yielding a vote or other net outcome) or boost one another (by iteratively adding a new tree to model the parts of the solution that the pre-existing set of trees couldn't model well).\\nDue to the power and ease of use of random forests, they are \\ncommonly used as benchmarking algorithms.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 167}),\n",
              " Document(page_content='The process of implementing bag of words is, again, fairly straightforward. We initialize our bagging tool (matter-of-factly referred to as a vectorizer). Note that for this example, we\\'re putting a limit on the size of the feature vector. This is largely to save ourselves some time; each document must be compared against each item in the feature list, so when we get to running our classifier this could take a little while!\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nvectorizer = TfidfVectorizer(analyzer = \"word\",   \\\\\\n                             tokenizer = None,    \\\\                             preprocessor = None, \\\\                             stop_words = None,   \\\\                             max_features = 5000)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 167}),\n",
              " Document(page_content='Our next step is to fit the vectorizer on our word data via fit_transform ; as part of \\nthe fitting process, our data is transformed into feature vectors:\\ntrain_data_features = vectorizer.fit_transform(words)\\ntrain_data_features = train_data_features.toarray()', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 167}),\n",
              " Document(page_content=\"Text Feature Engineering[ 146 ]This completes the pre-processing of our text data. We've taken this dataset through \\na full battery of text mining techniques, walking through the theory and reasoning behind each technique as well as employing some powerful Python scripts to process our test dataset.We're in a good position now to take a crack at Kaggle's insult detection challenge!\\nTesting our prepared data\\nSo, now that we've done some initial preparation of the dataset, let's give the real problem a shot and see how we do. To help set the scene, let's consider Impermium's guidance and data description:\\nThis is a single-class classification problem. The label is either 0 meaning a neutral comment,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 168}),\n",
              " Document(page_content='or 1 meaning an insulting comment (neutral can be considered as not belonging to the insult class.  Your predictions must be a real number in the range [0,1] where 1 indicates 100% confident prediction that comment is an insult.\\n• We are looking for comments that are intended to be insulting to a person who is a part of the larger blog/forum conversation.\\n• We are NOT looking for insults directed to non-participants (such as celebrities, public figures etc.).\\n• Insults could contain profanity, racial slurs, or other offensive language. But often times, they do not.\\n• Comments which contain profanity or racial slurs, but are not necessarily insulting to another person are considered not insulting.\\n• The insulting nature of the comment should be obvious, and not subtle.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 168}),\n",
              " Document(page_content='• There may be a small amount of noise in the labels as they have not been meticulously cleaned. However, contestants can be confident the error in the training and testing data is < 1%.\\nContestants should also be warned that this problem tends to strongly overfit. The provided data is generally representative of the full test set, but not exhaustive by any measure. Impermium will be conducting final evaluations based on an unpublished set of data drawn from a wide sample.\\nThis is pretty nice guidance, in that it raises two particular points of caution. The \\ndesired score is the area under the curve (AUC), which is a measure that is very \\nsensitive both to false positives and to incorrect negative results (specificity and sensitivity).', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 168}),\n",
              " Document(page_content=\"Chapter 6[ 147 ]The guidance clearly states that continuous predictions are desired rather \\nthan binary 0/1 outputs. This becomes critically important when using AUC; \\neven a small amount of incorrect predictions given will radically decrease one's score if you only use categorical values. This suggests that rather than using the \\nRandomForestClassifier  algorithm, we'll want to use the \\nRandomForestRegressor , a regression-focused alternative, and then rescale the \\nresults between zero and one.\\nReal Kaggle contests are run in a much more challenging and realistic environment—\\none where the correct solution is not available. In Chapter 8, Ensemble Methods, we'll\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 169}),\n",
              " Document(page_content=\"explore how top data scientists react and thrive in such environments. For now, we'll take advantage of having the ability to confirm whether we're doing well on the test dataset. Note that this advantage also presents a risk; if the problem overfits strongly, we'll need to be disciplined to ensure that we're not overtraining on the test data!\\nIn addition, we also have the benefit of being able to see how well real contestants \\ndid. While we'll save the real discussion for Chapter 8, Ensemble Methods, it's \\nreasonable to expect each highly-ranking contestant to have submitted quite a large \\nnumber of failed attempts; having a benchmark will help us tell whether we're heading in the right direction.\\nSpecifically, the top 14 participants on the private (test) leaderboard managed to\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 169}),\n",
              " Document(page_content=\"reach an AUC score of over 0.8. The top scorer managed a pretty impressive 0.84, \\nwhile over half of the 50 teams who entered scored above 0.77.\\nAs we discussed earlier, let's begin with a random forest regression model.\\nA random forest is an ensemble of decision trees.\\nWhile a single decision tree is likely to suffer from variance- or \\nbias-related issues, random forests are able to use a weighted average over multiple parallel trials to balance the results of modeling.\\nRandom forests are very straightforward to apply and are a good\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 169}),\n",
              " Document(page_content='first-pass technique for a new data challenge; applying a random forest classifier to the data early on enables you to develop a good understanding as to what initial, baseline classification accuracy will look like as well as giving valuable insight into how the classification boundaries were formed; during the initial stages of working with a dataset, this kind of insight is invaluable.\\nScikit-learn provides RandomForestClassifier to enable the \\neasy application of a random forest algorithm.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 169}),\n",
              " Document(page_content='Text Feature Engineering[ 148 ]For this first pass, we\\'ll use 100 trees; increasing the number of trees can improve \\nclassification accuracy but will take additional time. Generally speaking, it\\'s sensible to attempt fast iteration in the early stages of model creation; the faster you can repeatedly run your model, the faster you can learn what your results are looking like and how to improve them!\\nWe begin by  initializing and training our model:\\ntrollspotter = RandomForestRegressor(n_estimators = 100, max_depth = \\n10, max_features = 1000)\\ny = trolls[\"y\"]\\ntrollspotted = trollspotter.fit(train_data_features, y)\\nWe then grab the test data and apply our model to predict a score for each test case. \\nWe rescale these scores using a simple stretching technique:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 170}),\n",
              " Document(page_content='moretrolls = pd.read_csv(\\'moretrolls.csv\\', header=True, names=[\\'y\\', \\'date\\', \\'Comment\\', \\'Usage\\'])\\nmoretrolls[\"Words\"] = moretrolls[\"Comment\"].apply(cleaner)\\ny = moretrolls[\"y\"]test_data_features = vectorizer.fit_transform(moretrolls[\"Words\"])\\ntest_data_features = test_data_features.toarray()\\npred = pred.predict(test_data_features)\\npred = (pred - pred.min())/(pred.max() - pred.min())\\nFinally, we apply the roc_auc  function to calculate an AUC score for the model:\\nfpr, tpr, _ = roc_curve(y, pred)roc_auc = auc(fpr, tpr)print(\"Random Forest benchmark AUC score, 100 estimators\")print(roc_auc)\\nAs we can see, the results are definitely not at the level that we want them to be at:\\nRandom Forest benchmark AUC score, 100 estimators\\n0.537894912105', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 170}),\n",
              " Document(page_content=\"Chapter 6[ 149 ]Thankfully, we have a number of options that we can try to configure here:\\n• Our approach to how we work with the input (preprocessing steps and \\nnormalisation)\\n• The number of estimators in our random forest\\n• The classifier we choose to employ\\n• The properties of our bag of words implementation (particularly the maximum number of terms)\\n• The structure of our n-gram tagger\\nOn our next pass, let's adjust the size of our bag of words implementation, increasing the term cap from a slightly arbitrary 5,000 to anywhere up to 8,000 terms; rather than picking just one value, we'll run over a range and see what we can learn. We'll also increase the number of trees to a more reasonable number (in this case, we stepped up to \\n1000 ):\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 171}),\n",
              " Document(page_content=\"Random Forest benchmark AUC score, 1000 estimators\\n0.546439310772\\nThese results are slightly better than the previous set, but not dramatically so. \\nThey're definitely a fair distance from where we want to be! Let's go further and set up a different classifier. Let's try a fairly familiar option—the SVM. We'll set up our own SVM object to work with:\\nclass SVM(object):\\n        def __init__(self, texts, classes, nlpdict=None):\\n        self.svm = svm.LinearSVC(C=1000, class_weight='auto')\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 171}),\n",
              " Document(page_content='if nlpdict:            self.dictionary = nlpdict        else:            self.dictionary = NLPDict(texts=texts)        self._train(texts, classes)            def _train(self, texts, classes):        vectors = self.dictionary.feature_vectors(texts)        self.svm.fit(vectors, classes)            def classify(self, texts):        vectors = self.dictionary.feature_vectors(texts)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 171}),\n",
              " Document(page_content=\"Text Feature Engineering[ 150 ]        predictions = self.svm.decision_function(vectors)\\n        predictions = p.transpose(predictions)[0:len(predictions)]        predictions = predictions / 2 + 0.5\\n        predictions[predictions > 1] = 1\\n        predictions[predictions < 0] = 0\\n        return predictions\\nWhile the workings of SVM are almost impenetrable to human assessment, as an \\nalgorithm it operates effectively, iteratively translating the dataset into multiple \\nadditional dimensions in order to create complex hyperplanes at optimal class boundaries. It isn't a huge surprise, then, to see that the quality of our classification has increased:\\nSVM AUC score\\n0.625245653817\\nPerhaps we're not getting enough visibility into what's happening with our results.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 172}),\n",
              " Document(page_content=\"Let's try shaking things up with a different take on performance measurement. Specifically, let's look at the difference between the model's label predictions and actual targets to see whether the model is failing more frequently with certain types of input.\\nSo we've taken our prediction quite far. While we still have a number of options on \\nthe table, it's worth considering the use of a more sophisticated ensemble of models as being a solid option. In this case, leveraging multiple models instead of just one can enable us to obtain the relative advantages of each. To try out an ensemble against this example, run the \\nscore_trolls_blendedensemble.py  script.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 172}),\n",
              " Document(page_content=\"This ensemble is a blended/stacked ensemble. We'll be spending more time discussing how this ensemble works in Chapter 8, Ensemble Methods!\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 172}),\n",
              " Document(page_content=\"Chapter 6[ 151 ]Plotting our results, we can see that performance has improved, but by significantly \\nless than we'd hoped:\\nWe're clearly having some issues with building a model against this data, but at this point, there isn't a lot of value in throwing a more developed model at the problem. We need to go back to our features and aim to extend the feature set.\\nAt this point, it's worth taking some pointers from one of the most successful \\nentrants of this particular Kaggle contest. In general, top-scoring entries tend to be developed by finding all of the tricks around the input data. The second-place contestant in the official Kaggle contest that this dataset was drawn from was  a user named tuzzeg. This contestant provided a usable code repository at\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 173}),\n",
              " Document(page_content=\"https://github.com/tuzzeg/detect_insults .\\nTuzzeg's implementation differs from ours by virtue of much greater thoroughness. In addition to the basic features that we built using POS tagging, he employed POS-based bigrams and trigrams as well as subsequences (created from sliding windows of N-many terms). He worked with n-grams up to 7-grams and created character n-grams of lengths 2, 3, and 4.\\nFurthermore, tuzzeg took the time to create two types of composite model, both \\nof which were incorporated into his solution—sentence level and ranking models. \\nRanking took our rationalization around the nature of the problem a step further  \\nby turning the cases in our data into ranked continuous values.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 173}),\n",
              " Document(page_content=\"Text Feature Engineering[ 152 ]Meanwhile, the innovative sentence-level model that he developed was trained \\nspecifically on single-sentence cases in the training data. For prediction on test data, he split the cases into sentences, evaluated each separately, and took only the highest score for sentences within the case. This was to accommodate the expectation that in natural language, speakers will frequently confine insulting comments to a single part of their speech.\\nTuzzeg's model created over 100 feature groups (where a stem-based bigram is an \\nexample feature group—a group in the sense that the bigram process creates a vector \\nof features), with the most important ones (ranked by impact) being the following:\\nstem subsequence based         0.66\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 174}),\n",
              " Document(page_content=\"stem based (unigrams, bigrams) 0.18char ngrams based (sentence)   0.07char ngrams based              0.04all syntax                     0.006all language models            0.004all mixed                      0.002\\nThis is interesting, in that it suggests that a set of feature translations that we  \\naren't currently using is important in generating a usable solution. Particularly,  \\nthe subsequence-based features are only a short step from our initial feature set, \\nmaking it straightforward to add the extra feature:\\ndef subseq2(n, xs):\\n  l = len(xs)  return ['%s %s' % (xs[i], xs[j]) for i in xrange(l-1) for j in \\nxrange(i+1, i+n+1) if j < l]\\ndef getSubseq2(seqF, n):\\n  def f(row):    seq = seqF(row)    return set(seq + subseq2(n, seq))  return f\\nSubseq2test = getSubseq2(line, 2)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 174}),\n",
              " Document(page_content=\"This approach yields excellent results. While I'd encourage you to export Tuzzeg's \\nown solution and apply it, you can also look at the score_trolls_withsubseq.\\npy script provided in this project's repository to get a feeling for how powerful \\nadditional features can be incorporated.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 174}),\n",
              " Document(page_content=\"Chapter 6[ 153 ]With these additional features added, we see a dramatic improvement in our  \\nAUC score:\\nRunning this code provides a very healthy 0.834  AUC score. This simply goes to \\nshow the power of thoughtful and innovative feature engineering; while the specific \\nfeatures generated in this chapter will serve you well in other contexts, specific hypotheses (such as hostile comments being isolated to specific sentences within a multi-sentence comment) can lead to very effective features.\\nAs we've had the luxury of checking our reasoning against test data throughout this\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 175}),\n",
              " Document(page_content=\"chapter, we can't reasonably say that we've worked under life-like conditions. We didn't take advantage of having access to the test data by reviewing it ourselves, but it's fair to say that knowing what the private leaderboard scored for this challenge made it easier for us to target the right fixes. In Chapter 8, Ensemble Methods, we'll \\nbe working on another tricky Kaggle problem in a more rigorous and realistic way. We'll also be discussing ensembles in depth!\\nFurther reading\\nThe quotes at the start of this chapter were sourced from the highly-readable Kaggle blog, No Free Hunch. Refer to \\nhttp://blog.kaggle.com/2014/08/01/learning-\\nfrom-the-best/ .\\nThere are many good resources for understanding NLP tasks. One fairly thorough, eight-part piece, is available online at\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 175}),\n",
              " Document(page_content='http://textminingonline.com/dive-into-\\nnltk-part-i-getting-started-with-nltk .', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 175}),\n",
              " Document(page_content=\"Text Feature Engineering[ 154 ]If you're keen to get started, one great option is to try Kaggle's for Knowledge \\nNLP task, which is perfectly suited as a testbed for the techniques described in this chapter: \\nhttps://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-\\nfor-beginners-bag-of-words .\\nThe Kaggle contest cited in this chapter is available at https://www.kaggle.com/c/\\ndetecting-insults-in-social-commentary . \\nFor readers interested in further description of the ROC curve and the AUC measure, \\nconsider Tom Fawcett's excellent introduction, available at https://ccrma.\\nstanford.edu/workshops/mir2009/references/ROCintro.pdf . \\nSummary\\nWe've been introduced to a lot of useful and highly applicable skills in this chapter.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 176}),\n",
              " Document(page_content='In this chapter, we took a set of messy, complication-strewn text data and, through a series of rigorous steps, turned it into a large set of effective features. We began by picking up a set of data cleaning skills which stripped out a lot of the noise and problem elements, then we followed up by turning text into features using POS tagging and bag of words. In the process, you learned to apply a set of techniques that are widely applicable and very empowering, enabling us to solve difficult problems in many natural language processing contexts.\\nThrough experimentation with multiple individual models and ensembles,  \\nwe discovered that where a smarter algorithm might not yield a strong result, \\nthorough and creative feature engineering can yield massive improvements in  model performance.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 176}),\n",
              " Document(page_content='[ 155 ]Feature Engineering Part II\\nIntroduction\\nWe have recognized the importance of feature engineering. In the previous chapter, \\nwe discussed techniques that enable us to select from a range of features and work effectively to transform our original data into features, which can be effectively processed by the advanced ML algorithms that we have discussed thus far.\\nThe adage garbage in, garbage out is relevant in this context. In earlier chapters, we \\nhave seen how image recognition and NLP tasks require carefully-prepared data. In this chapter, we will be looking at a more ubiquitous type of data: quantitative or categorical data that is collected from real-world applications.\\nData of the type that we will be working with in this chapter is common to many', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 177}),\n",
              " Document(page_content='contexts. We could be discussing telemetry data captured from sensors in a forest, \\ngame consoles, or financial transactions. We could be working with geological \\nsurvey information or bioassay data collected through research. Regardless,  \\nthe core principles and techniques remain the same.\\nIn this chapter, you will be learning how to interrogate this data to weed out  \\nor mitigate quality issues, how to transform it into forms that are conducive to \\nmachine learning, and how to creatively enhance that data.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 177}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 156 ]In general terms, the concepts that we'll be discussing in this chapter are as follows:\\n• The different approaches to feature set creation and the limits of  \\nfeature engineering\\n• How to use a large set of techniques to enhance and improve an initial dataset\\n• How to tie in and use domain knowledge to understand valid options to \\ntransform and improve the clarity of existing data\\n• How we can test the value of individual features and feature combinations so \\nthat we only keep what we need\\nWhile we will begin with a detailed discussion of the underlying concepts, by the end of this chapter we will be working with multiple, iterative trials and using specialized tests to understand how helpful the features that we are creating will  be to us.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 178}),\n",
              " Document(page_content='Creating a feature set\\nThe most important factor involved in successful machine learning is the quality of your input data. A good model with misleading, inappropriately normalized, or uninformative data will not see the same level of success anywhere near a model run over appropriately prepared data.\\nIn some cases, you have the ability to specify data collection or have access to a \\nuseful, sizeable, and varied set of source data. With the right knowledge and skillset, you can use this data to create highly useful feature sets.\\nIn general, having a strong knowledge as to how to construct good feature sets', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 178}),\n",
              " Document(page_content=\"is very helpful as it enables you to audit and assess any new dataset for missed opportunities. In this chapter, we will introduce a design process and technique set that make it easier to create effective feature sets.\\nAs such, we'll begin by discussing some techniques that we can use to extend or \\nreinterpret existing features, potentially creating a large number of useful parameters to include in our models.\\nHowever, as we will see, there are limitations on the effective use of feature \\nengineering techniques and we need to be mindful of the risks around  engineered datasets.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 178}),\n",
              " Document(page_content='Chapter 7[ 157 ]Engineering features for ML applications\\nWe have discussed what you can do about patching up data quality issues in your \\ndata and we have talked about how you can creatively use dimensions in what you \\nhave to join to external data.\\nOnce you have a reasonably well-understood and quality-checked set of data in \\nfront of you, there is usually still a significant amount of work needed before you can produce effective models from that data.\\nUsing rescaling techniques to improve the learnability of features', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 179}),\n",
              " Document(page_content=\"The main challenge with directly feeding unprepared data to many machine learning models is that the algorithm is sensitive to the relative size of different variables. If your dataset has multiple parameters whose ranges differ, some algorithms will treat the variables whose variance is greater as indicative of more significant change than algorithms with smaller values and less variance.\\nThe key to resolving this potential problem is rescaling, a process by which \\nparameter values' relative size is adjusted while retaining the initial ordering of values within each parameter (a monotonic translation).\\nGradient descent algorithms (which include most deep learning algorithms—\\nhttp://sebastianruder.com/optimizing-gradient-descent/ ) are significantly\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 179}),\n",
              " Document(page_content=\"more efficient if the input data is scaled prior to training. To understand why,  \\nwe'll resort to drawing some pictures. A given series of training steps may  \\nappear as follows:\\nWhen applied to unscaled data, these training steps may not converge effectively (as per the left-hand example in the following diagram).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 179}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 158 ]With each parameter having a differing scale, the parameter space in which models \\nare attempting to train can be highly distorted and complex. The more complex this space, the harder it becomes to train a model within it. This is an involved subject that can be effectively described, in general terms, through a metaphor, but for readers looking for a fuller explanation there is an excellent reference in this chapter's Further reading  section. For now, it is not unreasonable to think in terms \\nof gradient descent models during training as behaving like marbles rolling down a slope. These marbles are prone to getting stuck  in saddle points or other complex\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 180}),\n",
              " Document(page_content=\"geometries on the slope (which, in this context, is the surface created by our model's objective function—the learning function whose output our models typically train to minimize). With scaled data, however, the surface becomes more regularly-shaped and training can become much more effective:\\nThe classic example is a linear rescaling between 0 and 1; with this method, the \\nlargest parameter value is rescaled to 1, the smallest to 0, with intermediate values falling in the 0-1 interval, proportionate to their original size relative to the largest and smallest values. Under such a transformation, the vector [0,10,25,20,18], for \\ninstance, would become [0,0.4, 1, 0.8, 0.72].\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 180}),\n",
              " Document(page_content='The particular value of this transformation is that, for multiple data points that  may vary in magnitude in its raw form, the rescaled features will sit within the  same range, enabling your machine learning algorithm to train on meaningful information content.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 180}),\n",
              " Document(page_content=\"Chapter 7[ 159 ]This is the most straightforward rescaling option, but there are some nonlinear \\nscaling alternatives that can be much more helpful in the right circumstances; these include square scaling, square root scaling, and perhaps most commonly, log-scaling.\\nLog-scaling of parameter values is very common in physics and in contexts \\nwhere the underlying data is frequently affected by a power law (for example, an exponential growth in y given a linear increase in x).\\nUnlike linear rescaling, log-scaling adjusts the relative spacing between data cases. This can be a double-edged sword. On the one hand, log-scaling handles outlying \\ncases very well. Let's take an example dataset describing individual net wealth for\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 181}),\n",
              " Document(page_content='members of a fictional population, described by the following summary statistics:\\nStatistic Wealth\\nMin\\nFirst Quartile\\nMean\\nMedian\\nThird Quartile\\nMax1\\n42.5\\n3205433.343\\n600\\n1358\\n10000000000\\nPrior to rescaling, this population is hugely skewed toward that single individual \\nwith absurd net worth. The distribution of cases per decile is as follows:\\nRange Count of Cases\\n0 > 0.1\\n0.1 > 0.2\\n0.2 > 0.3\\n0.6 > 0.70.3 > 0.4\\n0.7 > 0.80.4 > 0.5\\n0.8 > 0.90.5 > 0.6\\n0.9 > 13060\\n0\\n0\\n00\\n00\\n00\\n1', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 181}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 160 ]After log-scaling, this distribution is far friendlier:\\nRange Count of Cases\\n0 > 0.1\\n0.1 > 0.2\\n0.2 > 0.3\\n0.6 > 0.70.3 > 0.4\\n0.7 > 0.80.4 > 0.50.8 > 0.90.5 > 0.60.9 > 1740\\n1633\\n544\\n0141\\n10\\n01\\n1\\nWe could've chosen to take scaling further and drawn out the first half of this \\ndistribution more by doing that. In this case, log-10 normalization significantly reduces the impact of these outlying values, enabling us to retain outliers in the dataset without losing detail at the lower end.\\nWith this said, it's important to note that in some contexts, that same enhancement  \\nof clustered cases can enhance noise in variant parameter values and create the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 182}),\n",
              " Document(page_content='false impression of greater spacing between values. This tends not to negatively affect how log-scaling handles outliers; the impact is usually seen for groups of smaller-valued cases whose original values are very similar.\\nThe challenges created by introducing nonlinearities through log-scaling are \\nsignificant and in general, nonlinear scaling is only recommended for variables  \\nthat you understand and have a nonlinear relationship or trend underlying them.\\nCreating effective derived variables', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 182}),\n",
              " Document(page_content='Rescaling is a standard part of preprocessing in many machine learning applications (for instance, almost all neural networks). In addition to rescaling, there are other preparatory techniques, which can improve model performance by strategically reducing the number of parameters input to the model. The most common example is of a derived measure that takes multiple existing data points and represents them within a single measure.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 182}),\n",
              " Document(page_content='Chapter 7[ 161 ]These are extremely prevalent; examples include acceleration (as a function of \\nvelocity values from two points in time), body mass index (as a function of height, weight, and age), and price-earnings (P/E) ratio for stock scoring. Essentially, any derived score, ratio, or complex measure that you ever encounter is a combination score formed from multiple components.\\nFor datasets in familiar contexts, many of these pre-existing measures will be  \\nwell-known. Even in relatively well-known areas, however, looking for new \\nsupporting measures or transformations using a mix of domain knowledge and \\nexisting data can be very effective. When thinking through derived measure options, \\nsome useful concepts are as follows:', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 183}),\n",
              " Document(page_content='• Two variable combinations: Multiplication, division, or normalization of the \\nn parameter as a function of the m parameter.\\n• Measures of change over time: A classic example here is acceleration or 7D \\nchange in a measure. In more complex contexts, the slope of an underlying time series function can be a helpful parameter to work with instead of working directly with the current and past values.\\n• Subtraction of a baseline : Using a base expectation (a flat expectation such \\nas the baseline churn rate ) to recast a parameter in terms of that baseline can be', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 183}),\n",
              " Document(page_content='a more immediately informative way of looking at the same variable. For the churn example, we could generate a parameter that describes churn in terms of deviation from an expectation. Similarly, in stock trading cases, we might look at closing price in terms of the opening price.\\n• Normalization: Following on from the previous case, normalization of parameter values based on the values of another parameter or baseline that  is dynamically calculated given properties of other variables. One example here is failed transaction rate; in addition to looking at this value as a raw  (or rescaled) count, it often makes sense to normalize this in terms of attempted transactions.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 183}),\n",
              " Document(page_content=\"Creative recombination of these different elements lets us build very effective scores. Sometimes, for instance, a parameter that tells us the slope of customer engagement (declining or increasing) over time needs to be conditioned on whether that customer was previously highly engaged or hardly engaged, as a slight decline in engagement might mean very different things in each context. It is the data scientist's job to effectively and creatively feature sets that capture these subtleties for a given domain.\\nSo far, this discussion has focused on numerical data. Often, however, useful data \\nis locked up inside non-numeric parameters such as codes or categorical data. \\nAccordingly, we will next discuss a set of effective techniques to turn non-numeric features into usable parameters.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 183}),\n",
              " Document(page_content='Feature Engineering Part II[ 162 ]Reinterpreting non-numeric features\\nA common challenge, which can be problematic and problem-specific, is how  \\nnon-numeric features are treated. Frequently, valuable information is encoded within \\nnon-numerical shorthand values. In the case of stock trades, for instance, the identity of the stock itself (for example, AAPL) as well as that of the buyer and seller is interesting information that we expect to relate meaningfully to our problem. Taking this example further, we might also expect some stocks to trade differently from others even within the industry, and organizational differences within companies, which may occur at some or all points of time, also provide important context.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 184}),\n",
              " Document(page_content=\"One simple option that works in some cases is building an aggregation or series \\nof aggregations. The most obvious example is a count of occurrences with the possibility of creating extended measures (changes in count between two time windows) as described in the preceding section.\\nBuilding summary statistics and reducing the number of rows in the dataset \\nintroduces the risk of reducing the amount of information that your model has available to learn from (increasing the risk of model fragility and overfitting). As such, it's generally a bad idea to extensively aggregate and reduce input data. This \\nis doubly true with deep learning techniques, such as the algorithms discussed and \\nused in Chapters 2-4.\\nRather than extensively using aggregation-based approaches, let's look at an\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 184}),\n",
              " Document(page_content='alternative way of translating string-encoded values into numerical data. Another very popular class of techniques is encoding, with the most common encoding tactic being one-hot encoding. One-hot encoding is the process of turning a series of categorical responses (for example, age groups) into a set of binary variables, with each response option (for example, 18-30) represented by its own binary variable. This is a little more intuitive when presented visually:\\nCase Age Gender\\n1\\n2\\n3\\n4\\n5\\n622M\\n25M\\n34F\\n23M\\n25F\\n41F', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 184}),\n",
              " Document(page_content='Chapter 7[ 163 ]After encoding, this dataset of categorical and continuous variables becomes a tensor \\nof binary variables:\\nCase Age_22 Age_25 Age_41 Gender_M Age_23 Age_34 Gender_F\\n1\\n2\\n3\\n4\\n5\\n610 0 000\\n01 0 000\\n000 01 1\\n000 10 0\\n00 0 00 1\\n00 1 0011\\n1\\n0\\n1\\n0\\n0\\nThe advantage that this presents is significant; it enables us to tap into the very \\nvaluable tag information contained within a lot of datasets without aggregation or risk of reducing the information content of the data. Furthermore, one-hot allows us to separate specific response codes for encoded variables into separate features, meaning that we can identify more or less meaningful codes for a specific variable and only retain the important values.\\nAnother very effective technique, used primarily for text codes, is known as the', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 185}),\n",
              " Document(page_content=\"hash trick . A hash, in simple terms, is a function that translates data into a numeric \\nrepresentation. Hashes will be a familiar concept to many, as they're frequently used to encode sensitive parameters and summarize otherwise bulky data. In order to get the most out of the hash trick, however, it's important to understand how the trick works and what can be done with it.\\nWe can use hashing to turn a text phrase into a numeric value that we can use as \\nan identifier for that phrase. While there are many applications of different hashing algorithms, in this context even a simple hash makes it straightforward to turn string keys and codes into numerical parameters that we can model effectively.\\nA very simple hash might turn each alphabet character into a corresponding number.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 185}),\n",
              " Document(page_content='a would become 1, b would be 2, and so on. Hashes could be generated for words \\nand phrases by summing those values. The phrase cat gifs would translate under this \\nscheme as follows:\\nCat: 3 + 1 + 20\\nGifs: 7 + 9 + 6 + 19Total: 65', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 185}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 164 ]This is a terrible hash for two reasons (quite disregarding the fact that the input \\ncontains junk words!). Firstly, there's no real limit on how many outputs it can present. When one remembers that the whole point of the hash trick is to provide dimensionality reduction, it stands to reason that the number of possible outputs from a hash must be bounded! Most hashes limit the range of numbers that they output, so part of the decision in terms of selecting a hash is related to the number of features you'd prefer your model to have.\\nOne common behavior is to choose a power of two as the hash range; this tends to speed things up by allowing bitwise operations during \\nthe hashing process.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 186}),\n",
              " Document(page_content=\"The other reason that this hash kind of sucks is that changes to the word have a \\nsmall impact rather than a large one. If cat became bat, we'd want our hash output to change substantially. Instead, it changes by one (becoming 64). In general, a good \\nhash function is one where a small change in the input text will cause a large change in the output. This is partly because language structures tend to be very uniform (thus scoring similarly), but slightly different sets of nouns and verbs within a given structure tend to confer very different meanings to one another (the cat sat on the mat versus the car sat on the cat ).\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 186}),\n",
              " Document(page_content=\"So we've described hashing. The hash trick takes things a little further. Hypothetically, turning every word into a hashed numerical code is going to lead to a large number of hash collisions—cases where two words have the same hash value. Naturally, these are rather bad.\\nHandily, there's a distribution underlying how frequently different terms are used \\nthat work in our favor. Called the Zipf distribution , it entails that the probability \\nof encountering the n\\nth most common term is approximated by P(n) = 0.1/n up \\nto around 1,000 (Zipf's law). This entails that each term is much less likely to be encountered than the preceding term. After n = 1000, terms tend to be sufficiently obscure that it's unlikely to encounter two that have the same hash in one dataset.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 186}),\n",
              " Document(page_content=\"At the same time, a good hashing function has a limited range and is significantly \\naffected by small changes in input. These properties make the hash collision chance largely independent of term usage frequency.\\nThese two concepts—Zipf's law and a good hash's independence of hash collision \\nchance and term usage frequency—mean that there is very little chance of a hash collision, and where one occurs it is overwhelmingly likely to be between two infrequently-used words.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 186}),\n",
              " Document(page_content='Chapter 7[ 165 ]This gives the hash trick a peculiar property. Namely, it is possible to reduce \\nthe dimensionality of a set of text input data massively (from tens of thousands of naturally occurring words to a few hundred or fewer) without reducing the performance of a model trained on hashed data, compared to training on unhashed bag-of-words features.\\nProper use of the hash trick enables a lot of possibilities, including augmentations  \\nto the techniques that we discussed (specifically, bag-of-words). References to \\ndifferent hashing implementations are included in the Further reading  section  \\nat the end of this chapter.\\nUsing feature selection techniques\\nNow that we have a good selection of options for feature creation, as well as an', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 187}),\n",
              " Document(page_content='understanding of the creative feature engineering possibilities, we can begin building our existing features into more effective variants. Given this new-found feature engineering skillset, we run the risk of creating extensive and hard-to-manage datasets.\\nAdding features without limit increases the risk of model fragility and overfitting', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 187}),\n",
              " Document(page_content=\"for certain types of models. This is tied to the complexity of the trends that you're attempting to model. In the simplest case, if you're attempting to identify a significant distinction between two large groups, your model is likely to support a large number of features. However, as the model you need to fit to make this distinction becomes more complex and as the group sizes that you have to work with become smaller, adding more and more features can harm the model's ability to classify consistently and effectively.\\nThis challenge is compounded by the fact that it isn't always obvious which\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 187}),\n",
              " Document(page_content=\"parameter or variation is best-suited for the task. Suitability can vary by the underlying model; decision forests, for instance, don't perform any better with monotonic transformations (that is, transformations that retain the initial ordering of \\ndata cases; one example is log-scaling) than with the unscaled base data; however, \\nfor other algorithms, the choice to rescale and the rescaling method used are both \\nvery impactful choices.\\nTraditionally, the quantity of features and limits on the parameter amount were tied \\nto the desire to develop a mathematical function that relates key inputs to the desired outcome scores. In this context, additional parameters needed to be incorporated as moving or nuisance variables.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 187}),\n",
              " Document(page_content='Feature Engineering Part II[ 166 ]Each new parameter introduces another dimension that makes the modeled \\nrelationship more complex and the resultant model more likely to be overfitting the data that exists. A trivial example is if you introduce a parameter that is just a unique label for each case; at this point, your algorithm will just learn those labels, making it very likely that your model fails entirely when introduced to a new dataset.\\nLess trivial examples are no less problematic; the proportion of cases to features \\nbecomes very important when your features are separating cases down to very small \\ngroups. In short, increasing the complexity of the modeled function causes your \\nmodel to be more liable to overfit and adding features can exacerbate this effect.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 188}),\n",
              " Document(page_content=\"According to this principle, we should be beginning with very small datasets and adding parameters only after justifying that they improve the model.\\nHowever, in recent times, an opposing methodology—now generally seen as being \\npart of a common way of doing data science—has gained ground. This methodology \\nsuggests that it's a good idea to add very large feature sets to incorporate every \\npotentially valuable feature and work down to a smaller feature set that does the job.\\nThis methodology is supported by techniques that enable decisions to be made \\nover huge feature sets (potentially hundreds or thousands of features) and that tend to operate in a brute force  manner. These techniques will exhaustively test\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 188}),\n",
              " Document(page_content=\"feature combinations, running models in series or in parallel until the most effective parameter subsets are identified.\\nThese techniques work, which is why this methodology has become popular. It is \\ndefinitely worth knowing about these techniques, if not using them, so you'll be learning how to apply them later in this chapter.\\nThe main disadvantage around using brute force techniques for feature selection \\nis that it becomes very easy to trust the outcomes of the algorithm, irrespective of what the features it selects actually mean. It is sensible to balance the use of highly \\neffective, black-box algorithms against domain knowledge and an understanding of \\nwhat's being undertaken. Therefore, this chapter will enable you to use techniques\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 188}),\n",
              " Document(page_content=\"from both paradigms (build up and build down) so that you can adapt to different contexts. We'll begin by learning how to narrow down the feature set that you have to work with, from many features to the most valuable subset.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 188}),\n",
              " Document(page_content=\"Chapter 7[ 167 ]Performing feature selection\\nHaving built a large  dataset, often the next challenge one faces is how to narrow \\ndown the options to retain only the most effective data. In this section, we'll discuss \\na variety of techniques that support feature selection, working by themselves or as wrappers to familiar algorithms.\\nThese techniques include correlation analysis, regularization techniques, and \\nRecursive Feature Elimination ( RFE). When we're done, you'll be able to confidently \\nuse these techniques to support your selection of feature sets, potentially saving yourself a significant amount of work every time you work with a new dataset!\\nCorrelation\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 189}),\n",
              " Document(page_content=\"We'll begin our discussion of feature selection by looking for a simple source of major problems for regression models: multicollinearity. Multicollinearity is the \\nfancy name for moderate or high degrees of correlation between features in a dataset. \\nAn obvious example is how pizza slice count is collinear with pizza price.\\nThere are two types of multicollinearity: structural and data-based. Structural \\nmulticollinearity occurs when the creation of new features, such as feature f1 from feature f, creates multiple features that may be highly correlated with one another. Data-based multicollinearity tends to occur when two variables are affected by the same causative factor.\\nBoth kinds of multicollinearity can cause some unfortunate effects. In particular, our\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 189}),\n",
              " Document(page_content=\"models' performance tends to become affected by which feature combinations are used; when collinear features are used, the performance of our model will tend  \\nto degrade.\\nIn either case, our approach is simple: we can test for multicollinearity and remove \\nunderperforming features. Naturally, underperforming features are ones that add very little to model performance. They might be underperforming because they replicate information available in other features, or they may simply not provide data that is meaningful to the problem at hand. There are multiple ways to test for weak features as many feature selection techniques will sift out multicollinear feature combinations and recommend their removal if they're underperformant.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 189}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 168 ]In addition, there is a specific multicollinearity test that's worth considering; namely,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 190}),\n",
              " Document(page_content='inspecting the eigenvalues of our data\\'s correlation matrix. Eigenvectors and eigenvalues are fundamental concepts in the matrix theory with many prominent applications. More details are given at the end of this chapter. For now, suffice it to say that eigenvalues in the correlation matrix generated by our dataset provide us with a quantified measure of multicollinearity. Consider a set of eigenvalues as indicative of how much \"new information content\" our features bring to the dataset; a low eigenvalue suggests that the data may be correlated with other features. For an example of this at work, consider the following code, which creates a feature set and then adds collinearity to features 0, 2, and 4:\\nimport numpy as np\\nx = np.random.randn(100, 5)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 190}),\n",
              " Document(page_content=\"noise = np.random.randn(100)x[:,4] = 2 * x[:,0] + 3 * x[:,2] + .5 * noise \\nWhen we generate the correlation matrix and compute eigenvalues, we find the \\nfollowing:\\ncorr = np.corrcoef(x, rowvar=0)\\nw, v = np.linalg.eig(corr)\\nprint('eigenvalues of features in the dataset x')\\nprint(w)\\neigenvalues of features in the dataset x\\n[ 0.00716428  1.94474029  1.30385565  0.74699492  0.99724486]\\nClearly, our 0th feature is suspect! We can then inspect the eigenvalues of this feature \\nvia calling v:\\nprint('eigenvalues of eigenvector 0')\\nprint(v[:,0])\\neigenvalues of eigenvector 0\\n[-0.35663659 -0.00853105 -0.62463305  0.00959048  0.69460718]\\nFrom the small values of features in position one and three, we can tell that features\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 190}),\n",
              " Document(page_content='2 and 4 are highly multicollinear with feature 0. We ought to remove two of these \\nthree features before proceeding!', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 190}),\n",
              " Document(page_content='Chapter 7[ 169 ]LASSO\\nRegularized methods are among the most helpful feature selection techniques as \\nthey provide sparse solutions: ones where weaker features return zero, leaving only a subset of features with real coefficient values.\\nThe two most used regularization models are L1 and L2 regularization, referred to as \\nLASSO and ridge regression respectively in linear regression contexts.\\nRegularized methods function by adding a penalty to the loss function. Instead \\nof minimizing a loss function E(X,Y), the penalty leads to E(X,Y) + a||w||. The \\nhyperparameter a relates to the amount of regularization (enabling us to tune the \\nstrength of our regularization and thus the proportion of the original feature set that is selected).', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 191}),\n",
              " Document(page_content=\"In LASSO regularization, the specific penalty function used is α∑ni=1|wi|. Each \\nnon-zero coefficient adds to the size of the penalty term, forcing weaker features to return coefficients of 0. Selecting an appropriate penalty term can be achieved using scikit-learn's parameter optimization support for hyperparameters. In this case, we'll be using \\nestimator.get_params()  to perform a grid search for appropriate \\nhyperparameter values. For more information on how grid searches operate, see the Further reading  section at the end of this chapter.\\nIn scikit-learn, logistic regression is provided with an L1 penalty for classification. Meanwhile, the LASSO module is provided for linear regression. For now, let's\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 191}),\n",
              " Document(page_content='begin by applying LASSO to an example dataset. In this case, we\\'ll use the Boston housing dataset:\\nfromsklearn.linear_model import Lasso\\nfromsklearn.preprocessing import StandardScalerfromsklearn.datasets import load_boston\\nboston = load_boston()\\nscaler = StandardScaler()X = scaler.fit_transform(boston[\"data\"])Y = boston[\"target\"]names = boston[\"feature_names\"]\\nlasso = Lasso(alpha=.3)\\nlasso.fit(X, Y)\\nprint \"Lasso model: \", pretty_print_linear(lasso.coef_, names, sort = \\nTrue)\\nLasso model: -3.707 * LSTAT + 2.992 * RM + -1.757 * PTRATIO + -1.081 \\n* DIS + -0.7 * NOX + 0.631 * B + 0.54 * CHAS + -0.236 * CRIM + 0.081 * ZN + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 191}),\n",
              " Document(page_content='Feature Engineering Part II[ 170 ]Several of the features in the original set returned a correlation of 0.0. Increasing the \\ncorrelation makes the solution increasingly sparse. For instance, we see the following \\nresults when alpha = 0.4 :\\nLasso model: -3.707 * LSTAT + 2.992 * RM + -1.757 * PTRATIO + -1.081 * DIS + -0.7 * NOX + 0.631 * B + 0.54 * CHAS + -0.236 * CRIM + 0.081 * ZN + -0.0 * INDUS + -0.0 * AGE + 0.0 * RAD + -0.0 * TAX\\nWe can immediately see the value of L1 regularization as a feature selection technique. However, it is important to note that L1 regularized regression is unstable. Coefficients can vary significantly, even with small data changes, when features in the data are correlated.\\nThis problem is effectively addressed with L2 regularization, or ridge regression,', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 192}),\n",
              " Document(page_content=\"which develops  a feature coefficient with different applications. L2 normalization \\nadds an additional penalty, the L2 norm penalty, to the loss function. This penalty takes the form (a∑ni=1w2i). A sharp-eyed reader will notice that, unlike the L1 penalty (α∑ni=1|wi|), the L2 penalty uses squared coefficients. This causes the coefficient values to be spread out more evenly and has the added effect that correlated features tend to receive similar coefficient values. This significantly improves stability as the coefficients no longer fluctuate on small data changes.\\nHowever, L2 normalization isn't as directly useful for feature selection as L1. Rather,\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 192}),\n",
              " Document(page_content='as interesting features (with predictive power) tend to have non-zero coefficients, L2 is more useful as an exploratory tool allowing inference about the quality of features in the classification. It has the added merit of being more stable and reliable than L1 \\nregularization.\\nRecursive Feature Elimination\\nRFE is a greedy, iterative process that functions as a wrapper over another model, \\nsuch as an SVM (SVM-RFE), which it repeatedly runs over different subsets of the input data.\\nAs with LASSO and ridge regression, our goal is to find the best-performing feature', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 192}),\n",
              " Document(page_content='subset. As the name suggests, on each iteration a feature is set aside allowing the process to be repeated with the rest of the feature set until all features in the dataset have been eliminated. The ordering with which features are eliminated becomes their rank. After multiple iterations with incrementally smaller subsets, each feature is accurately scored and relevant subsets can be selected for use.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 192}),\n",
              " Document(page_content=\"Chapter 7[ 171 ]To get a better understanding of how this works, let's look at a simple example. We'll \\nuse the (by now familiar) digits dataset to understand how this approach works in practice:\\nprint(__doc__)\\nfrom sklearn.svm import SVC\\nfromsklearn.datasets import load_digitsfromsklearn.feature_selection import RFE\\nimportmatplotlib.pyplot as plt\\ndigits = load_digits()\\nX = digits.images.reshape((len(digits.images), -1))y = digits.target\\nWe'll use an SVM as our base estimator via the SVC operator for Support Vector \\nClassification (SVC). We then apply the RFE wrapper over this model. RFE takes \\nseveral arguments, with the first being a reference to the estimator of choice. The second argument is \\nn_features_to_select , which is fairly self-explanatory. In\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 193}),\n",
              " Document(page_content='cases where the feature set contains many interrelated features whose subsets possess multivariate distributions that are highly effective classification features, it\\'s possible to opt for feature combinations of two or more.\\nStepping enables the removal of multiple features on each iteration. When given \\na value between 0.0 and 1.0, each step enables the removal of a percentage of the feature set, corresponding to the proportion given in the step argument:\\nsvc = SVC(kernel=\"linear\", C=1)\\nrfe = RFE(estimator=svc, n_features_to_select=1, step=1)rfe.fit(X, y)ranking = rfe.ranking_.reshape(digits.images[0].shape)\\nplt.matshow(ranking)\\nplt.colorbar()plt.title(\"Ranking of pixels with RFE\")plt.show()', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 193}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 172 ]Given that we're familiar with the digits dataset, we know that each instance is an \\n8 x 8 image of a handwritten digit, as shown in the following image. Each image is located in the center of the 8 x 8 grid:\\nWhen we apply RFE over the digits dataset, we can see that it broadly captures this information in applying a ranking:\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 194}),\n",
              " Document(page_content=\"Chapter 7[ 173 ]The first pixels to be cut were in and around the (typically empty) vertical edges of \\nthe image. Next, the algorithm began culling normally whitespace areas around the vertical edges or near the top of the image. The pixels that were retained longest were those that enabled the most differentiation between the different characters—pixels that would be present for some numbers and not for others.\\nThis example gives us great visual confirmation that RFE works. What it doesn't \\ngive us is evidence for how consistently the technique works. The stability of RFE \\nis dependent on the stability of the base model and, in some cases, ridge regression \\nwill provide a more stable solution. (For more information on which cases and the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 195}),\n",
              " Document(page_content='conditions involved, consult the Further reading  section at the end of this chapter.)\\nGenetic models\\nEarlier in this chapter, we discussed the existence of algorithms that enable feature selection with very large parameter sets. Some of the most prominent techniques of this type are genetic algorithms, which emulate natural selection to generate increasingly effective models.\\nA genetic solution for feature selection works roughly as follows:\\n• An initial set of variables (predictors is the term typically used in this \\ncontext) are combined into multiple subsets (candidates) and a performance \\nmeasure is calculated for each candidate\\n• The predictors from candidates with the best performance are randomly \\nrecombined into a new iteration (generation) of models', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 195}),\n",
              " Document(page_content='• During this recombination step, for each subset there is the  probability of a mutation, whereby a predictor may be added or removed from a subset\\nThis algorithm typically iterates for multiple generations. The appropriate iteration amount is dependent on the complexity of the dataset and the model required. As with gradient descent techniques, the typical relationship between the performance and iteration count is present for genetic algorithms, where performance improvement declines nonlinearly as the count of iterations increases, eventually hitting a minimum before the overfitting risk increases.\\nTo find an effective iteration count, we can perform testing using training data; by \\nrunning the model for a large number of iterations and plotting the Root Mean', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 195}),\n",
              " Document(page_content=\"Squared Error (RMSE), we're able to find an appropriate amount of iterations given our input data and model configuration.\\nLet's talk in a little more detail about what happens within each generation. \\nSpecifically, let's talk about how candidates are created, how performance is scored, and how recombination is performed.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 195}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 174 ]The candidates are initially configured to use a random sample of the available \\npredictors. There is no hard and fast rule concerning how many predictors to use in the first generation; it depends on how many features are available, but it's common to see first generation candidates using 50% to 80% of the available features (with a smaller percentage used in cases with more features).\\nThe fitness measure can be difficult to define, but a common practice is to use two \\nforms of cross-validation. Internal cross-validation (testing each model solely in the \\ncontext of its own parameters without comparing models) is typically used to track \\nperformance at a given iteration; the fitness measures from internal cross-validation\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 196}),\n",
              " Document(page_content='are used to select models to recombine in the next generation. External cross-validation (testing against a dataset that was not used in validation at any iteration) is also needed in order to confirm that the search process produced a model that has not overfitted to the internal training data.\\nRecombination is controlled by three key parameters: mutation, cross-over \\nprobabilities, and elitism. The latter is an optional parameter that one may use to \\nreserve n-many of the top-performing models from the current generation; by doing so, one may preserve particularly effective candidates from being lost entirely during recombination. This can be done while also using that candidate in mutated variants \\nand/or using them as parents to next-generation candidates.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 196}),\n",
              " Document(page_content='The mutation probability defines the chance of a next-generation model being \\nrandomly readjusted (via some predictors, typically one, being added or removed). Mutation tends to help the genetic algorithm maintain a broad coverage of the candidate variables, reducing the risk of falling into a parameter-local solution.\\nCross-over probability defines the likelihood that a pair of candidates will', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 196}),\n",
              " Document(page_content=\"be selected for recombination into a next-generation model. There are several  cross-over algorithms: parts of each parent's feature set might be spliced (for example, first half/second half) into the child or a random selection of each parent's features might be used. Common features to both parents might also be used by default. Random sampling from the set of both parent's unique predictors is a common default approach.\\nThese are the main parts of a general genetic algorithm, which can be used as a \\nwrapper to existing models (logistic regression, SVM, and others). The technique \\ndescribed here can be varied in many different ways and is related to feature selection\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 196}),\n",
              " Document(page_content=\"techniques used slightly differently across multiple quantitative fields. Let's take the theory that we've covered thus far and start applying it to a practical example.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 196}),\n",
              " Document(page_content=\"Chapter 7[ 175 ]Feature engineering in practice\\nDepending on the modeling technique that you're using, some of this work may be \\nmore valuable than other parts. Deep learning algorithms tend to perform better on less-engineered data than shallower models and it might be that less work is needed to improve results.\\nThe key to understanding what is needed is to iterate quickly through the whole \\nprocess from dataset acquisition to modeling. On a first pass with a clear target for model accuracy, find the acceptable minimum amount of processing and perform that. Learn whatever you can about the results and make a plan for the next iteration.\\nTo show how this looks in practice, we'll work with an unfamiliar, high-dimensional\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 197}),\n",
              " Document(page_content=\"dataset, using an iterative process to generate increasingly effective modeling.\\nI was recently living in Vancouver. While it has many positive qualities, one of the \\nworst things about living in the city was the somewhat unpredictable commute. Whether I was traveling by car or taking Translink's Skytrain system (a monorail-meets-rollercoaster high-speed line), I found myself subject to hard-to-predict delays and congestion issues.\\nIn the spirit of putting our new feature engineering skillset into practice, let's take a \\nlook at whether we can improve this experience by taking the following steps:\\n• Writing code to harvest data from multiple APIs, including text and  climate streams\\n• Using our feature engineering techniques to derive variables from this  initial data\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 197}),\n",
              " Document(page_content=\"• Testing our feature set by generating commute delay risk scores\\nUnusually, in this example, we'll focus less on building and scoring a highly performant model. Instead, our focus is on creating a self-sufficient solution that you can adjust and apply for your own local area. While it suits the goals of the current chapter to take this approach, there are two additional and important motivations.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 197}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 176 ]Firstly, there are some challenges around sharing and making use of Twitter data. \\nPart of the terms of use of Twitter's API is an obligation on the developer to ensure that any adjustments to the state of a timeline or dataset (including, for instance, the deletion of a tweet) are reproduced in datasets that are extracted from Twitter and publicly shared. This makes the inclusion of real Twitter data in this chapter's GitHub repository impractical. Ultimately, this makes it difficult to provide reproducible results from any downstream model based on streamed data because users will need to build their own stream and accumulate data points and because variations in context (such as seasonal variations) are likely to affect model performance.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 198}),\n",
              " Document(page_content=\"The second element here is simple enough: not everybody lives in Vancouver! In \\norder to generate something of value to an end user, we should think in terms of an adjustable, general solution rather than a geographically-specific one.\\nThe code presented in the next section is therefore intended to be something to build \\nfrom and develop. It offers potential as the basis of a successful commercial app \\nor simply a useful, data-driven life hack. With this in mind, review this chapter's \\ncontent (and leverage the code in the associated code directory) with an eye to finding and creating new applications that fit your own situation, locally available data, and personal needs.\\nAcquiring data via RESTful APIs\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 198}),\n",
              " Document(page_content=\"In order to begin, we're going to need to collect some data! We're going to need to look for rich, timestamped data that is captured at sufficient frequency (preferably at least one record per commute period) to enable model training.\\nA natural place to begin with is the Twitter API, which allows us to harvest recent \\ntweet data. We can put this API to two uses.\\nFirstly, we can harvest tweets from official transit authorities (specifically, bus and \\ntrain companies). These companies provide transit service information on delays \\nand service disruptions that, helpfully for us, takes a consistent format conducive to \\ntagging efforts.\\nSecondly, we can tap into commuter sentiment by listening for tweets from the\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 198}),\n",
              " Document(page_content='geographical area of interest, using a customized dictionary to listen for terms related to cases of disruption or the causes thereof.\\nIn addition to mining the Twitter API for data to support our model, we can \\nleverage other APIs to extract a wealth of information. One particularly valuable source of data is the Bing Traffic API. This API can be easily called to provide traffic congestion or disruption incidents across a user-specified geographical area.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 198}),\n",
              " Document(page_content=\"Chapter 7[ 177 ]In addition, we can leverage weather data from the Yahoo Weather API. This API \\nprovides the current weather for a given location, taking zip codes or location input. It provides a wealth of local climate information including, but not limited to, temperature, wind speed, humidity, atmospheric pressure, and visibility. Additionally, it provides a text string description of current conditions as well as forecast information.\\nWhile there are other data sources that we can consider tying into our analysis, we'll \\nbegin with this data and see how we do.\\nTesting the performance of our model\\nIn order to meaningfully assess our commute disruption prediction attempt, we \\nshould try to define test criteria and an appropriate performance score.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 199}),\n",
              " Document(page_content=\"What we're attempting to do is identify the risk of commute disruption on the \\ncurrent day, each day. Preferably, we'd like to know the commute risk with  \\nsufficient advance notice that we can take action to mitigate it (for example,  \\nby leaving home earlier).\\nIn order to do this, we're going to need three things:\\n• An understanding of what our model is going to output\\n• A measure we can use to quantify model performance\\n• Some target data we can use to score model performance according to  \\nour measure\\nWe can have an interesting discussion about why this matters. It can be argued, \\neffectively, that some models are information in purpose. Our commute risk score,  \\nit might be said, is useful insofar as it generates information that we didn't previously have.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 199}),\n",
              " Document(page_content=\"The reality of the situation, however, is that there is inalienably going to be a \\nperformance criterion. In this case, it might simply be my satisfaction with the \\nresults output by my model, but it's important to be aware that there is always some performance criterion at play. Quantifying performance is therefore valuable, even in contexts where a model appears to be informational (or even better, unsupervised). \\nThis makes it prudent to resist the temptation to waive performance testing; at least \\nthis way, you have a quantified performance measure to iteratively improve on.\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 199}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 178 ]A sensible starting point is to assert that our model is intended to output a numerical \\nscore in a 0-1 range for outbound (home to work) commutes on a given day. We  have a few options with regard to how we present this score; perhaps the most obvious option would be to apply a log rescaling to the data. There are good reasons to log-scale and in this situation it might not be a bad idea. (It's not unlikely that the distribution of commute delay time obeys a power law.) For now, we won't reshape this set of scores. Instead, we'll wait to review the output of our model.\\nIn terms of delivering practical guidance, a 0-1 score isn't necessarily very helpful. \\nWe might find ourselves wanting to use a bucketed system (such as high risk, mid\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 200}),\n",
              " Document(page_content=\"risk, or low risk) with bucket boundaries at specific boundaries in the 0-1 range. In short, we would transition to treating the problem as a multiclass classification problem with categorical output (class labels), rather than as a regression problem with a continuous output.\\nThis might improve model performance. (More specifically, because it'll increase \\nthe margin of free error to the full breadth of the relevant bucket, which is a very \\ngenerous performance measure.) Equally though, it probably isn't a great idea to introduce this change on the first iteration. Until we've reviewed the distribution of real commute delays, we won't know where to draw the boundaries between classes!\\nNext, we need to consider how we measure the performance of our model. The\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 200}),\n",
              " Document(page_content=\"selection of an appropriate scoring measure generally depends on the characteristics of the problem. We're presented with a lot of options around classifier performance scoring. (For more information around performance measures for machine learning algorithms, see the Further reading  section at the end of this chapter.)\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 200}),\n",
              " Document(page_content=\"One way of deciding which performance measure is suitable for the task at hand is to consider the confusion matrix. A confusion matrix is a table of contingencies; in the context of statistical modeling, they typically describe the label prediction versus actual labels. It is common to output a confusion matrix (particularly for multiclass problems with more classes) for a trained model as it can yield valuable information about classification failures by failure type and class.\\nIn this context, the reference to a confusion matrix is more illustrative. We can \\nconsider the following simplified matrix to assess whether there is any contingency \\nthat we don't care about:\\nPredictionActual Result\\nTrue Positive\\nTrue NegativeFalse Positive\\nFalse NegativeFALSE\\nTRUE\\nFALSETRUE\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 200}),\n",
              " Document(page_content='Chapter 7[ 179 ]In this case, we care about all four contingency types. False negatives will cause us \\nto be caught in unexpected delays, while false positives will cause us to leave for our commute earlier than necessary. This implies that we want a performance measure that values both high sensitivity (true positive rate) and high specificity (false positive rate). The ideal measure, given this, is area under the curve (AUC).\\nThe second challenge is how to measure this score; we need some target against \\nwhich to predict. Thankfully, this is quite easy to obtain. I do, after all, have a daily \\ncommute to do! I simply began self-recording my commute time using a stopwatch, \\na consistent start time, and a consistent route.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 201}),\n",
              " Document(page_content=\"It's important to recognize the limitations of this approach. As a data source, I am \\nsubject to my own internal trends. I am, for instance, somewhat sluggish before my \\nmorning coffee. Similarly, my own consistent commute route may possess local \\ntrends that other routes do not. It would be far better to collect commute data from a \\nnumber of people and a number of routes.\\nHowever, in some ways, I was happy with the use of this target data. Not least\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 201}),\n",
              " Document(page_content=\"because I am attempting to classify disruption to my own commute route and would not want natural variance in my commute time to be misinterpreted through training, say, against targets set by some other group of commuters or routes. In addition, given the anticipated slight natural variability from day-to-day, should be disregarded by a functional model.\\nIt's rather hard to tell what's good enough in terms of model performance. More\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 201}),\n",
              " Document(page_content=\"precisely, it's not easy to know when this model is outperforming my own expectations. Unfortunately, not only do I not have any very reliable with regard to the accuracy of my own commute delay predictions, it also seems unlikely that one person's predictions are generalizable to other commutes in other locations. It seems ill-advised to train a model to exceed a fairly subjective target.\\nLet's instead attempt to outperform a fairly simple threshold—a model that naively \\nsuggests that every single day will not contain commute delays. This target has the \\nrather pleasing property of mirroring our actual behavior (in that we tend to get up each day and act as though there will not be transit disruption).\\nOf the 85 target data cases, 14 commute delays were observed. Based on this target\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 201}),\n",
              " Document(page_content='data and the score measure we created, our target to beat is therefore 0.5.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 201}),\n",
              " Document(page_content=\"Feature Engineering Part II[ 180 ]Twitter\\nGiven that we're focusing this example analysis on the city of Vancouver, we have an \\nopportunity to tap into a second Twitter data source. Specifically, we can use service \\nannouncements from Vancouver's public transit authority, Translink.\\nTranslink Twitter\\nAs noted, this data is already well-structured and conducive both to text mining and \\nsubsequent analysis; by processing this data using the techniques we reviewed in the last two chapters, we can clean the text and then encode it into useful features.\\nWe're going to apply the Twitter API to harvest Translink's tweets over an extended\", metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 202}),\n",
              " Document(page_content='period. The Twitter API is a pretty friendly piece of kit that is easy enough to work with from Python. (For extended guidance around how to work with the Twitter API, see the Further reading  section at the end of this chapter!) In this case, we want \\nto extract the date and body text from the tweet. The body text contains almost everything we need to know, including the following:\\n• The nature of the tweet (delay or non-delay)\\n• The station affected\\n• Some information as to the nature of the delay', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 202}),\n",
              " ...]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYSX5GKRUqso",
        "outputId": "27da3212-6379-4592-f2bb-ed69cfb57825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ],
      "source": [
        "embeddings_model_repo = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "model_kwargs={'device' : 'cpu'}\n",
        "embeddings = HuggingFaceInstructEmbeddings( model_name =embeddings_model_repo , model_kwargs={'device' : 'cpu'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NzC5x-oGNas"
      },
      "outputs": [],
      "source": [
        "vectordb = FAISS.from_documents(\n",
        "   documents = texts,\n",
        "    embedding = embeddings\n",
        " )\n",
        "\n",
        "\n",
        "vectordb.save_local(\"faiss_index_hp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cxN4-cyNB0h",
        "outputId": "f7c3f382-8f8d-493b-993d-680df2aea7e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceInstructEmbeddings(client=INSTRUCTOR(\n",
              "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: T5EncoderModel \n",
              "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})\n",
              "  (2): Dense({'in_features': 1024, 'out_features': 768, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
              "  (3): Normalize()\n",
              "), model_name='hkunlp/instructor-large', cache_folder=None, model_kwargs={'device': 'cpu'}, encode_kwargs={'normalize_embeddings': True}, embed_instruction='Represent the document for retrieval: ', query_instruction='Represent the question for retrieving supporting documents: ')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "d1vIyZ7a3Yes",
        "outputId": "2b133ff3-ded6-4319-cc3b-8ddec8cf303a"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "VectorStore.from_documents() missing 1 required positional argument: 'embedding'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2896a8577c14>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vectordb = FAISS.from_documents(\n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: VectorStore.from_documents() missing 1 required positional argument: 'embedding'"
          ]
        }
      ],
      "source": [
        "vectordb = FAISS.from_documents(\n",
        "   documents = texts,\n",
        " )\n",
        "\n",
        "\n",
        "vectordb.save_local(\"faiss_index_hp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392,
          "referenced_widgets": [
            "aa749b201b324e45aeb3fdc5e157503e",
            "3157ee66557d4e14b53d41aa49cf6640",
            "59103fb636264a80ba02321c1e3ebd3e",
            "0f8b8a58b8734425b31d46b14ad5a8e2",
            "35e3acb9aae045d8a1391604ac897cb8",
            "b458336632f14d2fa74055e635813371",
            "8adf7de5f1ad41e585fb9c379880509c",
            "67c4cc30296d4062a19a922f706864af",
            "daa2c8d82417425ea17b305124d034dc",
            "cacfbbd5d1f0470ca42890b58e4e6900",
            "4e76f629d9e54132be7871116423478b",
            "9c983a3b243148d7b2b07804d83234b4",
            "f7d917c921d7453cad9bf1425c07f52c",
            "8a1f71c8bfde4dfe9ddffb44409a6984",
            "9f94d3b420e8458eb4e967b309e5eca7",
            "8cbba5df11334b25b163c648cd1c208b",
            "d2fb00280a2640c1863b191907bde088",
            "2e393313728d4e9b96c1baaa2deecddc",
            "da0ba7fe26044178b07ee58e7e0eac25",
            "c2b0326344c7466fa45233158130240a",
            "6a41f6cb59b24148b295b1a77427e3fe",
            "e2de896af414409694d262688b76f067",
            "f37b04d31ef1455681b98a753b5476f4",
            "a4d31b1ee2a04d8e8e52175e64ddc680",
            "b0e673ec01cb4441b0b4639b1775c456",
            "f9b5ecd847114027aa278510e4c18e45",
            "fa58782683944545806e8d7a03905e95",
            "ca3926a9bcef4a19935e2f0992e6e06b",
            "1c97412b5f9d4e4db3297c57905578b7",
            "3ad21d7db87344c0b0cde9429ae793c4",
            "9d44a35228414e86a89e06e66434e975",
            "3fd9226875e34d319c90b6cd88870906",
            "36e65a8cc7f043f0b5a6491f6e3b53aa",
            "847dea87798f4170bf539bf8318aa3cb",
            "c650c033bcb24c779a9891b54b8da219",
            "725ae83c8383490ea8453f72b442c724",
            "d60dbf7f818e4e568fc06863ced521b7",
            "592cda2bc1d34f70a75376a5b3de8185",
            "807ce00e629149678b3649d6c02ff67f",
            "832cc49113c34d30b562e476575b983a",
            "04c2d4da2321438aaea32902fc31a451",
            "10a4932afe7147918172123bb9ffe416",
            "5e7e0c9643d34180a052fb314b8735cd",
            "ebff15f9b7454673bb928d675e3291c1",
            "9ff517288f9f476ca968c40d2a9bf31f",
            "33baa38c764c4fc686bc143365c7f9db",
            "536f6d8687af4aa088f2c2785a9642cb",
            "3eb6be301f9d463b99a0915a383a7d34",
            "e5d50c4598f54f1abb2ef0d2e9ca95a5",
            "aa5409bf2a3e4bc3a94d12ef12a4b78e",
            "fec3e04becb747298b19260748b874c5",
            "f0bf1d5f74624e67b0abb332db9bd0ff",
            "f7c1ab76a81e470fb99b82fcaf4cd48b",
            "083d5e6997934b2ba15497ec6bc6dfeb",
            "2cb1417b3f744068a2d4499b4e20db9a",
            "8fd526d2804f4e71b87772cf52c32b22",
            "b16d6a22389e4417b44f2982c961385a",
            "d77c2b0dba0847d890ec8f820171ddd2",
            "628a3e3bbad84d5fa31746f0785ee83c",
            "26a2f0efb882499cadac357508949bba",
            "cf4533176d8245689c371b1233aba2ec",
            "2e1ebe881b5a42c58587569ba4bc4ee5",
            "7a80a188e9a24f81b692cb09dd13eef0",
            "bfee76eb8c9a47fab2022c181637328d",
            "d6051ad35b6940cda73df32a26f10030",
            "5afc0e55770a47adbe26702253d75e48",
            "fc180f1b45ec4021bd1a7d9b3e1290e0",
            "d62ca963a7e7456a9cdee2c2bbdc70c8",
            "d324f2f3b7b34f3ab502c66049b6b430",
            "b16948b1fd5049bb83329fc2077c1987",
            "44e0b472a17c47448adca9c581bb4e85",
            "c672691d80c0473bb3bc44f62e32a9f2",
            "d93e401dd97a4cef86d8c80fed16a98c",
            "7ad73ea5e1be4a359ecd7cbc49508043",
            "f524b286d88c4299939f7906985703e8",
            "de7ffa395c5e4da185a855beb5bac22a",
            "37db1a7ca2a747d3954eb566627c3911",
            "d68fbc522dde4d239d4f93ae2bf77b46",
            "cd0a39ae7243412eab43e5c2f22a1e32",
            "8783f0c5e28d4617a3d2dd0ef7db294a",
            "693fdc2e9673430397a39108a134779f",
            "8d6c0dd8a26840e88f68653fe5108ec1",
            "87bb5591bb1b4c25bb860a8db09babdc",
            "0cf0768f4e1f42d595c47576b8f66dac",
            "b3b395c628e24112b0c2187fbac8495e",
            "634c2d37c5654255824ca4aa2c243b10",
            "fdb3284aa4ff4e4499b2bda1c6912829",
            "e9ccb4056dde4e7ebddc7e2307e9707d",
            "08b81dc7346f42e19952fe558c8dc794",
            "d59310db9e3648f1bdeabc9977802db3",
            "215a1399eef14948a7b639fd01b43a6f",
            "f83837f7cbe7456b9e8166e0ac6feb8b",
            "f16044a1afd8473f9aa57c634b8cfab8",
            "6b7ef3b2f2b04fee8efcac86d1585f17",
            "ba5ab4eec6b7462593eca772a51ab824",
            "e53ef8648d164a15ac19c333af8607eb",
            "1ed9a795e8ce4b3f8347b1f85f774ad0",
            "aada6b037a004280883eefe043492884",
            "beace35c737c42c9828e1586ef91a71c",
            "4eab4ca01651413c90222e245898239d",
            "eea49467fbba44d29ba25baf467ffbed",
            "3d560adf019b486f8afc19c86a320fa5",
            "237d93fdf956493aad5a15a916b90b46",
            "a0567ca8e9f54e829bb77722e92f243a",
            "8406164b0d0f43f8bb081cd49f4246ec",
            "757a0f0ba8724da9a6fbf73aba5de82f",
            "13561401a97e410c806ffbea1d2d39c4",
            "4fe012ddf2544d99af73c79f2cea3942",
            "7a96b3bc8f054a4485513b036f44afa9",
            "78ba450cf295426697f02800c5a2a060"
          ]
        },
        "id": "6guvrgzu2abo",
        "outputId": "d00cbfce-6135-4c11-ef58-c0d26587d7c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa749b201b324e45aeb3fdc5e157503e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c983a3b243148d7b2b07804d83234b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f37b04d31ef1455681b98a753b5476f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "847dea87798f4170bf539bf8318aa3cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ff517288f9f476ca968c40d2a9bf31f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd526d2804f4e71b87772cf52c32b22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc180f1b45ec4021bd1a7d9b3e1290e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d68fbc522dde4d239d4f93ae2bf77b46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08b81dc7346f42e19952fe558c8dc794",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eab4ca01651413c90222e245898239d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666,
          "referenced_widgets": [
            "6018d3f9fe8448338bcacdfde0700455",
            "d78137388b2748a4aeb8a6f21dcc0d23",
            "075f3c66bf564908beb879619f6a1d2c",
            "fc54d4668a304b219dc905aedcf037b1",
            "0c2db96c1aa34ddda9e27121e97a19fe",
            "e5ac4540ecb74e789551ae70c0c6f37e",
            "8436ebf7f3df4257bf92a8df31c72826",
            "fbd2ba16f5a14916855d10412a02c035",
            "5c06337837d848e2a129deb492a64e9f",
            "987b0d9fae584ed599532a5889b6db40",
            "541e19804f044767a955876ed8473564",
            "250d521edb1f4561a29ddb57c0932832",
            "76294695cb1a405c9610be93737afca6",
            "9d8d8818e5904c8f8e0a09d6995d624e",
            "44d1cc5e82dd47f4854628d4d5f60a75",
            "b0964b0c43d64388abe1d9348f76dfe1",
            "e6345d06513b454b91792470ed1b0cc0",
            "b8f3ba97542d451fad66ebcf873c3dbe",
            "6e886eb6e7ff41af899ecc8d90fd9591",
            "3419b259f07b4cca86eab685d05d6e74",
            "0b7445166ed1432c9a21c704d58a5cca",
            "d575e8b440c14398a6cd7abb22f579a6",
            "2b171340475e41228aa0b8868a7c5785",
            "b4172c6cfc044be99a91b4c28588d5d1",
            "04c6bd1809b447589de233d7798f8681",
            "dc6d6df107e544758eb14241b8072628",
            "125eeaa48d334bc6a676eb0604845da0",
            "18c56170974c426088c9f98cc4929ec6",
            "087f3fb3dece4ba38f11d8e1337d81b1",
            "0e297f34245044af921062cbe294695b",
            "59b2f52edd1b4d0a9a3a34293584e52c",
            "b2be3e3f50da4675924526a47e507172",
            "6a79e4c345484b0aa3c4cef1f02f0fec",
            "179c1ae7a1f942bbb15cd3babfc5489b",
            "e611461bbf9345c29b2fa329959ec4c3",
            "cedddddd215f4932bf42a08b45ddf93e",
            "566c1dc0339b45b6a7de7c370aac74f3",
            "6b1fa95f7529411c946ae1889dff8371",
            "ddc126a925e44ecbbc4ba708fb1cfc53",
            "d023c3c6081a4a77a3fb6de417b0c0af",
            "fbb3c007568b48e79ea453d213881697",
            "0d0b63e006214bb199c7543443cf3dd4",
            "5af75d6e78dd4d5c9b8d4f80c6ed407b",
            "500b19d54f4c48d589f3f6d98d3491ba",
            "eccc112bdfae4b4ca19641dafd65ac70",
            "09918fbd9ede462c8b5b079e88301694",
            "5435d900005746cfa4af930cae25cd80",
            "ef7a94486d3b4c28a864daf5020ef3da",
            "528ce477dd49496dbff1829d1e80af34",
            "8e248d5d70bb409d83c02589e7d687db",
            "6c58f2e1a2464ff0be894fe381aa4eb4",
            "3134c9eb30d94da9a65bfab29157b285",
            "5148f657b913401fa6ed707ee8385226",
            "92bb7a6fe45d4424a0d98c4b7bb8c7c9",
            "58c142ff738543179e3bc3b747991f19",
            "06f8cbadd0454aecbe8a717c59bab76f",
            "46c1e92e6e1c4629b7856fafc0f8871b",
            "4edc67783bbf46e49f2bab588d92ab7b",
            "379938874836440ea0ea801410930999",
            "6d966a6e2a1e4de4b92e46eceeb0d85e",
            "b4a3d268b68340498e6518d1442112d3",
            "374a2632378a4c0bbf118713474b6d25",
            "afc1a6ba3fb34a40a353c7c348bf03a3",
            "33f1861d8d3e4742926f5d86150ad968",
            "9f3d2557492647e2a804f4f5ce32eec7",
            "3c01a116f6ea484189413ef3e04caaa2",
            "bbfa611b3dce4fcf9a2b8a0c80d6bdc6",
            "4b3b03e29c894280a24872b6e800de64",
            "c6acd511d9a842558ca3c7899f34c070",
            "94ecb12282104cd784701a2a2cb409c2",
            "50609d8d50eb48f2abf9142905512af4",
            "bb3ee7101f52431eb432321ddc75e9b2",
            "317cf6a0ae3047a281b1f314973afdbe",
            "11d69fc88a6b457c997da400566d6a02",
            "596655d0ad1245a690d37ebc70d51cd3",
            "a4e5f80c88024136b995ca8ad7f227b2",
            "6dbee8e3782142f8b5e7c1cc2f11ee2d",
            "c5e82c9fcaaf4f63963b62aeed0e24d8",
            "4bb55f9a2efb403c8d92e4c5ffe1993e",
            "2349fde161f649af85222df94c23b045",
            "f5adee2290924e7a8439d4cff65123cb",
            "a751841437dd48b6ae822587f215db06",
            "a09d0265a264472cad6f883431f1e412",
            "45e639bee68f40f8ab0fd48942f05c45",
            "ee9356333e7046f9a86aee08621dda90",
            "44ce6896393649c49378d098318ec420",
            "cfd9a78938cc404db75c35378068a04d",
            "54a41279949842a4abefeb0dfdc6458e",
            "1014f1b708294f6da4f59e8baa58a8ba",
            "7b78226f2d3545bfa3ef0cda9044b9dd",
            "472cdd18d64d4832a399e28cce566fa4",
            "e9272fc7a0ce4eb49e076794a6b0b0ba",
            "e101f73cd7574e07b7f8d55f97030627",
            "1c6187fd614e43a7b0cca4d6aa50ecf7",
            "0d9851fef0ad44f0b6ebe24a058190a7",
            "4c28ce30898244848475b2e552235759",
            "f6628047e7674ab89601484abcec35db",
            "674d1fa78c204dc9b9c418d3d195cfde",
            "24d55a35c0b04a49bc6c907db05519d6",
            "f87bb131ffb2419f8800100cb8d316d3",
            "e4d183e6bb1044eab1d0739661e0c70b",
            "ca207e6b5bd644d9b21437ffdf8eba7d",
            "0c09574f6d8b455885000920293fcd70",
            "e4bf3d31d3134aa2bc04e09485cf1e4c",
            "ec004fbc916640f3b9e11e9d52b9cb95",
            "77bb1b0e53fa4309935ef5d509cb1388",
            "ab430d17325643b39c5b25e3dcfee1a5",
            "d0aaa23af7bd4e8a8f303689af41fe5d",
            "96fdbc55bbd04714a34e9cb422b355be",
            "0e241e8d9c1446f2b02f98b37146bb39",
            "5107bc49ffb24a8a90f070d475a17633",
            "ea4b48cff61f4b33a5e7eaaf7537f132",
            "821a64c5732346ee946923aa9d1ef851",
            "5f345218f7494bf2aa00bf3a6b3a24e7",
            "0ae816bfda414f5ea69ebe4e25891102",
            "551e041650c74c29a3257fee3b980621",
            "08312738806345918af44ea457a9fc7f",
            "124def6079044e9db4b9b8879e49206e",
            "11196990072b48f1b3e3e7a8e638a7c8",
            "c9a6480a0eba411a8a4acce844559588",
            "4686648f13ac4c29812a07e63f1f4471",
            "72a9e15d7adf4c83b7ea777824bf6b38",
            "8d5ddc1000e2403e908ab4e5c5447ba8",
            "88f7a6ba703846228def312ee258c9b8",
            "425b2a0f9ed44b4b9648ba2a1f5ba5f5",
            "ae946eac3079424f80eba8150808f9d6",
            "4a46dbdef375448e8a71454e4f3b99ec",
            "fa7bc7a30bc745d690399b97b3273b3d",
            "e860ba7e68ae485ab34876033e12bb45",
            "4d822cade65e45a4b95f497d7c7d617f",
            "45cc8c94c2c94780a91c1fb25966f0f0",
            "ff5b743d3eaa43048c8e8c060731417f",
            "8a1fbb70e796420285def5f2830f408d",
            "64dca1392793410ebee9d3797d37fefa",
            "bc26f917c99a4aac9f849f0442422ce5",
            "e25ab01821964452833988ca0491780e",
            "1ef8fb078bbd4d4b85488b845bac0b56",
            "0746a25fe34346f1b797e237338d4ece",
            "774574348b274b068b73cef78a367544",
            "0bc339e3c8a244c191c062214509d997",
            "193093e6cfff417f951ebaaf09671e87",
            "b7e2d3b3294443dcbcc0e984f4d87a24",
            "a1f5b1bb3182455c82883515d6b0c9b9",
            "3d94cf17a0cd4cfa87f6c3126350ce8d",
            "01b5c46ab6c946918b8c7b0e27b35e82",
            "65125e5e371b46e082cf40387a35da1a",
            "a09e4fac1fcd4a5b8d67b9564997c816",
            "f2edbff665fc4565841e6794d5c408a9",
            "12fa1c1bca154b99ac4fab88097137d7",
            "3800b0ef6ea44923a9c2d35841a98a46",
            "669cdb1f5bcd4c05a8cdf1820a94262e",
            "a1e1e1363f4a460db453b9df68b47799",
            "317a2045e23f46be83afa8a474f0234e",
            "f0b31d544aa448089225893f91e2f346"
          ]
        },
        "id": "81qe68ZEqS5K",
        "outputId": "b5e5b3ab-d31a-4a2c-b4ef-503602a87a11"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6018d3f9fe8448338bcacdfde0700455",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "250d521edb1f4561a29ddb57c0932832",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b171340475e41228aa0b8868a7c5785",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "179c1ae7a1f942bbb15cd3babfc5489b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eccc112bdfae4b4ca19641dafd65ac70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06f8cbadd0454aecbe8a717c59bab76f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbfa611b3dce4fcf9a2b8a0c80d6bdc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5e82c9fcaaf4f63963b62aeed0e24d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1014f1b708294f6da4f59e8baa58a8ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f87bb131ffb2419f8800100cb8d316d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5107bc49ffb24a8a90f070d475a17633",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72a9e15d7adf4c83b7ea777824bf6b38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a1fbb70e796420285def5f2830f408d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d94cf17a0cd4cfa87f6c3126350ce8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load INSTRUCTOR_Transformer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_seq_length  512\n"
          ]
        }
      ],
      "source": [
        "\n",
        "embeddings = HuggingFaceInstructEmbeddings(\n",
        "    model_name = \"all-MiniLM-L6-v2\",\n",
        "    model_kwargs = {\"device\": \"cpu\"}\n",
        ")\n",
        "\n",
        "vectordb = FAISS.load_local(\n",
        "   \"/content/faiss_index_hp/content/faiss_index_hp\",\n",
        "    embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RzvpKE8qlX6",
        "outputId": "5c0057b6-06e9-4678-a809-994bd1dd1aee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"recently the rectified linear unit  (ReLU) has gained traction. Let's compare the \\nmost important activation functions so that we understand their advantages and \\ndrawbacks. Note that we mention the output range and active range of the function. \\nThe output range is simply the actual output of the function itself. The active range, however, is a little more complicated; it is the range where the gradient has the most variance in the final weight updates. This means that outside of this range, the gradient is near zero and does not add to the parameter updates during learning. This problem of a close-to-zero gradient is also referred to as the vanishing gradient \\nproblem and is solved by the ReLU activation function, which at this time is the\", metadata={'source': '/content/Large Scale Machine Learning with Python.pdf', 'page': 153}),\n",
              " Document(page_content='0 to infinity. You can see that it is much easier \\nto calculate than the sigmoid function. The biggest benefit of this function is that it bypasses the vanishing gradient problem. If ReLU is an option during a deep learning project, use it.\\nSoftmax for classification\\nSo far, we have seen that activation functions transform the values within a certain \\nrange after they are multiplied with the weight vectors. We also need to transform \\nthe outputs of the last hidden layer before providing balanced classes or probability outputs (log-likelihood values).', metadata={'source': '/content/Large Scale Machine Learning with Python.pdf', 'page': 154}),\n",
              " Document(page_content='(ReLU). This approach is heavily used in speech and audio modeling contexts as ReLU can be used to effectively train deep models without pretraining and without facing some of the gradient vanishing problems that challenge other activation types. More information on ReLU is provided in the Further reading  section of this chapter. \\nThe DepthConcat element provides a concatenation function, which consolidates the outputs of multiple units and substantially improves training time.\\nGoogLeNet chains layers of this type to create a full network. Indeed, the repetition \\nof inception modules through GoogLeNet (nine times!) suggests that Network In Network ( NIN) (deep architectures created from chained network modules)', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 113}),\n",
              " Document(page_content=\"Deep Learning with TensorFlow[ 196 ]This is where we start to give form to the neural network architecture that we have \\nin mind. Let's start a two-hidden layer neural network with relu  activation and \\nthree units in each hidden layer. Our first layer has four inputs because we have four features in this case. After that, we add the hidden layers with three units, hence (\\nmodel.add(dense(3) ).\\nLike we have seen before, we will use a softmax  function to pass the network to the \\noutput layer:\\nmodel = Sequential()\\nmodel.add(Dense(4, input_shape=(4,)))model.add(Activation('relu'))model.add(Dense(3))model.add(Activation('relu'))model.add(Dense(3))model.add(Activation('softmax'))\\nFirst, we specify our SGD function, where we implement the most important\", metadata={'source': '/content/Large Scale Machine Learning with Python.pdf', 'page': 218})]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectordb.similarity_search('relu activation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAUmfadpq23r"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "Don't try to make up an answer, if you don't know just say that you don't know.\n",
        "Answer in the same language the question was asked.\n",
        "Make answer precise as possible.\n",
        "\n",
        "{context}\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template = prompt_template,\n",
        "    input_variables = [\"context\", \"question\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMVJrv09rYoN",
        "outputId": "1b472d58-df79-41a3-b498-1e6a60c628d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"\\nDon't try to make up an answer, if you don't know just say that you don't know.\\nAnswer in the same language the question was asked.\\nMake answer precise as possible.\\n\\n{context}\\nQuestion: {question}\\nAnswer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7c41d2207430>))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_chain = LLMChain(prompt=PROMPT, llm=llm)\n",
        "llm_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rjyqQCBra4_"
      },
      "outputs": [],
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs = {\"k\": 3, \"search_type\" : \"similarity\"})\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm = llm,\n",
        "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
        "    retriever = retriever,\n",
        "    chain_type_kwargs = {\"prompt\": PROMPT},\n",
        "    return_source_documents = True,\n",
        "    verbose = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdAXsRBargFa",
        "outputId": "c63adde5-1926-45b7-fbec-cbd56d92e872"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='model has learned based on both the signal and noise. The concept of overfitting is generally used to describe a model that has fit so well to a given dataset that it has learned to predict based on both the signal and noise, rendering it less powerful against other samples than a model with a less exact fit.', metadata={'source': '/content/Advanced Machine Learning with Python.pdf', 'page': 244}),\n",
              " Document(page_content='machine learning model is the complexity associated with the model. The machine learning algorithms are intrinsically very complex as they work on voluminous and possibly unstructured data such as texts, images, and speech. As a consequence, training of such algorithms demands sophisticated computing infrastructure and a high level of knowledge and skill on the part of the modelers. However, countering such complexities with overly sophisticated models can be very counterproduc -', metadata={'source': '/content/2. Machine Learning Author Jaydip Sen.pdf', 'page': 26}),\n",
              " Document(page_content='model class is too large and a model is chosen which perfectly explains the training data, then\\nthe generalization performance (the performance on future data) may be low. This case is called\\n“overﬁtting” . Reason is that the model is ﬁtted or adapted to special characteristics of the training\\ndata, where these characteristics include noisy measurements, outliers, or labeling errors. There-\\nfore before model selection based on the best training data ﬁtting model, the model class must be\\nchosen.\\nOn the other hand, if a low complex model class is chosen, then it may be possible that the\\ntraining data cannot be ﬁtted well enough. The generalization performance may be low because\\nthe general structure in the data was not extracted because the model complexity did not allow to', metadata={'source': '/content/4. Machine Learning - Supervised Techniques Author Sepp Hochreiter.pdf', 'page': 34}),\n",
              " Document(page_content='Dynamic calibration of models: There is an adaptable class of machine learn-', metadata={'source': '/content/2. Machine Learning Author Jaydip Sen.pdf', 'page': 28}),\n",
              " Document(page_content='• During modeling, a recursive approach inserting and/or excluding features on the basis of their capability to improve the predictive power of the algorithm, as tested on a holdout sample. Using a smaller subset of just \\nrelevant features allows the machine learning algorithm to be less affected by \\noverfitting because of noisy variables and the parameters in excess due to the \\nhigh dimensionality of the features.', metadata={'source': '/content/Large Scale Machine Learning with Python.pdf', 'page': 126})]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"How to make machine learing model free from overfitting\"\n",
        "vectordb.similarity_search(question, k = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfAZctsur6Fd"
      },
      "outputs": [],
      "source": [
        "def wrap_text_preserve_newlines(text, width=500):\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text\n",
        "\n",
        "\n",
        "def process_llm_response(llm_response):\n",
        "    ans = wrap_text_preserve_newlines(llm_response['result'])\n",
        "\n",
        "    sources_used = ' \\n'.join(\n",
        "        [\n",
        "            source.metadata['source'].split('/')[-1][:-4] + ' - page: ' + str(source.metadata['page'])\n",
        "            for source in llm_response['source_documents']\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    ans = ans + '\\n\\nSources: \\n' + sources_used\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va9SXHrnsyX3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2po1NPM2simD"
      },
      "outputs": [],
      "source": [
        "def ans(query):\n",
        "    start = time.time()\n",
        "    llm_response = qa_chain(query)\n",
        "    ans = process_llm_response(llm_response)\n",
        "    end = time.time()\n",
        "\n",
        "    time_elapsed = int(round(end - start, 0))\n",
        "    time_elapsed_str = f'\\n\\nTime elapsed: {time_elapsed} s'\n",
        "    return ans + time_elapsed_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "sEwGxqwHsmiS",
        "outputId": "1fce8515-c158-4ad5-db89-afcabfb12564"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `(0.95,)` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
            "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b9e62ec1c9ac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"solve underfitting in machine learning models\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-ace972278136>\u001b[0m in \u001b[0;36mans\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mllm_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    361\u001b[0m         }\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/retrieval_qa/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         answer = self.combine_documents_chain.run(\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0minput_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    361\u001b[0m         }\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Other keys are assumed to be needed for LLM prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mother_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         output, extra_return_dict = self.combine_docs(\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mother_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/combine_documents/stuff.py\u001b[0m in \u001b[0;36mcombine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# Call predict on the LLM.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     async def acombine_docs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"funny\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    361\u001b[0m         }\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    529\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m                 )\n\u001b[1;32m    702\u001b[0m             ]\n\u001b[0;32m--> 703\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             output = (\n\u001b[0;32m--> 554\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    555\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_prompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;31m# Process each response in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m               \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 )\n\u001b[0;32m-> 1143\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgeneration_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGREEDY_SEARCH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m             \u001b[0;31m# 11. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1480\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2339\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2340\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2341\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2342\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bloom/modeling_bloom.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m    859\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bloom/modeling_bloom.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 )\n\u001b[1;32m    721\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    723\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bloom/modeling_bloom.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, alibi, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# Self attention.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         attn_outputs = self.self_attention(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0mlayernorm_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bloom/modeling_bloom.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, residual, alibi, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 )\n\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "query = \"solve underfitting in machine learning models\"\n",
        "print(ans(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "CVhFE9Lo0oOd",
        "outputId": "f08ecd05-ff37-47c3-9a2d-e2bbd2b60976"
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f2796ad02655>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install flask-ngrok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55L8D4MfsusH"
      },
      "outputs": [],
      "source": [
        "!mkdir templates\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_kT2Nalyk1m"
      },
      "outputs": [],
      "source": [
        "!mkdir style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lheIw7kDytNR"
      },
      "outputs": [],
      "source": [
        "\n",
        "!mkdir style/css"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IquqbzkLUeDj"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CPJ1u0_R8LRT"
      },
      "outputs": [],
      "source": [
        "!pip install flask --quiet\n",
        "!pip install flask-ngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzhH8IBo8SCq",
        "outputId": "2ede7bdb-e9e6-41c6-ea47-1f7bfb03c827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-03 12:49:02--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 18.205.222.128, 54.237.133.81, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13856790 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.tgz’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.21M  19.4MB/s    in 0.7s    \n",
            "\n",
            "2024-02-03 12:49:03 (19.4 MB/s) - ‘ngrok-stable-linux-amd64.tgz’ saved [13856790/13856790]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bryxUX4u8Yl2",
        "outputId": "0f63ab1c-9462-4458-f377-96a9aa2b8314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ngrok\n"
          ]
        }
      ],
      "source": [
        "!tar -xvf /content/ngrok-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG6DCaoW8cxI",
        "outputId": "da951f82-51bc-45f0-84a2-3240f3d36f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!./ngrok authtoken \"Your Token\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WatLSx2d75rs",
        "outputId": "945fb061-9285-4022-ab6d-bbf2a0ac0514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://857f-34-125-48-6.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Feb/2024 13:00:22] \"\u001b[32mPOST /submit HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Feb/2024 13:00:24] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Feb/2024 13:00:25] \"\u001b[33mGET /static/css/style.css HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Feb/2024 13:00:25] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `(0.95,)` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Feb/2024 13:01:27] \"\u001b[32mPOST /submit HTTP/1.1\u001b[0m\" 302 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Feb/2024 13:01:27] \"GET /submit HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Feb/2024 13:01:28] \"\u001b[33mGET /static/css/style.css HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, render_template , redirect , url_for\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__ , template_folder=r\"/content/templates\")\n",
        "run_with_ngrok(app)\n",
        "chat = []\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "\n",
        "@app.route('/submit'  , methods=[  \"GET\" ,  \"POST\"  ])\n",
        "def abc():\n",
        "    user=None\n",
        "    ai=None\n",
        "    if request.method=='POST':\n",
        "        user = request.form[\"text\"]\n",
        "        ai=ans(user)\n",
        "        chat.append([user , ai])\n",
        "        return redirect(url_for('abc'))\n",
        "    return render_template(\"index.html\" , ans=ai , chat= chat )\n",
        "\n",
        "    user=None\n",
        "    ai=None\n",
        "    return render_template(\"index.html\" , ans=ai , chat= request.form.get(\"text\") )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF3bBPviCY4F",
        "outputId": "1f49fc05-62f9-44c0-8edd-a61b50e8882b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: ngrok: command not found\n"
          ]
        }
      ],
      "source": [
        "!ngrok http PORT --host-header=\"localhost:PORT\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-emIG1ARKeQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01b5c46ab6c946918b8c7b0e27b35e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12fa1c1bca154b99ac4fab88097137d7",
            "placeholder": "​",
            "style": "IPY_MODEL_3800b0ef6ea44923a9c2d35841a98a46",
            "value": "modules.json: 100%"
          }
        },
        "027b7a49ad3d48f3a575ed03c2245e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f556d528d64ce9b3c76d22ac9d344e",
            "max": 4161852232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f818c26ad0643c3a3fe9c96a4045f9c",
            "value": 4161852232
          }
        },
        "028dc09f782e4e58af108564ee9d2b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03c3f550b72d4d5d97c065f21df6373b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c2d4da2321438aaea32902fc31a451": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c6bd1809b447589de233d7798f8681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e297f34245044af921062cbe294695b",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59b2f52edd1b4d0a9a3a34293584e52c",
            "value": 10610
          }
        },
        "06f8cbadd0454aecbe8a717c59bab76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46c1e92e6e1c4629b7856fafc0f8871b",
              "IPY_MODEL_4edc67783bbf46e49f2bab588d92ab7b",
              "IPY_MODEL_379938874836440ea0ea801410930999"
            ],
            "layout": "IPY_MODEL_6d966a6e2a1e4de4b92e46eceeb0d85e"
          }
        },
        "0746a25fe34346f1b797e237338d4ece": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "075f3c66bf564908beb879619f6a1d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd2ba16f5a14916855d10412a02c035",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c06337837d848e2a129deb492a64e9f",
            "value": 1175
          }
        },
        "08312738806345918af44ea457a9fc7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "083d5e6997934b2ba15497ec6bc6dfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "087f3fb3dece4ba38f11d8e1337d81b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08b81dc7346f42e19952fe558c8dc794": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d59310db9e3648f1bdeabc9977802db3",
              "IPY_MODEL_215a1399eef14948a7b639fd01b43a6f",
              "IPY_MODEL_f83837f7cbe7456b9e8166e0ac6feb8b"
            ],
            "layout": "IPY_MODEL_f16044a1afd8473f9aa57c634b8cfab8"
          }
        },
        "09918fbd9ede462c8b5b079e88301694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e248d5d70bb409d83c02589e7d687db",
            "placeholder": "​",
            "style": "IPY_MODEL_6c58f2e1a2464ff0be894fe381aa4eb4",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "0ae816bfda414f5ea69ebe4e25891102": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b73d3efd96d4229a4a82e63c25f0a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b7445166ed1432c9a21c704d58a5cca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc339e3c8a244c191c062214509d997": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c09574f6d8b455885000920293fcd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fdbc55bbd04714a34e9cb422b355be",
            "placeholder": "​",
            "style": "IPY_MODEL_0e241e8d9c1446f2b02f98b37146bb39",
            "value": " 466k/466k [00:00&lt;00:00, 4.08MB/s]"
          }
        },
        "0c2db96c1aa34ddda9e27121e97a19fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf0768f4e1f42d595c47576b8f66dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d0b63e006214bb199c7543443cf3dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d4530d33c4e45728ab76235bcced886": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f20a5c8f3f0425bb32aa5a7aae2a90f",
            "placeholder": "​",
            "style": "IPY_MODEL_586e2c4167b548d2a8ecb8ca2e8f5e4c",
            "value": " 14.5M/14.5M [00:00&lt;00:00, 38.3MB/s]"
          }
        },
        "0d9851fef0ad44f0b6ebe24a058190a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e241e8d9c1446f2b02f98b37146bb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e297f34245044af921062cbe294695b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ed385c3bea340d8972992169b5d100d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8b8a58b8734425b31d46b14ad5a8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cacfbbd5d1f0470ca42890b58e4e6900",
            "placeholder": "​",
            "style": "IPY_MODEL_4e76f629d9e54132be7871116423478b",
            "value": " 116/116 [00:00&lt;00:00, 4.74kB/s]"
          }
        },
        "1014f1b708294f6da4f59e8baa58a8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b78226f2d3545bfa3ef0cda9044b9dd",
              "IPY_MODEL_472cdd18d64d4832a399e28cce566fa4",
              "IPY_MODEL_e9272fc7a0ce4eb49e076794a6b0b0ba"
            ],
            "layout": "IPY_MODEL_e101f73cd7574e07b7f8d55f97030627"
          }
        },
        "102d52e569d344d2aaded742f0cfb3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10a4932afe7147918172123bb9ffe416": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11196990072b48f1b3e3e7a8e638a7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11cdecc3da334cad8b08c304d9e2906e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d1c1b5a3067478a832990c3c014e589",
            "placeholder": "​",
            "style": "IPY_MODEL_bdd3ae8bfbf446309b54f466de0e1af6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "11d69fc88a6b457c997da400566d6a02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "124def6079044e9db4b9b8879e49206e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125eeaa48d334bc6a676eb0604845da0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12fa1c1bca154b99ac4fab88097137d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13561401a97e410c806ffbea1d2d39c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174853e7a904470792682f90af79cc22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa3049ba4dd4d3788c49a3204042123",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_102d52e569d344d2aaded742f0cfb3a9",
            "value": 2
          }
        },
        "179c1ae7a1f942bbb15cd3babfc5489b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e611461bbf9345c29b2fa329959ec4c3",
              "IPY_MODEL_cedddddd215f4932bf42a08b45ddf93e",
              "IPY_MODEL_566c1dc0339b45b6a7de7c370aac74f3"
            ],
            "layout": "IPY_MODEL_6b1fa95f7529411c946ae1889dff8371"
          }
        },
        "182715959efd4d5ead1788d541798b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18c56170974c426088c9f98cc4929ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1927851c41db406c83933bbbefd90739": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "193093e6cfff417f951ebaaf09671e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b32cdc0338344898ef00ee08844758b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b3342e5a9c94d379df8d74d67784de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c6187fd614e43a7b0cca4d6aa50ecf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c97412b5f9d4e4db3297c57905578b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ed9a795e8ce4b3f8347b1f85f774ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ef8fb078bbd4d4b85488b845bac0b56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ba8d6240a54973b897d633bcbe8366": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "215a1399eef14948a7b639fd01b43a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53ef8648d164a15ac19c333af8607eb",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ed9a795e8ce4b3f8347b1f85f774ad0",
            "value": 112
          }
        },
        "2349fde161f649af85222df94c23b045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee9356333e7046f9a86aee08621dda90",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44ce6896393649c49378d098318ec420",
            "value": 53
          }
        },
        "237d93fdf956493aad5a15a916b90b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a96b3bc8f054a4485513b036f44afa9",
            "placeholder": "​",
            "style": "IPY_MODEL_78ba450cf295426697f02800c5a2a060",
            "value": " 190/190 [00:00&lt;00:00, 11.5kB/s]"
          }
        },
        "24d55a35c0b04a49bc6c907db05519d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "250d521edb1f4561a29ddb57c0932832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76294695cb1a405c9610be93737afca6",
              "IPY_MODEL_9d8d8818e5904c8f8e0a09d6995d624e",
              "IPY_MODEL_44d1cc5e82dd47f4854628d4d5f60a75"
            ],
            "layout": "IPY_MODEL_b0964b0c43d64388abe1d9348f76dfe1"
          }
        },
        "2654acfd96794d8588535aa6b0e562ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e936149ad5a403498bb59085048fbbd",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a2d985fd93740878573c9d68bd1e780",
            "value": 85
          }
        },
        "26a2f0efb882499cadac357508949bba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26d73cdf39c44477b7e1e066e4b843dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_927312b07c954fe6ac2afc1daa42d78a",
            "placeholder": "​",
            "style": "IPY_MODEL_f0579994e98144beab765911a8e385ec",
            "value": " 2/2 [00:58&lt;00:00, 27.13s/it]"
          }
        },
        "26f70cb48b7940f6a7676233dbeef3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b171340475e41228aa0b8868a7c5785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4172c6cfc044be99a91b4c28588d5d1",
              "IPY_MODEL_04c6bd1809b447589de233d7798f8681",
              "IPY_MODEL_dc6d6df107e544758eb14241b8072628"
            ],
            "layout": "IPY_MODEL_125eeaa48d334bc6a676eb0604845da0"
          }
        },
        "2cb1417b3f744068a2d4499b4e20db9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e1ebe881b5a42c58587569ba4bc4ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e393313728d4e9b96c1baaa2deecddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3134c9eb30d94da9a65bfab29157b285": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3157ee66557d4e14b53d41aa49cf6640": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b458336632f14d2fa74055e635813371",
            "placeholder": "​",
            "style": "IPY_MODEL_8adf7de5f1ad41e585fb9c379880509c",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "317a2045e23f46be83afa8a474f0234e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317cf6a0ae3047a281b1f314973afdbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31e6dc60c55e4c989f2498cb555756b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41bb013c679b4697b508b3d10a236b3f",
            "max": 28931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1927851c41db406c83933bbbefd90739",
            "value": 28931
          }
        },
        "321511fc895d489fab1c1167e3801bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c3f550b72d4d5d97c065f21df6373b",
            "placeholder": "​",
            "style": "IPY_MODEL_48d753276ecf475797379d7161896706",
            "value": " 85.0/85.0 [00:00&lt;00:00, 4.87kB/s]"
          }
        },
        "3270078a406642f69672d71de71cb446": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33baa38c764c4fc686bc143365c7f9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5409bf2a3e4bc3a94d12ef12a4b78e",
            "placeholder": "​",
            "style": "IPY_MODEL_fec3e04becb747298b19260748b874c5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "33f1861d8d3e4742926f5d86150ad968": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3419b259f07b4cca86eab685d05d6e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3476eaecfd78486691dbd70c52bf2467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63101aedfece4324939736dfa344abf8",
            "placeholder": "​",
            "style": "IPY_MODEL_c881d316bea849b9a4db9ef6b4f18599",
            "value": "tokenizer.json: 100%"
          }
        },
        "35e3acb9aae045d8a1391604ac897cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3699239f496242f79da402d86701d97d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e65a8cc7f043f0b5a6491f6e3b53aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "374a2632378a4c0bbf118713474b6d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "379938874836440ea0ea801410930999": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f3d2557492647e2a804f4f5ce32eec7",
            "placeholder": "​",
            "style": "IPY_MODEL_3c01a116f6ea484189413ef3e04caaa2",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 2.07MB/s]"
          }
        },
        "37db1a7ca2a747d3954eb566627c3911": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3800b0ef6ea44923a9c2d35841a98a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "397c41e4536f4f83bddcc8af5882a026": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4754b50a94aa420eb28eb46f4e5faf16",
            "max": 14500438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f15e937eb6f41ebbdd7e9b66bc5309c",
            "value": 14500438
          }
        },
        "3a8f1fd4ac49493ba27be1b88b4efc10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa484311f1b4c9a81aeec7d877b3fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ad21d7db87344c0b0cde9429ae793c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bdedb0152c6464492ab9292ae6982d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3476eaecfd78486691dbd70c52bf2467",
              "IPY_MODEL_397c41e4536f4f83bddcc8af5882a026",
              "IPY_MODEL_0d4530d33c4e45728ab76235bcced886"
            ],
            "layout": "IPY_MODEL_418c7414c017437eafde601358bdc5c3"
          }
        },
        "3c01a116f6ea484189413ef3e04caaa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c1f507882d042b5ba45562b27be9679": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d560adf019b486f8afc19c86a320fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13561401a97e410c806ffbea1d2d39c4",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fe012ddf2544d99af73c79f2cea3942",
            "value": 190
          }
        },
        "3d94cf17a0cd4cfa87f6c3126350ce8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01b5c46ab6c946918b8c7b0e27b35e82",
              "IPY_MODEL_65125e5e371b46e082cf40387a35da1a",
              "IPY_MODEL_a09e4fac1fcd4a5b8d67b9564997c816"
            ],
            "layout": "IPY_MODEL_f2edbff665fc4565841e6794d5c408a9"
          }
        },
        "3e949d6ad24440d8b78cefc19d0897ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62db16d354fc4e41af4196ec4b4193da",
              "IPY_MODEL_dc550b8d89fc42e190367d0cd6b04886",
              "IPY_MODEL_8c6e1b6fa17040e39b64eb4a6d552bf0"
            ],
            "layout": "IPY_MODEL_3699239f496242f79da402d86701d97d"
          }
        },
        "3eb6be301f9d463b99a0915a383a7d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_083d5e6997934b2ba15497ec6bc6dfeb",
            "placeholder": "​",
            "style": "IPY_MODEL_2cb1417b3f744068a2d4499b4e20db9a",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 238MB/s]"
          }
        },
        "3fd9226875e34d319c90b6cd88870906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401ae295d4844593afdcacf49a469915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea13ac8fa51542abb1a6d9be5aa0fec2",
              "IPY_MODEL_b69afe3bc7c24699a638a2777cc41532",
              "IPY_MODEL_26d73cdf39c44477b7e1e066e4b843dd"
            ],
            "layout": "IPY_MODEL_3270078a406642f69672d71de71cb446"
          }
        },
        "418c7414c017437eafde601358bdc5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bb013c679b4697b508b3d10a236b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425b2a0f9ed44b4b9648ba2a1f5ba5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45cc8c94c2c94780a91c1fb25966f0f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ff5b743d3eaa43048c8e8c060731417f",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 445kB/s]"
          }
        },
        "427287483c0d4fa0955e64afb31853a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "448f5743d6f743189b6f4fe4b79580ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ce6896393649c49378d098318ec420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44d1cc5e82dd47f4854628d4d5f60a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7445166ed1432c9a21c704d58a5cca",
            "placeholder": "​",
            "style": "IPY_MODEL_d575e8b440c14398a6cd7abb22f579a6",
            "value": " 190/190 [00:00&lt;00:00, 12.4kB/s]"
          }
        },
        "44e0b472a17c47448adca9c581bb4e85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45cc8c94c2c94780a91c1fb25966f0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e639bee68f40f8ab0fd48942f05c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4686648f13ac4c29812a07e63f1f4471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46c1e92e6e1c4629b7856fafc0f8871b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4a3d268b68340498e6518d1442112d3",
            "placeholder": "​",
            "style": "IPY_MODEL_374a2632378a4c0bbf118713474b6d25",
            "value": "data_config.json: 100%"
          }
        },
        "472cdd18d64d4832a399e28cce566fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c28ce30898244848475b2e552235759",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6628047e7674ab89601484abcec35db",
            "value": 112
          }
        },
        "4754b50a94aa420eb28eb46f4e5faf16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d753276ecf475797379d7161896706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49fbbe1ca0c64348abe4047859b5dd5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a46dbdef375448e8a71454e4f3b99ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1577ec50754dbaaef75a250ad96f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b479556d1624c04945faa851d9e31b9",
            "placeholder": "​",
            "style": "IPY_MODEL_66d9e3d5830c488ca4211001475ed84f",
            "value": " 739/739 [00:00&lt;00:00, 36.7kB/s]"
          }
        },
        "4b3b03e29c894280a24872b6e800de64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb3ee7101f52431eb432321ddc75e9b2",
            "placeholder": "​",
            "style": "IPY_MODEL_317cf6a0ae3047a281b1f314973afdbe",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "4b479556d1624c04945faa851d9e31b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bb55f9a2efb403c8d92e4c5ffe1993e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a09d0265a264472cad6f883431f1e412",
            "placeholder": "​",
            "style": "IPY_MODEL_45e639bee68f40f8ab0fd48942f05c45",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "4c28ce30898244848475b2e552235759": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d822cade65e45a4b95f497d7c7d617f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e76f629d9e54132be7871116423478b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eab4ca01651413c90222e245898239d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eea49467fbba44d29ba25baf467ffbed",
              "IPY_MODEL_3d560adf019b486f8afc19c86a320fa5",
              "IPY_MODEL_237d93fdf956493aad5a15a916b90b46"
            ],
            "layout": "IPY_MODEL_a0567ca8e9f54e829bb77722e92f243a"
          }
        },
        "4edc67783bbf46e49f2bab588d92ab7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc1a6ba3fb34a40a353c7c348bf03a3",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33f1861d8d3e4742926f5d86150ad968",
            "value": 39265
          }
        },
        "4f15e937eb6f41ebbdd7e9b66bc5309c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fe012ddf2544d99af73c79f2cea3942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "500b19d54f4c48d589f3f6d98d3491ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50609d8d50eb48f2abf9142905512af4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5107bc49ffb24a8a90f070d475a17633": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea4b48cff61f4b33a5e7eaaf7537f132",
              "IPY_MODEL_821a64c5732346ee946923aa9d1ef851",
              "IPY_MODEL_5f345218f7494bf2aa00bf3a6b3a24e7"
            ],
            "layout": "IPY_MODEL_0ae816bfda414f5ea69ebe4e25891102"
          }
        },
        "5148f657b913401fa6ed707ee8385226": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "528ce477dd49496dbff1829d1e80af34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536f6d8687af4aa088f2c2785a9642cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0bf1d5f74624e67b0abb332db9bd0ff",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c1ab76a81e470fb99b82fcaf4cd48b",
            "value": 90888945
          }
        },
        "541e19804f044767a955876ed8473564": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5435d900005746cfa4af930cae25cd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3134c9eb30d94da9a65bfab29157b285",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5148f657b913401fa6ed707ee8385226",
            "value": 116
          }
        },
        "54a41279949842a4abefeb0dfdc6458e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "551e041650c74c29a3257fee3b980621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566c1dc0339b45b6a7de7c370aac74f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af75d6e78dd4d5c9b8d4f80c6ed407b",
            "placeholder": "​",
            "style": "IPY_MODEL_500b19d54f4c48d589f3f6d98d3491ba",
            "value": " 612/612 [00:00&lt;00:00, 36.4kB/s]"
          }
        },
        "586e2c4167b548d2a8ecb8ca2e8f5e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58c142ff738543179e3bc3b747991f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59103fb636264a80ba02321c1e3ebd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67c4cc30296d4062a19a922f706864af",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daa2c8d82417425ea17b305124d034dc",
            "value": 116
          }
        },
        "592cda2bc1d34f70a75376a5b3de8185": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596655d0ad1245a690d37ebc70d51cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59b2f52edd1b4d0a9a3a34293584e52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5af75d6e78dd4d5c9b8d4f80c6ed407b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5afc0e55770a47adbe26702253d75e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c06337837d848e2a129deb492a64e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e7e0c9643d34180a052fb314b8735cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e936149ad5a403498bb59085048fbbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f345218f7494bf2aa00bf3a6b3a24e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9a6480a0eba411a8a4acce844559588",
            "placeholder": "​",
            "style": "IPY_MODEL_4686648f13ac4c29812a07e63f1f4471",
            "value": " 350/350 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "6018d3f9fe8448338bcacdfde0700455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d78137388b2748a4aeb8a6f21dcc0d23",
              "IPY_MODEL_075f3c66bf564908beb879619f6a1d2c",
              "IPY_MODEL_fc54d4668a304b219dc905aedcf037b1"
            ],
            "layout": "IPY_MODEL_0c2db96c1aa34ddda9e27121e97a19fe"
          }
        },
        "612174fd64c442e39aca36f4f904b56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1f507882d042b5ba45562b27be9679",
            "placeholder": "​",
            "style": "IPY_MODEL_182715959efd4d5ead1788d541798b6a",
            "value": "Downloading shards: 100%"
          }
        },
        "628a3e3bbad84d5fa31746f0785ee83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6051ad35b6940cda73df32a26f10030",
            "placeholder": "​",
            "style": "IPY_MODEL_5afc0e55770a47adbe26702253d75e48",
            "value": " 350/350 [00:00&lt;00:00, 20.0kB/s]"
          }
        },
        "62db16d354fc4e41af4196ec4b4193da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75da699ae6994e2491b75c402d3cc48a",
            "placeholder": "​",
            "style": "IPY_MODEL_20ba8d6240a54973b897d633bcbe8366",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "63101aedfece4324939736dfa344abf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634c2d37c5654255824ca4aa2c243b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64d999ec1d37458b8b75fd1e8fede25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11cdecc3da334cad8b08c304d9e2906e",
              "IPY_MODEL_2654acfd96794d8588535aa6b0e562ce",
              "IPY_MODEL_321511fc895d489fab1c1167e3801bb2"
            ],
            "layout": "IPY_MODEL_448f5743d6f743189b6f4fe4b79580ed"
          }
        },
        "64dca1392793410ebee9d3797d37fefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0746a25fe34346f1b797e237338d4ece",
            "placeholder": "​",
            "style": "IPY_MODEL_774574348b274b068b73cef78a367544",
            "value": "vocab.txt: 100%"
          }
        },
        "65125e5e371b46e082cf40387a35da1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669cdb1f5bcd4c05a8cdf1820a94262e",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1e1e1363f4a460db453b9df68b47799",
            "value": 349
          }
        },
        "669cdb1f5bcd4c05a8cdf1820a94262e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d9e3d5830c488ca4211001475ed84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "674d1fa78c204dc9b9c418d3d195cfde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67c4cc30296d4062a19a922f706864af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "691df0a2b2ba414dbe86c51480f7e824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b73d3efd96d4229a4a82e63c25f0a17",
            "placeholder": "​",
            "style": "IPY_MODEL_1b3342e5a9c94d379df8d74d67784de4",
            "value": " 222/222 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "693fdc2e9673430397a39108a134779f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdb3284aa4ff4e4499b2bda1c6912829",
            "placeholder": "​",
            "style": "IPY_MODEL_e9ccb4056dde4e7ebddc7e2307e9707d",
            "value": " 466k/466k [00:00&lt;00:00, 984kB/s]"
          }
        },
        "6a41f6cb59b24148b295b1a77427e3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a544fd636004abbba74ed30d7e922d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a79e4c345484b0aa3c4cef1f02f0fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b1fa95f7529411c946ae1889dff8371": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7ef3b2f2b04fee8efcac86d1585f17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c05a3fc16a04f67b4a65c7ee90cbefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_612174fd64c442e39aca36f4f904b56f",
              "IPY_MODEL_174853e7a904470792682f90af79cc22",
              "IPY_MODEL_e5bedfddcf224d6698e3c19a56af0d63"
            ],
            "layout": "IPY_MODEL_8433d0798b8b49409774397d133f97a0"
          }
        },
        "6c58f2e1a2464ff0be894fe381aa4eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d966a6e2a1e4de4b92e46eceeb0d85e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dbee8e3782142f8b5e7c1cc2f11ee2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e886eb6e7ff41af899ecc8d90fd9591": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725ae83c8383490ea8453f72b442c724": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c2d4da2321438aaea32902fc31a451",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10a4932afe7147918172123bb9ffe416",
            "value": 612
          }
        },
        "72a9e15d7adf4c83b7ea777824bf6b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d5ddc1000e2403e908ab4e5c5447ba8",
              "IPY_MODEL_88f7a6ba703846228def312ee258c9b8",
              "IPY_MODEL_425b2a0f9ed44b4b9648ba2a1f5ba5f5"
            ],
            "layout": "IPY_MODEL_ae946eac3079424f80eba8150808f9d6"
          }
        },
        "74757051b1684c939ad73ab268fd135a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b38ff279188c49afa8298ada33bb2d45",
              "IPY_MODEL_c92989c8bb764ba28778e47f242186ee",
              "IPY_MODEL_4b1577ec50754dbaaef75a250ad96f41"
            ],
            "layout": "IPY_MODEL_ed635c515e7844e587054c46f8a7293a"
          }
        },
        "757a0f0ba8724da9a6fbf73aba5de82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75da699ae6994e2491b75c402d3cc48a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76294695cb1a405c9610be93737afca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6345d06513b454b91792470ed1b0cc0",
            "placeholder": "​",
            "style": "IPY_MODEL_b8f3ba97542d451fad66ebcf873c3dbe",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "774574348b274b068b73cef78a367544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77bb1b0e53fa4309935ef5d509cb1388": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78ba450cf295426697f02800c5a2a060": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7920c1b266ef4d6a8c6bfbcc0b74244c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9feb4d40fa5a45c391aafdda0fde77b6",
              "IPY_MODEL_fc445ac7745f46f4a514761c8d5e90af",
              "IPY_MODEL_691df0a2b2ba414dbe86c51480f7e824"
            ],
            "layout": "IPY_MODEL_26f70cb48b7940f6a7676233dbeef3d1"
          }
        },
        "7a80a188e9a24f81b692cb09dd13eef0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a96b3bc8f054a4485513b036f44afa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad73ea5e1be4a359ecd7cbc49508043": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b78226f2d3545bfa3ef0cda9044b9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6187fd614e43a7b0cca4d6aa50ecf7",
            "placeholder": "​",
            "style": "IPY_MODEL_0d9851fef0ad44f0b6ebe24a058190a7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "7d1c1b5a3067478a832990c3c014e589": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f471d30ec974177816aef2acf2d1468": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf0df769c6b040359d8728c108b9bbe1",
            "placeholder": "​",
            "style": "IPY_MODEL_b429ee2cda484aa4b83f9c2e734115f7",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "807ce00e629149678b3649d6c02ff67f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f2ce731b1b4b60a674b362052a894a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "821a64c5732346ee946923aa9d1ef851": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124def6079044e9db4b9b8879e49206e",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11196990072b48f1b3e3e7a8e638a7c8",
            "value": 350
          }
        },
        "832cc49113c34d30b562e476575b983a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8406164b0d0f43f8bb081cd49f4246ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8433d0798b8b49409774397d133f97a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8436ebf7f3df4257bf92a8df31c72826": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "847dea87798f4170bf539bf8318aa3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c650c033bcb24c779a9891b54b8da219",
              "IPY_MODEL_725ae83c8383490ea8453f72b442c724",
              "IPY_MODEL_d60dbf7f818e4e568fc06863ced521b7"
            ],
            "layout": "IPY_MODEL_592cda2bc1d34f70a75376a5b3de8185"
          }
        },
        "857c1addd5c7459d833b9ac52453ea75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8783f0c5e28d4617a3d2dd0ef7db294a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b395c628e24112b0c2187fbac8495e",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_634c2d37c5654255824ca4aa2c243b10",
            "value": 466247
          }
        },
        "87bb5591bb1b4c25bb860a8db09babdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88f7a6ba703846228def312ee258c9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e860ba7e68ae485ab34876033e12bb45",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d822cade65e45a4b95f497d7c7d617f",
            "value": 13156
          }
        },
        "8965f7137844485386d2c23b69eb6a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a1f71c8bfde4dfe9ddffb44409a6984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0ba7fe26044178b07ee58e7e0eac25",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2b0326344c7466fa45233158130240a",
            "value": 10610
          }
        },
        "8a1fbb70e796420285def5f2830f408d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64dca1392793410ebee9d3797d37fefa",
              "IPY_MODEL_bc26f917c99a4aac9f849f0442422ce5",
              "IPY_MODEL_e25ab01821964452833988ca0491780e"
            ],
            "layout": "IPY_MODEL_1ef8fb078bbd4d4b85488b845bac0b56"
          }
        },
        "8aa3049ba4dd4d3788c49a3204042123": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8adf7de5f1ad41e585fb9c379880509c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c6e1b6fa17040e39b64eb4a6d552bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8f1fd4ac49493ba27be1b88b4efc10",
            "placeholder": "​",
            "style": "IPY_MODEL_80f2ce731b1b4b60a674b362052a894a",
            "value": " 9.98G/9.98G [01:40&lt;00:00, 83.6MB/s]"
          }
        },
        "8cbba5df11334b25b163c648cd1c208b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d214dff5b76415582a6cca9e17f81e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d5ddc1000e2403e908ab4e5c5447ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a46dbdef375448e8a71454e4f3b99ec",
            "placeholder": "​",
            "style": "IPY_MODEL_fa7bc7a30bc745d690399b97b3273b3d",
            "value": "train_script.py: 100%"
          }
        },
        "8d6c0dd8a26840e88f68653fe5108ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e248d5d70bb409d83c02589e7d687db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f20a5c8f3f0425bb32aa5a7aae2a90f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f818c26ad0643c3a3fe9c96a4045f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fd526d2804f4e71b87772cf52c32b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b16d6a22389e4417b44f2982c961385a",
              "IPY_MODEL_d77c2b0dba0847d890ec8f820171ddd2",
              "IPY_MODEL_628a3e3bbad84d5fa31746f0785ee83c"
            ],
            "layout": "IPY_MODEL_26a2f0efb882499cadac357508949bba"
          }
        },
        "927312b07c954fe6ac2afc1daa42d78a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92bb7a6fe45d4424a0d98c4b7bb8c7c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ecb12282104cd784701a2a2cb409c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e5f80c88024136b995ca8ad7f227b2",
            "placeholder": "​",
            "style": "IPY_MODEL_6dbee8e3782142f8b5e7c1cc2f11ee2d",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 188MB/s]"
          }
        },
        "95b0687fa64d4e9c920c06ca83c9aba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96fdbc55bbd04714a34e9cb422b355be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "987b0d9fae584ed599532a5889b6db40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2d985fd93740878573c9d68bd1e780": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c983a3b243148d7b2b07804d83234b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7d917c921d7453cad9bf1425c07f52c",
              "IPY_MODEL_8a1f71c8bfde4dfe9ddffb44409a6984",
              "IPY_MODEL_9f94d3b420e8458eb4e967b309e5eca7"
            ],
            "layout": "IPY_MODEL_8cbba5df11334b25b163c648cd1c208b"
          }
        },
        "9cd6ffbe92494e8aa6b5b7fa53bd7fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d44a35228414e86a89e06e66434e975": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8d8818e5904c8f8e0a09d6995d624e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e886eb6e7ff41af899ecc8d90fd9591",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3419b259f07b4cca86eab685d05d6e74",
            "value": 190
          }
        },
        "9f3d2557492647e2a804f4f5ce32eec7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f70a22bbb6146a4a0151ae2fbeffdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c266ac54bec7423588398b3da9430000",
              "IPY_MODEL_027b7a49ad3d48f3a575ed03c2245e60",
              "IPY_MODEL_e5125b04c82c4753946e289d8457ce5f"
            ],
            "layout": "IPY_MODEL_f019d0fef7f14dcbb3b217417122233a"
          }
        },
        "9f94d3b420e8458eb4e967b309e5eca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a41f6cb59b24148b295b1a77427e3fe",
            "placeholder": "​",
            "style": "IPY_MODEL_e2de896af414409694d262688b76f067",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 681kB/s]"
          }
        },
        "9feb4d40fa5a45c391aafdda0fde77b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feed9be0a0d840058632ab8326063fa9",
            "placeholder": "​",
            "style": "IPY_MODEL_a3caf8326c304b8fa8e2a56771b1349d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9ff517288f9f476ca968c40d2a9bf31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33baa38c764c4fc686bc143365c7f9db",
              "IPY_MODEL_536f6d8687af4aa088f2c2785a9642cb",
              "IPY_MODEL_3eb6be301f9d463b99a0915a383a7d34"
            ],
            "layout": "IPY_MODEL_e5d50c4598f54f1abb2ef0d2e9ca95a5"
          }
        },
        "a0567ca8e9f54e829bb77722e92f243a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09d0265a264472cad6f883431f1e412": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09e4fac1fcd4a5b8d67b9564997c816": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_317a2045e23f46be83afa8a474f0234e",
            "placeholder": "​",
            "style": "IPY_MODEL_f0b31d544aa448089225893f91e2f346",
            "value": " 349/349 [00:00&lt;00:00, 22.5kB/s]"
          }
        },
        "a1e1e1363f4a460db453b9df68b47799": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1f5b1bb3182455c82883515d6b0c9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3caf8326c304b8fa8e2a56771b1349d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4d31b1ee2a04d8e8e52175e64ddc680": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca3926a9bcef4a19935e2f0992e6e06b",
            "placeholder": "​",
            "style": "IPY_MODEL_1c97412b5f9d4e4db3297c57905578b7",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "a4e5f80c88024136b995ca8ad7f227b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f556d528d64ce9b3c76d22ac9d344e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63184bb7a5347ad96b228ba32fd43b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a698c05ca3914319a8a8ed8676fd3d32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a751841437dd48b6ae822587f215db06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a786fbf8a8454ec185964763ca8de96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f471d30ec974177816aef2acf2d1468",
              "IPY_MODEL_31e6dc60c55e4c989f2498cb555756b7",
              "IPY_MODEL_e10b4b04a66b43908851895ac0ef391a"
            ],
            "layout": "IPY_MODEL_c20207bc1e8748ffad80a3eeda12adcd"
          }
        },
        "aa5409bf2a3e4bc3a94d12ef12a4b78e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa749b201b324e45aeb3fdc5e157503e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3157ee66557d4e14b53d41aa49cf6640",
              "IPY_MODEL_59103fb636264a80ba02321c1e3ebd3e",
              "IPY_MODEL_0f8b8a58b8734425b31d46b14ad5a8e2"
            ],
            "layout": "IPY_MODEL_35e3acb9aae045d8a1391604ac897cb8"
          }
        },
        "aada6b037a004280883eefe043492884": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab430d17325643b39c5b25e3dcfee1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae946eac3079424f80eba8150808f9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc1a6ba3fb34a40a353c7c348bf03a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0964b0c43d64388abe1d9348f76dfe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e673ec01cb4441b0b4639b1775c456": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ad21d7db87344c0b0cde9429ae793c4",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d44a35228414e86a89e06e66434e975",
            "value": 53
          }
        },
        "b16948b1fd5049bb83329fc2077c1987": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de7ffa395c5e4da185a855beb5bac22a",
            "placeholder": "​",
            "style": "IPY_MODEL_37db1a7ca2a747d3954eb566627c3911",
            "value": " 232k/232k [00:00&lt;00:00, 1.01MB/s]"
          }
        },
        "b16d6a22389e4417b44f2982c961385a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4533176d8245689c371b1233aba2ec",
            "placeholder": "​",
            "style": "IPY_MODEL_2e1ebe881b5a42c58587569ba4bc4ee5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b2be3e3f50da4675924526a47e507172": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b38ff279188c49afa8298ada33bb2d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427287483c0d4fa0955e64afb31853a8",
            "placeholder": "​",
            "style": "IPY_MODEL_9cd6ffbe92494e8aa6b5b7fa53bd7fec",
            "value": "config.json: 100%"
          }
        },
        "b3b395c628e24112b0c2187fbac8495e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4172c6cfc044be99a91b4c28588d5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c56170974c426088c9f98cc4929ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_087f3fb3dece4ba38f11d8e1337d81b1",
            "value": "README.md: 100%"
          }
        },
        "b429ee2cda484aa4b83f9c2e734115f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b458336632f14d2fa74055e635813371": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a3d268b68340498e6518d1442112d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69afe3bc7c24699a638a2777cc41532": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e8f72e20c94ea78ca5ad65139dbe09",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95b0687fa64d4e9c920c06ca83c9aba3",
            "value": 2
          }
        },
        "b7e2d3b3294443dcbcc0e984f4d87a24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8f3ba97542d451fad66ebcf873c3dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba5ab4eec6b7462593eca772a51ab824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb3ee7101f52431eb432321ddc75e9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbfa611b3dce4fcf9a2b8a0c80d6bdc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b3b03e29c894280a24872b6e800de64",
              "IPY_MODEL_c6acd511d9a842558ca3c7899f34c070",
              "IPY_MODEL_94ecb12282104cd784701a2a2cb409c2"
            ],
            "layout": "IPY_MODEL_50609d8d50eb48f2abf9142905512af4"
          }
        },
        "bc26f917c99a4aac9f849f0442422ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc339e3c8a244c191c062214509d997",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_193093e6cfff417f951ebaaf09671e87",
            "value": 231508
          }
        },
        "bdd3ae8bfbf446309b54f466de0e1af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beace35c737c42c9828e1586ef91a71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf0df769c6b040359d8728c108b9bbe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfee76eb8c9a47fab2022c181637328d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0e8f72e20c94ea78ca5ad65139dbe09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20207bc1e8748ffad80a3eeda12adcd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c266ac54bec7423588398b3da9430000": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b32cdc0338344898ef00ee08844758b",
            "placeholder": "​",
            "style": "IPY_MODEL_8d214dff5b76415582a6cca9e17f81e1",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "c2b0326344c7466fa45233158130240a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c487ab2ee27c4007bd82f829d78fe77c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5e82c9fcaaf4f63963b62aeed0e24d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bb55f9a2efb403c8d92e4c5ffe1993e",
              "IPY_MODEL_2349fde161f649af85222df94c23b045",
              "IPY_MODEL_f5adee2290924e7a8439d4cff65123cb"
            ],
            "layout": "IPY_MODEL_a751841437dd48b6ae822587f215db06"
          }
        },
        "c650c033bcb24c779a9891b54b8da219": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_807ce00e629149678b3649d6c02ff67f",
            "placeholder": "​",
            "style": "IPY_MODEL_832cc49113c34d30b562e476575b983a",
            "value": "config.json: 100%"
          }
        },
        "c672691d80c0473bb3bc44f62e32a9f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6acd511d9a842558ca3c7899f34c070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11d69fc88a6b457c997da400566d6a02",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_596655d0ad1245a690d37ebc70d51cd3",
            "value": 90888945
          }
        },
        "c881d316bea849b9a4db9ef6b4f18599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c92989c8bb764ba28778e47f242186ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49fbbe1ca0c64348abe4047859b5dd5b",
            "max": 739,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d615cfe957a642ce80e2ea6da8656aed",
            "value": 739
          }
        },
        "c9a6480a0eba411a8a4acce844559588": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca207e6b5bd644d9b21437ffdf8eba7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab430d17325643b39c5b25e3dcfee1a5",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0aaa23af7bd4e8a8f303689af41fe5d",
            "value": 466247
          }
        },
        "ca3926a9bcef4a19935e2f0992e6e06b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cacfbbd5d1f0470ca42890b58e4e6900": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd0a39ae7243412eab43e5c2f22a1e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87bb5591bb1b4c25bb860a8db09babdc",
            "placeholder": "​",
            "style": "IPY_MODEL_0cf0768f4e1f42d595c47576b8f66dac",
            "value": "tokenizer.json: 100%"
          }
        },
        "cedddddd215f4932bf42a08b45ddf93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb3c007568b48e79ea453d213881697",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d0b63e006214bb199c7543443cf3dd4",
            "value": 612
          }
        },
        "cf4533176d8245689c371b1233aba2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd9a78938cc404db75c35378068a04d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d023c3c6081a4a77a3fb6de417b0c0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0aaa23af7bd4e8a8f303689af41fe5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2fb00280a2640c1863b191907bde088": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d324f2f3b7b34f3ab502c66049b6b430": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ad73ea5e1be4a359ecd7cbc49508043",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f524b286d88c4299939f7906985703e8",
            "value": 231508
          }
        },
        "d575e8b440c14398a6cd7abb22f579a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d59310db9e3648f1bdeabc9977802db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7ef3b2f2b04fee8efcac86d1585f17",
            "placeholder": "​",
            "style": "IPY_MODEL_ba5ab4eec6b7462593eca772a51ab824",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d6051ad35b6940cda73df32a26f10030": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60dbf7f818e4e568fc06863ced521b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e7e0c9643d34180a052fb314b8735cd",
            "placeholder": "​",
            "style": "IPY_MODEL_ebff15f9b7454673bb928d675e3291c1",
            "value": " 612/612 [00:00&lt;00:00, 38.9kB/s]"
          }
        },
        "d615cfe957a642ce80e2ea6da8656aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d62ca963a7e7456a9cdee2c2bbdc70c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c672691d80c0473bb3bc44f62e32a9f2",
            "placeholder": "​",
            "style": "IPY_MODEL_d93e401dd97a4cef86d8c80fed16a98c",
            "value": "vocab.txt: 100%"
          }
        },
        "d68fbc522dde4d239d4f93ae2bf77b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd0a39ae7243412eab43e5c2f22a1e32",
              "IPY_MODEL_8783f0c5e28d4617a3d2dd0ef7db294a",
              "IPY_MODEL_693fdc2e9673430397a39108a134779f"
            ],
            "layout": "IPY_MODEL_8d6c0dd8a26840e88f68653fe5108ec1"
          }
        },
        "d77c2b0dba0847d890ec8f820171ddd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a80a188e9a24f81b692cb09dd13eef0",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfee76eb8c9a47fab2022c181637328d",
            "value": 350
          }
        },
        "d78137388b2748a4aeb8a6f21dcc0d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ac4540ecb74e789551ae70c0c6f37e",
            "placeholder": "​",
            "style": "IPY_MODEL_8436ebf7f3df4257bf92a8df31c72826",
            "value": ".gitattributes: 100%"
          }
        },
        "d93e401dd97a4cef86d8c80fed16a98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9706e40a31543b28bd852bc55528059": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0ba7fe26044178b07ee58e7e0eac25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa2c8d82417425ea17b305124d034dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc550b8d89fc42e190367d0cd6b04886": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a698c05ca3914319a8a8ed8676fd3d32",
            "max": 9976218536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8965f7137844485386d2c23b69eb6a66",
            "value": 9976218536
          }
        },
        "dc6d6df107e544758eb14241b8072628": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2be3e3f50da4675924526a47e507172",
            "placeholder": "​",
            "style": "IPY_MODEL_6a79e4c345484b0aa3c4cef1f02f0fec",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 812kB/s]"
          }
        },
        "ddc126a925e44ecbbc4ba708fb1cfc53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de4db21c49824949972f6ff47c498ad9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de7ffa395c5e4da185a855beb5bac22a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e101f73cd7574e07b7f8d55f97030627": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e10b4b04a66b43908851895ac0ef391a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4db21c49824949972f6ff47c498ad9",
            "placeholder": "​",
            "style": "IPY_MODEL_ece4ca531d3045a0bbb1c59465e77cc6",
            "value": " 28.9k/28.9k [00:00&lt;00:00, 1.43MB/s]"
          }
        },
        "e25ab01821964452833988ca0491780e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e2d3b3294443dcbcc0e984f4d87a24",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f5b1bb3182455c82883515d6b0c9b9",
            "value": " 232k/232k [00:00&lt;00:00, 3.98MB/s]"
          }
        },
        "e2de896af414409694d262688b76f067": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4bf3d31d3134aa2bc04e09485cf1e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d183e6bb1044eab1d0739661e0c70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec004fbc916640f3b9e11e9d52b9cb95",
            "placeholder": "​",
            "style": "IPY_MODEL_77bb1b0e53fa4309935ef5d509cb1388",
            "value": "tokenizer.json: 100%"
          }
        },
        "e5125b04c82c4753946e289d8457ce5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed385c3bea340d8972992169b5d100d",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa484311f1b4c9a81aeec7d877b3fe9",
            "value": " 4.16G/4.16G [00:32&lt;00:00, 126MB/s]"
          }
        },
        "e53ef8648d164a15ac19c333af8607eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ac4540ecb74e789551ae70c0c6f37e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5bedfddcf224d6698e3c19a56af0d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a63184bb7a5347ad96b228ba32fd43b5",
            "placeholder": "​",
            "style": "IPY_MODEL_6a544fd636004abbba74ed30d7e922d7",
            "value": " 2/2 [02:12&lt;00:00, 60.48s/it]"
          }
        },
        "e5d50c4598f54f1abb2ef0d2e9ca95a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e611461bbf9345c29b2fa329959ec4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddc126a925e44ecbbc4ba708fb1cfc53",
            "placeholder": "​",
            "style": "IPY_MODEL_d023c3c6081a4a77a3fb6de417b0c0af",
            "value": "config.json: 100%"
          }
        },
        "e6345d06513b454b91792470ed1b0cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e860ba7e68ae485ab34876033e12bb45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9272fc7a0ce4eb49e076794a6b0b0ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674d1fa78c204dc9b9c418d3d195cfde",
            "placeholder": "​",
            "style": "IPY_MODEL_24d55a35c0b04a49bc6c907db05519d6",
            "value": " 112/112 [00:00&lt;00:00, 4.46kB/s]"
          }
        },
        "e9ccb4056dde4e7ebddc7e2307e9707d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea13ac8fa51542abb1a6d9be5aa0fec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9706e40a31543b28bd852bc55528059",
            "placeholder": "​",
            "style": "IPY_MODEL_c487ab2ee27c4007bd82f829d78fe77c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ea4b48cff61f4b33a5e7eaaf7537f132": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_551e041650c74c29a3257fee3b980621",
            "placeholder": "​",
            "style": "IPY_MODEL_08312738806345918af44ea457a9fc7f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ebff15f9b7454673bb928d675e3291c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec004fbc916640f3b9e11e9d52b9cb95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eccc112bdfae4b4ca19641dafd65ac70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09918fbd9ede462c8b5b079e88301694",
              "IPY_MODEL_5435d900005746cfa4af930cae25cd80",
              "IPY_MODEL_ef7a94486d3b4c28a864daf5020ef3da"
            ],
            "layout": "IPY_MODEL_528ce477dd49496dbff1829d1e80af34"
          }
        },
        "ece4ca531d3045a0bbb1c59465e77cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed635c515e7844e587054c46f8a7293a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee9356333e7046f9a86aee08621dda90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea49467fbba44d29ba25baf467ffbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8406164b0d0f43f8bb081cd49f4246ec",
            "placeholder": "​",
            "style": "IPY_MODEL_757a0f0ba8724da9a6fbf73aba5de82f",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "ef7a94486d3b4c28a864daf5020ef3da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92bb7a6fe45d4424a0d98c4b7bb8c7c9",
            "placeholder": "​",
            "style": "IPY_MODEL_58c142ff738543179e3bc3b747991f19",
            "value": " 116/116 [00:00&lt;00:00, 8.11kB/s]"
          }
        },
        "f019d0fef7f14dcbb3b217417122233a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0579994e98144beab765911a8e385ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0b31d544aa448089225893f91e2f346": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0bf1d5f74624e67b0abb332db9bd0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f16044a1afd8473f9aa57c634b8cfab8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2edbff665fc4565841e6794d5c408a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37b04d31ef1455681b98a753b5476f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d31b1ee2a04d8e8e52175e64ddc680",
              "IPY_MODEL_b0e673ec01cb4441b0b4639b1775c456",
              "IPY_MODEL_f9b5ecd847114027aa278510e4c18e45"
            ],
            "layout": "IPY_MODEL_fa58782683944545806e8d7a03905e95"
          }
        },
        "f524b286d88c4299939f7906985703e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5adee2290924e7a8439d4cff65123cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd9a78938cc404db75c35378068a04d",
            "placeholder": "​",
            "style": "IPY_MODEL_54a41279949842a4abefeb0dfdc6458e",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.29kB/s]"
          }
        },
        "f6628047e7674ab89601484abcec35db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7c1ab76a81e470fb99b82fcaf4cd48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7d917c921d7453cad9bf1425c07f52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2fb00280a2640c1863b191907bde088",
            "placeholder": "​",
            "style": "IPY_MODEL_2e393313728d4e9b96c1baaa2deecddc",
            "value": "README.md: 100%"
          }
        },
        "f83837f7cbe7456b9e8166e0ac6feb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aada6b037a004280883eefe043492884",
            "placeholder": "​",
            "style": "IPY_MODEL_beace35c737c42c9828e1586ef91a71c",
            "value": " 112/112 [00:00&lt;00:00, 4.33kB/s]"
          }
        },
        "f87bb131ffb2419f8800100cb8d316d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d183e6bb1044eab1d0739661e0c70b",
              "IPY_MODEL_ca207e6b5bd644d9b21437ffdf8eba7d",
              "IPY_MODEL_0c09574f6d8b455885000920293fcd70"
            ],
            "layout": "IPY_MODEL_e4bf3d31d3134aa2bc04e09485cf1e4c"
          }
        },
        "f9b5ecd847114027aa278510e4c18e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd9226875e34d319c90b6cd88870906",
            "placeholder": "​",
            "style": "IPY_MODEL_36e65a8cc7f043f0b5a6491f6e3b53aa",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.29kB/s]"
          }
        },
        "fa58782683944545806e8d7a03905e95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7bc7a30bc745d690399b97b3273b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbb3c007568b48e79ea453d213881697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd2ba16f5a14916855d10412a02c035": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc180f1b45ec4021bd1a7d9b3e1290e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d62ca963a7e7456a9cdee2c2bbdc70c8",
              "IPY_MODEL_d324f2f3b7b34f3ab502c66049b6b430",
              "IPY_MODEL_b16948b1fd5049bb83329fc2077c1987"
            ],
            "layout": "IPY_MODEL_44e0b472a17c47448adca9c581bb4e85"
          }
        },
        "fc445ac7745f46f4a514761c8d5e90af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_028dc09f782e4e58af108564ee9d2b7d",
            "max": 222,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_857c1addd5c7459d833b9ac52453ea75",
            "value": 222
          }
        },
        "fc54d4668a304b219dc905aedcf037b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_987b0d9fae584ed599532a5889b6db40",
            "placeholder": "​",
            "style": "IPY_MODEL_541e19804f044767a955876ed8473564",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 74.3kB/s]"
          }
        },
        "fdb3284aa4ff4e4499b2bda1c6912829": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec3e04becb747298b19260748b874c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feed9be0a0d840058632ab8326063fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff5b743d3eaa43048c8e8c060731417f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
